<!DOCTYPE html>


<html lang="en">
	

		<head>
			<meta charset="utf-8" />
			 
			<meta name="keywords" content="life,think,work,blog,code" />
			 
			<meta name="description" content="a place holder" />
			
			<meta
				name="viewport"
				content="width=device-width, initial-scale=1, maximum-scale=1"
			/>
			<meta
				name="google-site-verification"
				content="Xe5wkkWgdmMwA81kCWOHLlJSlYSRE47NKPlVzl8ynK8"
			/>
			<title> Blog</title>
  <meta name="generator" content="hexo-theme-ayer">
			
			<link rel="shortcut icon" href="/favicon.ico" />
			 
<link rel="stylesheet" href="/dist/main.css">

			<link
				rel="stylesheet"
				href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
			/>
			
<link rel="stylesheet" href="/css/custom.css">
 
			<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
			 
 

		<link rel="alternate" href="/atom.xml" title="Blog" type="application/atom+xml">
</head>
	</html>
</html>


<body>
  <div id="app">
    
      
      <canvas width="1777" height="841"
        style="position: fixed; left: 0px; top: 0px; z-index: 99999; pointer-events: none;"></canvas>
      
    <main class="content on">
      
<section class="cover">
	<div class="cover-frame">
		<div class="bg-box">
			<img src="/images/cover3.jpg" alt="image frame" />
		</div>
		<div class="cover-inner text-center text-white">
			<h1><a href="/">Blog</a></h1>
			<div id="subtitle-box">
				
				<span id="subtitle"></span>
				
			</div>
			<div>
				
			</div>
		</div>
	</div>
	<div class="cover-learn-more">
		<a href="javascript:void(0)" class="anchor"
			><i class="ri-arrow-down-line"></i
		></a>
	</div>
</section>
 
<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js"></script>


<!-- Subtitle -->

<script>
	try {
	  var typed = new Typed("#subtitle", {
	    strings: ['It doesn&#39;t work...... why?', 'It works...... why?', 'I used to have a life... But Now I&#39;m a programmer.'],
	    startDelay: 100,
	    typeSpeed: 50,
	    loop: false,
	    backSpeed: 20,
	    showCursor: true
	  });
	} catch (err) {
	  console.log(err)
	}
</script>


<div id="main">
  <section class="outer">
  
  
  <article class="articles">
    
    
    
    
    <article
  id="post-how-database-work"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/02/07/how-database-work/"
    >How database work</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/02/07/how-database-work/" class="article-date">
  <time datetime="2020-02-08T01:31:19.000Z" itemprop="datePublished">2020-02-07</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>When it comes to relational databases, I can’t help thinking that something is missing. They’re used everywhere. There are many different databases: from the small and useful SQLite to the powerful Teradata. But, there are only a few articles that explain how a database works. You can google by yourself “how does a relational database work” to see how few results there are. Moreover, those articles are short. Now, if you look for the last trendy technologies (Big Data, NoSQL or JavaScript), you’ll find more in-depth articles explaining how they work.</p>
<p>Are relational databases too old and too boring to be explained outside of university courses, research papers and books?</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/main_databases.jpg"><img src="../../public/images/main_databases-20200207203251326.jpg" alt="logos of main databases"></a></p>
<p>As a developer, I HATE using something I don’t understand. And, if databases have been used for 40 years, there must be a reason. Over the years, I’ve spent hundreds of hours to really understand these weird black boxes I use every day. <strong>Relational Databases</strong> <strong>are</strong> very interesting because they’re <strong>based on useful and reusable concepts</strong>. If understanding a database interests you but you’ve never had the time or the will to dig into this wide subject, you should like this article.</p>
<p>Though the title of this article is explicit, <strong>the aim of this article is NOT to understand how to use a database</strong>. Therefore, <strong>you should already know how to write a simple join query and basic CRUD queries</strong>; otherwise you might not understand this article. This is the only thing you need to know, I’ll explain everything else.</p>
<p>I’ll start with some computer science stuff like time complexity. I know that some of you hate this concept but, without it, you can’t understand the cleverness inside a database. Since it’s a huge topic, <strong>I’ll focus on</strong> what I think is essential: <strong>the way a database handles an SQL query</strong>. I’ll only present <strong>the basic concepts behind a database</strong> so that at the end of the article you’ll have a good idea of what’s happening under the hood.</p>
<p>Since it’s a long and technical article that involves many algorithms and data structures, take your time to read it. Some concepts are more difficult to understand; you can skip them and still get the overall idea.</p>
<p>For the more knowledgeable of you, this article is more or less divided into 3 parts:</p>
<ul>
<li>An overview of low-level and high-level database components</li>
<li>An overview of the query optimization process</li>
<li>An overview of the transaction and buffer pool management</li>
</ul>
<p>Contents [<a target="_blank" rel="noopener" href="http://coding-geek.com/how-databases-work/#">show</a>]</p>
<h1 id="Back-to-basics"><a href="#Back-to-basics" class="headerlink" title="Back to basics"></a>Back to basics</h1><p>A long time ago (in a galaxy far, far away….), developers had to know exactly the number of operations they were coding. They knew by heart their algorithms and data structures because they couldn’t afford to waste the CPU and memory of their slow computers.</p>
<p>In this part, I’ll remind you about some of these concepts because they are essential to understand a database. I’ll also introduce the notion of <strong>database index</strong>.</p>
<h2 id="O-1-vs-O-n2"><a href="#O-1-vs-O-n2" class="headerlink" title="O(1) vs O(n2)"></a>O(1) vs O(n2)</h2><p>Nowadays, many developers don’t care about time complexity … and they’re right!</p>
<p>But when you deal with a large amount of data (I’m not talking about thousands) or if you’re fighting for milliseconds, it becomes critical to understand this concept. And guess what, databases have to deal with both situations! I won’t bore you a long time, just the time to get the idea. This will help us later to understand the concept of <strong>cost based optimization</strong>.</p>
<h3 id="The-concept"><a href="#The-concept" class="headerlink" title="The concept"></a>The concept</h3><p>The <strong>time complexity is used to see how long an algorithm will take for a given amount of data</strong>. To describe this complexity, computer scientists use the mathematical big O notation. This notation is used with a function that describes how many operations an algorithm needs for a given amount of input data.</p>
<p>For example, when I say “this algorithm is in O( some_function() )”, it means that for a certain amount of data the algorithm needs some_function(a_certain_amount_of_data) operations to do its job.</p>
<p><strong>What’s important is</strong> not the amount of data but <strong>the way the number of operations increases when the amount of data increases</strong>. The time complexity doesn’t give the exact number of operations but a good idea.</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/TimeComplexity.png"><img src="../../public/images/TimeComplexity-20200207203251326.png" alt="time complexity analysis"></a></p>
<p>In this figure, you can see the evolution of different types of complexities. I used a logarithmic scale to plot it. In other words, the number of data is quickly increasing from 1 to 1 billion. We can see that:</p>
<ul>
<li>The O(1) or constant complexity stays constant (otherwise it wouldn’t be called constant complexity).</li>
<li>The <strong>O(log(n)) stays low even with billions of data</strong>.</li>
<li>The worst complexity is the <strong>O(n2) where the number of operations quickly explodes</strong>.</li>
<li>The two other complexities are quickly increasing.</li>
</ul>
<h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><p>With a low amount of data, the difference between O(1) and O(n2) is negligible. For example, let’s say you have an algorithm that needs to process 2000 elements.</p>
<ul>
<li>An O(1) algorithm will cost you 1 operation</li>
<li>An O(log(n)) algorithm will cost you 7 operations</li>
<li>An O(n) algorithm will cost you 2 000 operations</li>
<li>An O(n*log(n)) algorithm will cost you 14 000 operations</li>
<li>An O(n2) algorithm will cost you 4 000 000 operations</li>
</ul>
<p>The difference between O(1) and O(n2) seems a lot (4 million) but you’ll lose at max 2 ms, just the time to blink your eyes. Indeed, current processors can handle <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Instructions_per_second">hundreds of millions of operations per second</a>. This is why performance and optimization are not an issue in many IT projects.</p>
<p>As I said, it’s still important to know this concept when facing a huge number of data. If this time the algorithm needs to process 1 000 000 elements (which is not that big for a database):</p>
<ul>
<li>An O(1) algorithm will cost you 1 operation</li>
<li>An O(log(n)) algorithm will cost you 14 operations</li>
<li>An O(n) algorithm will cost you 1 000 000 operations</li>
<li>An O(n*log(n)) algorithm will cost you 14 000 000 operations</li>
<li>An O(n2) algorithm will cost you 1 000 000 000 000 operations</li>
</ul>
<p>I didn’t do the math but I’d say with the O(n2) algorithm you have the time to take a coffee (even a second one!). If you put another 0 on the amount of data, you’ll have the time to take a long nap.</p>
<h3 id="Going-deeper"><a href="#Going-deeper" class="headerlink" title="Going deeper"></a>Going deeper</h3><p>To give you an idea:</p>
<ul>
<li>A search in a good hash table gives an element in O(1)</li>
<li>A search in a well-balanced tree gives a result in O(log(n))</li>
<li>A search in an array gives a result in O(n)</li>
<li>The best sorting algorithms have an O(n*log(n)) complexity.</li>
<li>A bad sorting algorithm has an O(n2) complexity</li>
</ul>
<p>Note: In the next parts, we’ll see these algorithms and data structures.</p>
<p>There are multiple types of time complexity:</p>
<ul>
<li>the average case scenario</li>
<li>the best case scenario</li>
<li>and the worst case scenario</li>
</ul>
<p>The time complexity is often the worst case scenario.</p>
<p>I only talked about time complexity but complexity also works for:</p>
<ul>
<li>the memory consumption of an algorithm</li>
<li>the disk I/O consumption of an algorithm</li>
</ul>
<p>Of course there are worse complexities than n2, like:</p>
<ul>
<li>n4: that sucks! Some of the algorithms I’ll mention have this complexity.</li>
<li>3n: that sucks even more! One of the algorithms we’re going to see in the middle of this article has this complexity (and it’s really used in many databases).</li>
<li>factorial n : you’ll never get your results, even with a low amount of data.</li>
<li>nn: if you end-up with this complexity, you should ask yourself if IT is really your field…</li>
</ul>
<p>Note: I didn’t give you the real definition of the big O notation but just the idea. You can read this article on <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Big_O_notation">Wikipedia</a> for the real (asymptotic) definition.</p>
<h2 id="Merge-Sort"><a href="#Merge-Sort" class="headerlink" title="Merge Sort"></a>Merge Sort</h2><p>What do you do when you need to sort a collection? What? You call the sort() function … ok, good answer… But for a database you have to understand how this sort() function works.</p>
<p>There are several good sorting algorithms so I’ll focus on the most important one: <strong>the merge sort</strong>. You might not understand right now why sorting data is useful but you should after the part on query optimization. Moreover, understanding the merge sort will help us later to understand a common database join operation called the <strong>merge join</strong>.</p>
<h3 id="Merge"><a href="#Merge" class="headerlink" title="Merge"></a>Merge</h3><p>Like many useful algorithms, the merge sort is based on a trick: merging 2 sorted arrays of size N/2 into a N-element sorted array only costs N operations. This operation is called a <strong>merge</strong>.</p>
<p>Let’s see what this means with a simple example:</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/merge_sort_3.png"><img src="../../public/images/merge_sort_3-20200207203251311.png" alt="merge operation during merge sort algorithm"></a></p>
<p>You can see on this figure that to construct the final sorted array of 8 elements, you only need to iterate one time in the 2 4-element arrays. Since both 4-element arrays are already sorted:</p>
<ul>
<li>1) you compare both current elements in the 2 arrays (current=first for the first time)</li>
<li>2) then take the lowest one to put it in the 8-element array</li>
<li>3) and go to the next element in the array you took the lowest element</li>
<li>and repeat 1,2,3 until you reach the last element of one of the arrays.</li>
<li>Then you take the rest of the elements of the other array to put them in the 8-element array.</li>
</ul>
<p>This works because both 4-element arrays are sorted and therefore you don’t need to “go back” in these arrays.</p>
<p>Now that we’ve understood this trick, here is my pseudocode of the merge sort.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array mergeSort(array a)&#96;&#96;  &#96;&#96;if&#96;&#96;(length(a)&#x3D;&#x3D;&#96;&#96;1&#96;&#96;)&#96;&#96;   &#96;&#96;return&#96; &#96;a[&#96;&#96;0&#96;&#96;];&#96;&#96;  &#96;&#96;end &#96;&#96;if&#96; &#96;  &#96;&#96;&#x2F;&#x2F;recursive calls&#96;&#96;  &#96;&#96;[left_array right_array] :&#x3D; split_into_2_equally_sized_arrays(a);&#96;&#96;  &#96;&#96;array new_left_array :&#x3D; mergeSort(left_array);&#96;&#96;  &#96;&#96;array new_right_array :&#x3D; mergeSort(right_array);&#96; &#96;  &#96;&#96;&#x2F;&#x2F;merging the 2 small ordered arrays into a big one&#96;&#96;  &#96;&#96;array result :&#x3D; merge(new_left_array,new_right_array);&#96;&#96;  &#96;&#96;return&#96; &#96;result;</span><br></pre></td></tr></table></figure>

<p>The merge sort breaks the problem into smaller problems then finds the results of the smaller problems to get the result of the initial problem (note: this kind of algorithms is called divide and conquer). If you don’t understand this algorithm, don’t worry; I didn’t understand it the first time I saw it. If it can help you, I see this algorithm as a two-phase algorithm:</p>
<ul>
<li>The division phase where the array is divided into smaller arrays</li>
<li>The sorting phase where the small arrays are put together (using the merge) to form a bigger array.</li>
</ul>
<h3 id="Division-phase"><a href="#Division-phase" class="headerlink" title="Division phase"></a>Division phase</h3><p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/merge_sort_1.png"><img src="../../public/images/merge_sort_1-20200207203251327.png" alt="division phaseduring merge sort algorithm"></a></p>
<p>During the division phase, the array is divided into unitary arrays using 3 steps. The formal number of steps is log(N) (since N=8, log(N) = 3).</p>
<p>How do I know that?</p>
<p>I’m a genius! In one word: mathematics. The idea is that each step divides the size of the initial array by 2. The number of steps is the number of times you can divide the initial array by two. This is the exact definition of logarithm (in base 2).</p>
<h3 id="Sorting-phase"><a href="#Sorting-phase" class="headerlink" title="Sorting phase"></a>Sorting phase</h3><p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/merge_sort_2.png"><img src="../../public/images/merge_sort_2-20200207203251328.png" alt="sort phaseduring merge sort algorithm"></a></p>
<p>In the sorting phase, you start with the unitary arrays. During each step, you apply multiple merges and the overall cost is N=8 operations:</p>
<ul>
<li>In the first step you have 4 merges that cost 2 operations each</li>
<li>In the second step you have 2 merges that cost 4 operations each</li>
<li>In the third step you have 1 merge that costs 8 operations</li>
</ul>
<p>Since there are log(N) steps, <strong>the overall costs N * log(N) operations</strong>.</p>
<h3 id="The-power-of-the-merge-sort"><a href="#The-power-of-the-merge-sort" class="headerlink" title="The power of the merge sort"></a>The power of the merge sort</h3><p>Why this algorithm is so powerful?</p>
<p>Because:</p>
<ul>
<li>You can modify it in order to reduce the memory footprint, in a way that you don’t create new arrays but you directly modify the input array.</li>
</ul>
<p>Note: this kind of algorithms is called <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/In-place_algorithm">in-place</a>.</p>
<ul>
<li>You can modify it in order to use disk space and a small amount of memory at the same time without a huge disk I/O penalty. The idea is to load in memory only the parts that are currently processed. This is important when you need to sort a multi-gigabyte table with only a memory buffer of 100 megabytes.</li>
</ul>
<p>Note: this kind of algorithms is called <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/External_sorting">external sorting</a>.</p>
<ul>
<li>You can modify it to run on multiple processes/threads/servers.</li>
</ul>
<p>For example, the distributed merge sort is one of the key components of <a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapreduce/Reducer.html">Hadoop </a>(which is THE framework in Big Data).</p>
<ul>
<li>This algorithm can turn lead into gold (true fact!).</li>
</ul>
<p>This sorting algorithm is used in most (if not all) databases but it’s not the only one. If you want to know more, you can read this <a target="_blank" rel="noopener" href="http://wwwlgis.informatik.uni-kl.de/archiv/wwwdvs.informatik.uni-kl.de/courses/DBSREAL/SS2005/Vorlesungsunterlagen/Implementing_Sorting.pdf">research paper</a> that discusses the pros and cons of the common sorting algorithms in a database.</p>
<h2 id="Array-Tree-and-Hash-table"><a href="#Array-Tree-and-Hash-table" class="headerlink" title="Array, Tree and Hash table"></a>Array, Tree and Hash table</h2><p>Now that we understand the idea behind time complexity and sorting, I have to tell you about 3 data structures. It’s important because they’re <strong>the backbone of modern databases</strong>. I’ll also introduce the notion of <strong>database index</strong>.</p>
<h3 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h3><p>The two-dimensional array is the simplest data structure. A table can be seen as an array. For example:</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/array.png"><img src="../../public/images/array-20200207203251327.png" alt="array table in databases"></a></p>
<p>This 2-dimensional array is a table with rows and columns:</p>
<ul>
<li>Each row represents a subject</li>
<li>The columns the features that describe the subjects.</li>
<li>Each column stores a certain type of data (integer, string, date …).</li>
</ul>
<p>Though it’s great to store and visualize data, when you need to look for a specific value it sucks.</p>
<p>For example, <strong>if you want to find all the guys who work in the UK</strong>, you’ll have to look at each row to find if the row belongs to the UK. <strong>This will cost you N operations</strong> (N being the number of rows) which is not bad but could there be a faster way? This is where trees come into play.</p>
<p>Note: Most modern databases provide advanced arrays to store tables efficiently like heap-organized tables or index-organized tables. But it doesn’t change the problem of fast searching for a specific condition on a group of columns.</p>
<h3 id="Tree-and-database-index"><a href="#Tree-and-database-index" class="headerlink" title="Tree and database index"></a>Tree and database index</h3><p>A binary search tree is a binary tree with a special property, the key in each node must be:</p>
<ul>
<li>greater than all keys stored in the left sub-tree</li>
<li>smaller than all keys stored in the right sub-tree</li>
</ul>
<p>Let’s see what it means visually</p>
<h4 id="The-idea"><a href="#The-idea" class="headerlink" title="The idea"></a>The idea</h4><p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/BST.png"><img src="../../public/images/BST-20200207203251343.png" alt="binary search tree"></a></p>
<p>This tree has N=15 elements. Let’s say I’m looking for 208:</p>
<ul>
<li>I start with the root whose key is 136. Since 136&lt;208, I look at the right sub-tree of the node 136.</li>
<li>398&gt;208 so, I look at the left sub-tree of the node 398</li>
<li>250&gt;208 so, I look at the left sub-tree of the node 250</li>
<li>200&lt;208 so, I look at the right sub-tree of the node 200. But 200 doesn’t have a right subtree, <strong>the value doesn’t exist</strong> (because if it did exist it would be in the right subtree of 200)</li>
</ul>
<p>Now let’s say I’m looking for 40</p>
<ul>
<li>I start with the root whose key is 136. Since 136&gt;40, I look at the left sub-tree of the node 136.</li>
<li>80&gt;40 so, I look at the left sub-tree of the node 80</li>
<li>40= 40, <strong>the node exists</strong>. I extract the id of the row inside the node (it’s not in the figure) and look at the table for the given row id.</li>
<li>Knowing the row id let me know where the data is precisely on the table and therefore I can get it instantly.</li>
</ul>
<p>In the end, both searches cost me the number of levels inside the tree. If you read carefully the part on the merge sort you should see that there are log(N) levels. So the <strong>cost of the search is log(N)</strong>, not bad!</p>
<h4 id="Back-to-our-problem"><a href="#Back-to-our-problem" class="headerlink" title="Back to our problem"></a>Back to our problem</h4><p>But this stuff is very abstract so let’s go back to our problem. Instead of a stupid integer, imagine the string that represents the country of someone in the previous table. Suppose you have a tree that contains the column “country” of the table:</p>
<ul>
<li>If you want to know who is working in the UK</li>
<li>you look at the tree to get the node that represents the UK</li>
<li>inside the “UK node” you’ll find the locations of the rows of the UK workers.</li>
</ul>
<p>This search only costs you log(N) operations instead of N operations if you directly use the array. What you’ve just imagined was a <strong>database index</strong>.</p>
<p>You can build a tree index for any group of columns (a string, an integer, 2 strings, an integer and a string, a date …) as long as you have a function to compare the keys (i.e. the group of columns) so that you can establish an <strong>order</strong> <strong>among the keys</strong> (which is the case for any basic types in a database).</p>
<h4 id="B-Tree-Index"><a href="#B-Tree-Index" class="headerlink" title="B+Tree Index"></a>B+Tree Index</h4><p>Although this tree works well to get a specific value, there is a BIG problem when you need to <strong>get multiple elements</strong> <strong>between two values</strong>. It will cost O(N) because you’ll have to look at each node in the tree and check if it’s between these 2 values (for example, with an in-order traversal of the tree). Moreover this operation is not disk I/O friendly since you’ll have to read the full tree. We need to find a way to efficiently do a <strong>range query</strong>. To answer this problem, modern databases use a modified version of the previous tree called B+Tree. In a B+Tree:</p>
<ul>
<li>only the lowest nodes (the leaves) <strong>store information</strong> (the location of the rows in the associated table)</li>
<li>the other nodes are just here <strong>to route</strong> to the right node <strong>during the search</strong>.</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/database_index.png"><img src="../../public/images/database_index-20200207203251357.png" alt="B+Tree index in databases"></a></p>
<p>As you can see, there are more nodes (twice more). Indeed, you have additional nodes, the “decision nodes” that will help you to find the right node (that stores the location of the rows in the associated table). But the search complexity is still in O(log(N)) (there is just one more level). The big difference is that <strong>the lowest nodes are linked to their successors</strong>.</p>
<p>With this B+Tree, if you’re looking for values between 40 and 100:</p>
<ul>
<li>You just have to look for 40 (or the closest value after 40 if 40 doesn’t exist) like you did with the previous tree.</li>
<li>Then gather the successors of 40 using the direct links to the successors until you reach 100.</li>
</ul>
<p>Let’s say you found M successors and the tree has N nodes. The search for a specific node costs log(N) like the previous tree. But, once you have this node, you get the M successors in M operations with the links to their successors. <strong>This search only costs M + log(N)</strong> operations vs N operations with the previous tree. Moreover, you don’t need to read the full tree (just M + log(N) nodes), which means less disk usage. If M is low (like 200 rows) and N large (1 000 000 rows) it makes a BIG difference.</p>
<p>But there are new problems (again!). If you add or remove a row in a database (and therefore in the associated B+Tree index):</p>
<ul>
<li>you have to keep the order between nodes inside the B+Tree otherwise you won’t be able to find nodes inside the mess.</li>
<li>you have to keep the lowest possible number of levels in the B+Tree otherwise the time complexity in O(log(N)) will become O(N).</li>
</ul>
<p>I other words, the B+Tree needs to be self-ordered and self-balanced. Thankfully, this is possible with smart deletion and insertion operations. But this comes with a cost: the insertion and deletion in a B+Tree are in O(log(N)). This is why some of you have heard that <strong>using too many indexes is not a good idea.</strong> Indeed, <strong>you’re slowing down the fast insertion/update/deletion of a row</strong> in a table since the database needs to update the indexes of the table with a costly O(log(N)) operation per index. Moreover, adding indexes means more workload for the <strong>transaction manager</strong> (we will see this manager at the end of the article).</p>
<p>For more details, you can look at the Wikipedia <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/B%2B_tree">article about B+Tree</a>. If you want an example of a B+Tree implementation in a database, look at <a target="_blank" rel="noopener" href="http://blog.jcole.us/2013/01/07/the-physical-structure-of-innodb-index-pages/">this article</a> and <a target="_blank" rel="noopener" href="http://blog.jcole.us/2013/01/10/btree-index-structures-in-innodb/">this article</a> from a core developer of MySQL. They both focus on how innoDB (the engine of MySQL) handles indexes.</p>
<p>Note: I was told by a reader that, because of low-level optimizations, the B+Tree needs to be fully balanced.</p>
<h3 id="Hash-table"><a href="#Hash-table" class="headerlink" title="Hash table"></a>Hash table</h3><p>Our last important data structure is the hash table. It’s very useful when you want to quickly look for values.  Moreover, understanding the hash table will help us later to understand a common database join operation called the <strong>hash join</strong>. This data structure is also used by a database to store some internal stuff (like the <strong>lock table</strong> or the <strong>buffer pool</strong>, we’ll see both concepts later)</p>
<p>The hash table is a data structure that quickly finds an element with its key. To build a hash table you need to define:</p>
<ul>
<li><strong>a key</strong> for your elements</li>
<li><strong>a hash function</strong> for the keys. The computed hashes of the keys give the locations of the elements (called <strong>buckets</strong>).</li>
<li><strong>a function to compare the keys</strong>. Once you found the right bucket you have to find the element you’re looking for inside the bucket using this comparison.</li>
</ul>
<h4 id="A-simple-example"><a href="#A-simple-example" class="headerlink" title="A simple example"></a>A simple example</h4><p>Let’s have a visual example:</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/hash_table.png"><img src="../../public/images/hash_table-20200207203251356.png" alt="hash table"></a></p>
<p>This hash table has 10 buckets. Since I’m lazy I only drew 5 buckets but I know you’re smart so I let you imagine the 5 others. The Hash function I used is the modulo 10 of the key. In other words I only keep the last digit of the key of an element to find its bucket:</p>
<ul>
<li>if the last digit is 0 the element ends up in the bucket 0,</li>
<li>if the last digit is 1 the element ends up in the bucket 1,</li>
<li>if the last digit is 2 the element ends up in the bucket 2,</li>
<li>…</li>
</ul>
<p>The compare function I used is simply the equality between 2 integers.</p>
<p>Let’s say you want to get the element 78:</p>
<ul>
<li>The hash table computes the hash code for 78 which is 8.</li>
<li>It looks in the bucket 8, and the first element it finds is 78.</li>
<li>It gives you back the element 78</li>
<li><strong>The</strong> <strong>search only costs 2 operations</strong> (1 for computing the hash value and the other for finding the element inside the bucket).</li>
</ul>
<p>Now, let’s say you want to get the element 59:</p>
<ul>
<li>The hash table computes the hash code for 59 which is 9.</li>
<li>It looks in the bucket 9, and the first element it finds is 99. Since 99!=59, element 99 is not the right element.</li>
<li>Using the same logic, it looks at the second element (9), the third (79), … , and the last (29).</li>
<li>The element doesn’t exist.</li>
<li><strong>The search costs 7 operations</strong>.</li>
</ul>
<h4 id="A-good-hash-function"><a href="#A-good-hash-function" class="headerlink" title="A good hash function"></a>A good hash function</h4><p>As you can see, depending on the value you’re looking for, the cost is not the same!</p>
<p>If I now change the hash function with the modulo 1 000 000 of the key (i.e. taking the last 6 digits), the second search only costs 1 operation because there are no elements in the bucket 000059. <strong>The real challenge is to find a good hash function that will create buckets that contain a very small amount of elements</strong>.</p>
<p>In my example, finding a good hash function is easy. But this is a simple example, finding a good hash function is more difficult when the key is:</p>
<ul>
<li>a string (for example the last name of a person)</li>
<li>2 strings (for example the last name and the first name of a person)</li>
<li>2 strings and a date (for example the last name, the first name and the birth date of a person)</li>
<li>…</li>
</ul>
<p><strong>With a good hash function,</strong> <strong>the search in a hash table is in O(1)</strong>.</p>
<h4 id="Array-vs-hash-table"><a href="#Array-vs-hash-table" class="headerlink" title="Array vs hash table"></a>Array vs hash table</h4><p>Why not using an array?</p>
<p>Hum, you’re asking a good question.</p>
<ul>
<li>A hash table can be <strong>half loaded in memory</strong> and the other buckets can stay on disk.</li>
<li>With an array you have to use a contiguous space in memory. If you’re loading a large table it’s <strong>very difficult to have enough contiguous space</strong>.</li>
<li>With a hash table you can <strong>choose the key you want</strong> (for example the country AND the last name of a person).</li>
</ul>
<p>For more information, you can read my article on the <a target="_blank" rel="noopener" href="http://coding-geek.com/how-does-a-hashmap-work-in-java/">Java HashMap</a> which is an efficient hash table implementation; you don’t need to understand Java to understand the concepts inside this article.</p>
<h1 id="Global-overview"><a href="#Global-overview" class="headerlink" title="Global overview"></a>Global overview</h1><p>We’ve just seen the basic components inside a database. We now need to step back to see the big picture.</p>
<p>A database is a collection of information that can easily be accessed and modified. But a simple bunch of files could do the same. In fact, the simplest databases like SQLite are nothing more than a bunch of files. But SQLite is a well-crafted bunch of files because it allows you to:</p>
<ul>
<li>use transactions that ensure data are safe and coherent</li>
<li>quickly process data even when you’re dealing with millions of data</li>
</ul>
<p>More generally, a database can be seen as the following figure:</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/global_overview.png"><img src="../../public/images/global_overview-20200207203251364.png" alt="global overview of a database"></a></p>
<p>Before writing this part, I’ve read multiple books/papers and every source had its on way to represent a database. So, don’t focus too much on how I organized this database or how I named the processes because I made some choices to fit the plan of this article. What matters are the different components; the overall idea is that <strong>a database is divided into multiple components that interact with each other</strong>.</p>
<p>The core components:</p>
<ul>
<li><strong>The process manager</strong>: Many databases have a <strong>pool of processes/threads</strong> that needs to be managed. Moreover, in order to gain nanoseconds, some modern databases use their own threads instead of the Operating System threads.</li>
<li><strong>The network manager</strong>: Network I/O is a big issue, especially for distributed databases. That’s why some databases have their own manager.</li>
<li><strong>File system manager</strong>: <strong>Disk I/O is the first bottleneck of a database</strong>. Having a manager that will perfectly handle the Operating System file system or even replace it is important.</li>
<li><strong>The memory manager</strong>: To avoid the disk I/O penalty a large quantity of ram is required. But if you handle a large amount of memory, you need an efficient memory manager. Especially when you have many queries using memory at the same time.</li>
<li><strong>Security Manager</strong>: for managing the authentication and the authorizations of the users</li>
<li><strong>Client manager</strong>: for managing the client connections</li>
<li>…</li>
</ul>
<p>The tools:</p>
<ul>
<li><strong>Backup manager</strong>: for saving and restoring a database.</li>
<li><strong>Recovery manager</strong>: for restarting the database in a <strong>coherent state</strong> after a crash</li>
<li><strong>Monitor manager</strong>: for logging the activity of the database and providing tools to monitor a database</li>
<li><strong>Administration manager</strong>: for storing metadata (like the names and the structures of the tables) and providing tools to manage databases, schemas, tablespaces, …</li>
<li>…</li>
</ul>
<p>The query Manager:</p>
<ul>
<li><strong>Query parser</strong>: to check if a query is valid</li>
<li><strong>Query rewriter</strong>: to pre-optimize a query</li>
<li><strong>Query optimizer</strong>: to optimize a query</li>
<li><strong>Query executor</strong>: to compile and execute a query</li>
</ul>
<p>The data manager:</p>
<ul>
<li><strong>Transaction manager</strong>: to handle transactions</li>
<li><strong>Cache manager</strong>: to put data in memory before using them and put data in memory before writing them on disk</li>
<li><strong>Data access manager</strong>: to access data on disk</li>
</ul>
<p>For the rest of this article, I’ll focus on how a database manages an SQL query through the following processes:</p>
<ul>
<li>the client manager</li>
<li>the query manager</li>
<li>the data manager (I’ll also include the recovery manager in this part)</li>
</ul>
<h1 id="Client-manager"><a href="#Client-manager" class="headerlink" title="Client manager"></a>Client manager</h1><p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/client_manager.png"><img src="../../public/images/client_manager-20200207203251358.png" alt="client manager in databases"></a></p>
<p>The client manager is the part that handles the communications with the client. The client can be a (web) server or an end-user/end-application. The client manager provides different ways to access the database through a set of well-known APIs: JDBC, ODBC, OLE-DB …</p>
<p>It can also provide proprietary database access APIs.</p>
<p>When you connect to a database:</p>
<ul>
<li>The manager first checks your <strong>authentication</strong> (your login and password) and then checks if you have the <strong>authorizations</strong> to use the database. These access rights are set by your DBA.</li>
<li>Then, it checks if there is a process (or a thread) available to manage your query.</li>
<li>It also checks if the database if not under heavy load.</li>
<li>It can wait a moment to get the required resources. If this wait reaches a timeout, it closes the connection and gives a readable error message.</li>
<li>Then it <strong>sends your query to the query manager</strong> and your query is processed</li>
<li>Since the query processing is not an “all or nothing” thing, as soon as it gets data from the query manager, it <strong>stores</strong> <strong>the partial results in a buffer and start sending</strong> them to you.</li>
<li>In case of problem, it stops the connection, gives you a <strong>readable explanation</strong> and releases the resources.</li>
</ul>
<h1 id="Query-manager"><a href="#Query-manager" class="headerlink" title="Query manager"></a>Query manager</h1><p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/query_manager.png"><img src="../../public/images/query_manager-20200207203251359.png" alt="query manager in databases"></a></p>
<p><strong>This part is where the power of a database lies</strong>. During this part, an ill-written query is transformed into a <strong>fast</strong> executable code. The code is then executed and the results are returned to the client manager. It’s a multiple-step operation:</p>
<ul>
<li>the query is first <strong>parsed</strong> to see if it’s valid</li>
<li>it’s then <strong>rewritten</strong> to remove useless operations and add some pre-optimizations</li>
<li>it’s then <strong>optimized</strong> to improve the performances and transformed into an execution and data access plan.</li>
<li>then the plan is <strong>compiled</strong></li>
<li>at last, it’s <strong>executed</strong></li>
</ul>
<p>In this part, I won’t talk a lot about the last 2 points because they’re less important.</p>
<p>After reading this part, if you want a better understanding I recommend reading:</p>
<ul>
<li>The initial research paper (1979) on cost based optimization: <a target="_blank" rel="noopener" href="http://www.cs.berkeley.edu/~brewer/cs262/3-selinger79.pdf">Access Path Selection in a Relational Database Management System</a>. This article is only 12 pages and understandable with an average level in computer science.</li>
<li>A very good and in-depth presentation on how DB2 9.X optimizes queries <a target="_blank" rel="noopener" href="http://infolab.stanford.edu/~hyunjung/cs346/db2-talk.pdf">here</a></li>
<li>A very good presentation on how PostgreSQL optimizes queries <a target="_blank" rel="noopener" href="http://momjian.us/main/writings/pgsql/optimizer.pdf">here</a>. It’s the most accessible document since it’s more a presentation on “let’s see what query plans PostgreSQL gives in these situations“ than a “let’s see the algorithms used by PostgreSQL”.</li>
<li>The official <a target="_blank" rel="noopener" href="https://www.sqlite.org/optoverview.html">SQLite documentation</a> about optimization. It’s “easy” to read because SQLite uses simple rules. Moreover, it’s the only official documentation that really explains how it works.</li>
<li>A good presentation on how SQL Server 2005 optimizes queries <a target="_blank" rel="noopener" href="https://blogs.msdn.com/cfs-filesystemfile.ashx/__key/communityserver-components-postattachments/00-08-50-84-93/QPTalk.pdf">here</a></li>
<li>A white paper about optimization in Oracle 12c <a target="_blank" rel="noopener" href="http://www.oracle.com/technetwork/database/bi-datawarehousing/twp-optimizer-with-oracledb-12c-1963236.pdf">here</a></li>
<li>2 theoretical courses on query optimization from the authors of the book “<em>DATABASE SYSTEM CONCEPTS”</em> <a target="_blank" rel="noopener" href="http://codex.cs.yale.edu/avi/db-book/db6/slide-dir/PPT-dir/ch12.ppt">here</a> and t<a target="_blank" rel="noopener" href="http://codex.cs.yale.edu/avi/db-book/db6/slide-dir/PPT-dir/ch13.ppt">here</a>. A good read that focuses on disk I/O cost but a good level in CS is required.</li>
<li>Another <a target="_blank" rel="noopener" href="https://www.informatik.hu-berlin.de/de/forschung/gebiete/wbi/teaching/archive/sose05/dbs2/slides/09_joins.pdf">theoretical course</a> that I find more accessible but that only focuses on join operators and disk I/O.</li>
</ul>
<h2 id="Query-parser"><a href="#Query-parser" class="headerlink" title="Query parser"></a>Query parser</h2><p>Each SQL statement is sent to the parser where it is checked for correct syntax. If you made a mistake in your query the parser will reject the query. For example, if you wrote “SLECT …” instead of “SELECT …”,  the story ends here.</p>
<p>But this goes deeper. It also checks that the keywords are used in the right order. For example a WHERE before a SELECT will be rejected.</p>
<p>Then, the tables and the fields inside the query are analyzed. The parser uses the metadata of the database to check:</p>
<ul>
<li>If the <strong>tables exist</strong></li>
<li>If the <strong>fields</strong> of the tables exist</li>
<li>If the <strong>operations</strong> for the types of the fields <strong>are possible</strong> (for example you can’t compare an integer with a string, you can’t use a substring() function on an integer)</li>
</ul>
<p>Then it checks if you have the <strong>authorizations</strong> to read (or write) the tables in the query. Again, these access rights on tables are set by your DBA.</p>
<p>During this parsing, the SQL query is transformed into an internal representation (often a tree)</p>
<p>If everything is ok then the internal representation is sent to the query rewriter.</p>
<h2 id="Query-rewriter"><a href="#Query-rewriter" class="headerlink" title="Query rewriter"></a>Query rewriter</h2><p>At this step, we have an internal representation of a query. The aim of the rewriter is:</p>
<ul>
<li>to pre-optimize the query</li>
<li>to avoid unnecessary operations</li>
<li>to help the optimizer to find the best possible solution</li>
</ul>
<p>The rewriter executes a list of known rules on the query. If the query fits a pattern of a rule, the rule is applied and the query is rewritten. Here is a non-exhaustive list of (optional) rules:</p>
<ul>
<li><strong>View merging:</strong> If you’re using a view in your query, the view is transformed with the SQL code of the view.</li>
<li><strong>Subquery flattening</strong>: Having subqueries is very difficult to optimize so the rewriter will try to modify a query with a subquery to remove the subquery.</li>
</ul>
<p>For example</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT&#96; &#96;PERSON.*&#96;&#96;FROM&#96; &#96;PERSON&#96;&#96;WHERE&#96; &#96;PERSON.person_key &#96;&#96;IN&#96;&#96;(&#96;&#96;SELECT&#96; &#96;MAILS.person_key&#96;&#96;FROM&#96; &#96;MAILS&#96;&#96;WHERE&#96; &#96;MAILS.mail &#96;&#96;LIKE&#96; &#96;&#39;christophe%&#39;&#96;&#96;);</span><br></pre></td></tr></table></figure>

<p>Will be replaced by</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT&#96; &#96;PERSON.*&#96;&#96;FROM&#96; &#96;PERSON, MAILS&#96;&#96;WHERE&#96; &#96;PERSON.person_key &#x3D; MAILS.person_key&#96;&#96;and&#96; &#96;MAILS.mail &#96;&#96;LIKE&#96; &#96;&#39;christophe%&#39;&#96;&#96;;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>Removal of unnecessary operators</strong>: For example if you use a DISTINCT whereas you have a UNIQUE constraint that prevents the data from being non-unique, the DISTINCT keyword is removed.</li>
<li><strong>Redundant join elimination:</strong> If you have twice the same join condition because one join condition is hidden in a view or if by transitivity there is a useless join, it’s removed.</li>
<li><strong>Constant arithmetic evaluation:</strong> If you write something that requires a calculus, then it’s computed once during the rewriting. For example WHERE AGE &gt; 10+2 is transformed into WHERE AGE &gt; 12 and TODATE(“some date”) is transformed into the date in the datetime format</li>
<li><strong>(**</strong>Advanced) Partition Pruning:** If you’re using a partitioned table, the rewriter is able to find what partitions to use.</li>
<li><strong>(Advanced) Materialized view rewrite</strong>: If you have a materialized view that matches a subset of the predicates in your query, the rewriter checks if the view is up to date and modifies the query to use the materialized view instead of the raw tables.</li>
<li><strong>(Advanced) Custom rules:</strong> If you have custom rules to modify a query (like Oracle policies), then the rewriter executes these rules</li>
<li><strong>(Advanced) Olap transformations</strong>: analytical/windowing functions, star joins, rollup … are also transformed (but I’m not sure if it’s done by the rewriter or the optimizer, since both processes are very close it must depends on the database).</li>
</ul>
<p>This rewritten query is then sent to the query optimizer where the fun begins!</p>
<h2 id="Statistics"><a href="#Statistics" class="headerlink" title="Statistics"></a>Statistics</h2><p>Before we see how a database optimizes a query we need to speak about <strong>statistics</strong> because <strong>without them</strong> <strong>a database is stupid</strong>. If you don’t tell the database to analyze its own data, it will not do it and it will make (very) bad assumptions.</p>
<p>But what kind of information does a database need?</p>
<p>I have to (briefly) talk about how databases and Operating systems store data. They’re using a minimum unit called <strong>a</strong> <strong>page</strong> or a block (4 or 8 kilobytes by default). This means that if you only need 1 Kbytes it will cost you one page anyway. If the page takes 8 Kbytes then you’ll waste 7 Kbytes.</p>
<p>Back to the statistics! When you ask a database to gather statistics, it computes values like:</p>
<ul>
<li>The number of rows/pages in a table</li>
<li>For each column in a table:<ul>
<li>distinct data values</li>
<li>the length of data values (min, max, average)</li>
<li>data range information (min, max, average)</li>
</ul>
</li>
<li>Information on the indexes of the table.</li>
</ul>
<p><strong>These statistics will help the optimizer to estimate the</strong> <strong>disk I/O, CPU and memory usages of the query.</strong></p>
<p>The statistics for each column are very important. For example if a table PERSON needs to be joined on 2 columns: LAST_NAME, FIRST_NAME. With the statistics, the database knows that there are only 1 000 different values on FIRST_NAME and 1 000 000 different values on LAST_NAME. Therefore, the database will join the data on LAST_NAME, FIRST_NAME instead of FIRST_NAME,LAST_NAME because it produces way less comparisons since the LAST_NAME are unlikely to be the same so most of the time a comparison on the 2 (or 3) first characters of the LAST_NAME is enough.</p>
<p>But these are basic statistics. You can ask a database to compute advanced statistics called <strong>histograms</strong>. Histograms are statistics that inform about the distribution of the values inside the columns. For example</p>
<ul>
<li>the most frequent values</li>
<li>the quantiles</li>
<li>…</li>
</ul>
<p>These extra statistics will help the database to find an even better query plan. Especially for equality predicate (ex: WHERE AGE = 18 ) or range predicates (ex: WHERE AGE &gt; 10 and AGE &lt;40 ) because the database will have a better idea of the number rows concerned by these predicates (note: the technical word for this concept is selectivity).</p>
<p>The statistics are stored in the metadata of the database. For example you can see the statistics for the (non-partitioned) tables:</p>
<ul>
<li>in USER/ALL/DBA_TABLES and USER/ALL/DBA_TAB_COLUMNS for Oracle</li>
<li>in SYSCAT.<em>TABLES</em> and <em>SYSCAT.COLUMNS for DB2</em>.</li>
</ul>
<p>The <strong>statistics have to be up to date</strong>. There is nothing worse than a database thinking a table has only 500 rows whereas it has 1 000 000 rows. The only drawback of the statistics is that <strong>it takes time to compute them</strong>. This is why they’re not automatically computed by default in most databases. It becomes difficult with millions of data to compute them. In this case, you can choose to compute only the basics statistics or to compute the stats on a sample of the database.</p>
<p>For example, when I was working on a project dealing with hundreds of millions rows in each tables, I chose to compute the statistics on only 10%, which led to a huge gain in time. For the story it turned out to be a bad decision because occasionally the 10% chosen by Oracle 10G for a specific column of a specific table were very different from the overall 100% (which is very unlikely to happen for a table with 100M rows). This wrong statistic led to a query taking occasionally 8 hours instead of 30 seconds; a nightmare to find the root cause. This example shows how important the statistics are.</p>
<p>Note: Of course, there are more advanced statistics specific for each database. If you want to know more, read the documentations of the databases. That being said, I’ve tried to understand how the statistics are used and the best official documentation I found was the <a target="_blank" rel="noopener" href="http://www.postgresql.org/docs/9.4/static/row-estimation-examples.html">one from PostgreSQL</a>.</p>
<h2 id="Query-optimizer"><a href="#Query-optimizer" class="headerlink" title="Query optimizer"></a>Query optimizer</h2><p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/15-McDonalds_CBO.jpg"><img src="../../public/images/15-McDonalds_CBO-20200207203251382.jpg" alt="CBO"></a></p>
<p>All modern databases are using a <strong>Cost Based Optimization</strong> (or <strong>CBO</strong>) to optimize queries. The idea is to put a cost an every operation and find the best way to reduce the cost of the query by using the cheapest chain of operations to get the result.</p>
<p>To understand how a cost optimizer works I think it’s good to have an example to “feel” the complexity behind this task. In this part I’ll present you the 3 common ways to join 2 tables and we will quickly see that even a simple join query is a nightmare to optimize. After that, we’ll see how real optimizers do this job.</p>
<p>For these joins, I’ll focus on their time complexity but <strong>a</strong> <strong>database optimizer computes</strong> their <strong>CPU cost, disk I/O cost and memory requirement</strong>. The difference between time complexity and CPU cost is that time cost is very approximate (it’s for lazy guys like me). For the CPU cost, I should count every operation like an addition, an “if statement”, a multiplication, an iteration … Moreover:</p>
<ul>
<li>Each high level code operation has a specific number of low level CPU operations.</li>
<li>The cost of a CPU operation is not the same (in terms of CPU cycles) whether you’re using an Intel Core i7, an Intel Pentium 4, an AMD Opteron…. In other words it depends on the CPU architecture.</li>
</ul>
<p>Using the time complexity is easier (at least for me) and with it we can still get the concept of CBO. I’ll sometimes speak about disk I/O since it’s an important concept. Keep in mind that <strong>the bottleneck is most of the time the disk I/O and not the CPU usage</strong>.</p>
<h3 id="Indexes"><a href="#Indexes" class="headerlink" title="Indexes"></a>Indexes</h3><p>We talked about indexes when we saw the B+Trees. Just remember that these <strong>indexes are already sorted</strong>.</p>
<p>FYI, there are other types of indexes like <strong>bitmap indexes</strong>. They don’t offer the same cost in terms of CPU, disk I/O and memory than B+Tree indexes.</p>
<p>Moreover, many modern databases can <strong>dynamically create temporary indexes</strong> just for the current query if it can improve the cost of the execution plan.</p>
<h3 id="Access-Path"><a href="#Access-Path" class="headerlink" title="Access Path"></a>Access Path</h3><p>Before applying your join operators, you first need to get your data. Here is how you can get your data.</p>
<p>Note: Since the real problem with all the access paths is the disk I/O, I won’t talk a lot about time complexity.</p>
<h4 id="Full-scan"><a href="#Full-scan" class="headerlink" title="Full scan"></a>Full scan</h4><p>If you’ve ever read an execution plan you must have seen the word <strong>full scan</strong> (or just scan). A full scan is simply the database reading a table or an index entirely. <strong>In terms of disk I/O, a table full scan is obviously more expensive than an index full scan</strong>.</p>
<h4 id="Range-Scan"><a href="#Range-Scan" class="headerlink" title="Range Scan"></a>Range Scan</h4><p>There are other types of scan like <strong>index range scan</strong>. It is used for example when you use a predicate like “WHERE AGE &gt; 20 AND AGE &lt;40”.</p>
<p>Of course you need have an index on the field AGE to use this index range scan.</p>
<p>We already saw in the first part that the time cost of a range query is something like log(N) +M, where N is the number of data in this index and M an estimation of the number of rows inside this range. <strong>Both N and M values are known thanks to the statistics</strong> (Note: M is the selectivity for the predicate AGE &gt;20 AND AGE&lt;40). Moreover, for a range scan you don’t need to read the full index so it’s <strong>less expensive in terms of disk I/O than a full scan</strong>.</p>
<h4 id="Unique-scan"><a href="#Unique-scan" class="headerlink" title="Unique scan"></a>Unique scan</h4><p>If you only need one value from an index you can use the <strong>unique scan</strong>.</p>
<h4 id="Access-by-row-id"><a href="#Access-by-row-id" class="headerlink" title="Access by row id"></a>Access by row id</h4><p>Most of the time, if the database uses an index, it will have to look for the rows associated to the index. To do so it will use an access by row id.</p>
<p>For example, if you do something like</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT&#96; &#96;LASTNAME, FIRSTNAME &#96;&#96;from&#96; &#96;PERSON &#96;&#96;WHERE&#96; &#96;AGE &#x3D; 28</span><br></pre></td></tr></table></figure>

<p>If you have an index for person on column age, the optimizer will use the index to find all the persons who are 28 then it will ask for the associate rows in the table because the index only has information about the age and you want to know the lastname and the firstname.</p>
<p>But, if now you do something like</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT&#96; &#96;TYPE_PERSON.CATEGORY &#96;&#96;from&#96; &#96;PERSON ,TYPE_PERSON&#96;&#96;WHERE&#96; &#96;PERSON.AGE &#x3D; TYPE_PERSON.AGE</span><br></pre></td></tr></table></figure>

<p>The index on PERSON will be used to join with TYPE_PERSON but the table PERSON will not be accessed by row id since you’re not asking information on this table.</p>
<p>Though it works great for a few accesses, the real issue with this operation is the disk I/O. If you need too many accesses by row id the database might choose a full scan.</p>
<h4 id="Others-paths"><a href="#Others-paths" class="headerlink" title="Others paths"></a>Others paths</h4><p>I didn’t present all the access paths. If you want to know more, you can read the <a target="_blank" rel="noopener" href="https://docs.oracle.com/database/121/TGSQL/tgsql_optop.htm">Oracle documentation</a>. The names might not be the same for the other databases but the concepts behind are the same.</p>
<h3 id="Join-operators"><a href="#Join-operators" class="headerlink" title="Join operators"></a>Join operators</h3><p>So, we know how to get our data, let’s join them!</p>
<p>I’ll present the 3 common join operators: Merge Join, Hash Join and Nested Loop Join. But before that, I need to introduce new vocabulary: <strong>inner relation</strong> and <strong>outer relation</strong>. A relation can be:</p>
<ul>
<li>a table</li>
<li>an index</li>
<li>an intermediate result from a previous operation (for example the result of a previous join)</li>
</ul>
<p>When you’re joining two relations, the join algorithms manage the two relations differently. In the rest of the article, I’ll assume that:</p>
<ul>
<li>the outer relation is the left data set</li>
<li>the inner relation is the right data set</li>
</ul>
<p>For example, A JOIN B is the join between A and B where A is the outer relation and B the inner relation.</p>
<p>Most of the time, <strong>the cost of A JOIN B is not the same as the cost of B JOIN A.</strong></p>
<p><strong>In this part, I’ll also assume that the outer relation has N elements</strong> <strong>and the inner relation M elements</strong>. Keep in mind that a real optimizer knows the values of N and M with the statistics.</p>
<p>Note: N and M are the cardinalities of the relations.</p>
<h4 id="Nested-loop-join"><a href="#Nested-loop-join" class="headerlink" title="Nested loop join"></a>Nested loop join</h4><p>The nested loop join is the easiest one.</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/nested_loop_join.png"><img src="../../public/images/nested_loop_join-20200207203251391.png" alt="nested loop join in databases"></a></p>
<p>Here is the idea:</p>
<ul>
<li>for each row in the outer relation</li>
<li>you look at all the rows in the inner relation to see if there are rows that match</li>
</ul>
<p>Here is a pseudo code:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nested_loop_join(array outer, array inner)&#96;&#96; &#96;&#96;for&#96; &#96;each row a in outer&#96;&#96;  &#96;&#96;for&#96; &#96;each row b in inner&#96;&#96;   &#96;&#96;if&#96; &#96;(match_join_condition(a,b))&#96;&#96;    &#96;&#96;write_result_in_output(a,b)&#96;&#96;   &#96;&#96;end &#96;&#96;if&#96;&#96;  &#96;&#96;end &#96;&#96;for&#96;&#96;  &#96;&#96;end &#96;&#96;for</span><br></pre></td></tr></table></figure>

<p>Since it’s a double iteration, the <strong>time complexity is O(N*M)</strong></p>
<p>In term of disk I/O, for each of the N rows in the outer relation, the inner loop needs to read M rows from the inner relation. This algorithm needs to read N + N<em>M rows from disk. But, if the inner relation is small enough, you can put the relation in memory and just have M +N reads. With this modification, *</em>the inner relation must be the smallest one** since it has more chance to fit in memory.</p>
<p>In terms of time complexity it makes no difference but in terms of disk I/O it’s way better to read only once both relations.   </p>
<p>Of course, the inner relation can be replaced by an index, it will be better for the disk I/O.</p>
<p>Since this algorithm is very simple, here is another version that is more disk I/O friendly if the inner relation is too big to fit in memory. Here is the idea:</p>
<ul>
<li>instead of reading both relation row by row,</li>
<li>you read them bunch by bunch and keep 2 bunches of rows (from each relation) in memory,</li>
<li>you compare the rows inside the two bunches and keep the rows that match,</li>
<li>then you load new bunches from disk and compare them</li>
<li>and so on until there are no bunches to load.</li>
</ul>
<p>Here is a possible algorithm:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; improved version to reduce the disk I&#x2F;O.&#96;&#96;nested_loop_join_v2(file outer, file inner)&#96;&#96; &#96;&#96;for&#96; &#96;each bunch ba in outer&#96;&#96; &#96;&#96;&#x2F;&#x2F; ba is now in memory&#96;&#96;  &#96;&#96;for&#96; &#96;each bunch bb in inner&#96;&#96;    &#96;&#96;&#x2F;&#x2F; bb is now in memory&#96;&#96;    &#96;&#96;for&#96; &#96;each row a in ba&#96;&#96;     &#96;&#96;for&#96; &#96;each row b in bb&#96;&#96;      &#96;&#96;if&#96; &#96;(match_join_condition(a,b))&#96;&#96;       &#96;&#96;write_result_in_output(a,b)&#96;&#96;      &#96;&#96;end &#96;&#96;if&#96;&#96;     &#96;&#96;end &#96;&#96;for&#96;&#96;    &#96;&#96;end &#96;&#96;for&#96;&#96;  &#96;&#96;end &#96;&#96;for&#96;&#96;  &#96;&#96;end &#96;&#96;for</span><br></pre></td></tr></table></figure>



<p><strong>With this version, the time complexity remains the same, but the number of disk access decreases</strong>:</p>
<ul>
<li>With the previous version, the algorithm needs N + N*M accesses (each access gets one row).</li>
<li>With this new version, the number of disk accesses becomes number_of_bunches_for(outer)+ number_of_ bunches_for(outer)* number_of_ bunches_for(inner).</li>
<li>If you increase the size of the bunch you reduce the number of disk accesses.</li>
</ul>
<p>Note: Each disk access gathers more data than the previous algorithm but it doesn’t matter since they’re sequential accesses (the real issue with mechanical disks is the time to get the first data).</p>
<h4 id="Hash-join"><a href="#Hash-join" class="headerlink" title="Hash join"></a>Hash join</h4><p>The hash join is more complicated but gives a better cost than a nested loop join in many situations.</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/hash_join.png"><img src="../../public/images/hash_join-20200207203251391.png" alt="hash join in a database"></a></p>
<p>The idea of the hash join is to:</p>
<ul>
<li>1) Get all elements from the inner relation</li>
<li>2) Build an in-memory hash table</li>
<li>3) Get all elements of the outer relation one by one</li>
<li>4) Compute the hash of each element (with the hash function of the hash table) to find the associated bucket of the inner relation</li>
<li>5) find if there is a match between the elements in the bucket and the element of the outer table</li>
</ul>
<p>In terms of time complexity I need to make some assumptions to simplify the problem:</p>
<ul>
<li>The inner relation is divided into X buckets</li>
<li>The hash function distributes hash values almost uniformly for both relations. In other words the buckets are equally sized.</li>
<li>The matching between an element of the outer relation and all elements inside a bucket costs the number of elements inside the buckets.</li>
</ul>
<p>The time complexity is (M/X) * N + cost_to_create_hash_table(M) + cost_of_hash_function*N</p>
<p>If the Hash function creates enough small-sized buckets then <strong>the time complexity is O(M+N)</strong></p>
<p>Here is another version of the hash join which is more memory friendly but less disk I/O friendly. This time:</p>
<ul>
<li>1) you compute the hash tables for both the inner and outer relations</li>
<li>2) then you put them on disk</li>
<li>3) then you compare the 2 relations bucket by bucket (with one loaded in-memory and the other read row by row)</li>
</ul>
<h4 id="Merge-join"><a href="#Merge-join" class="headerlink" title="Merge join"></a>Merge join</h4><p><strong>The merge join is the only join that produces a sorted result.</strong></p>
<p>Note: In this simplified merge join, there are no inner or outer tables; they both play the same role. But real implementations make a difference, for example, when dealing with duplicates.</p>
<p>The merge join can be divided into of two steps:</p>
<ol>
<li>(Optional) Sort join operations: Both the inputs are sorted on the join key(s).</li>
<li>Merge join operation: The sorted inputs are merged together.</li>
</ol>
<p>Sort</p>
<p>We already spoke about the merge sort, in this case a merge sort in a good algorithm (but not the best if memory is not an issue).</p>
<p>But sometimes the data sets are already sorted, for example:</p>
<ul>
<li>If the table is natively ordered, for example an index-organized table on the join condition</li>
<li>If the relation is an index on the join condition</li>
<li>If this join is applied on an intermediate result already sorted during the process of the query</li>
</ul>
<p>Merge join</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/merge_join.png"><img src="../../public/images/merge_join-20200207203251391.png" alt="merge join in a database"></a></p>
<p>This part is very similar to the merge operation of the merge sort we saw. But this time, instead of picking every element from both relations, we only pick the elements from both relations that are equals. Here is the idea:</p>
<ul>
<li>1) you compare both current elements in the 2 relations (current=first for the first time)</li>
<li>2) if they’re equal, then you put both elements in the result and you go to the next element for both relations</li>
<li>3) if not, you go to the next element for the relation with the lowest element (because the next element might match)</li>
<li>4) and repeat 1,2,3 until you reach the last element of one of the relation.</li>
</ul>
<p>This works because both relations are sorted and therefore you don’t need to “go back” in these relations.</p>
<p>This algorithm is a simplified version because it doesn’t handle the case where the same data appears multiple times in both arrays (in other words a multiple matches). The real version is more complicated “just” for this case; this is why I chose a simplified version.</p>
<p>If both relations are already sorted then <strong>the time complexity is O(N+M)</strong></p>
<p>If both relations need to be sorted then the time complexity is the cost to sort both relations: <strong>O(N*Log(N) + M*Log(M))</strong></p>
<p>For the CS geeks, here is a possible algorithm that handles the multiple matches (note: I’m not 100% sure about my algorithm):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mergeJoin(relation a, relation b)&#96;&#96; &#96;&#96;relation output&#96;&#96; &#96;&#96;integer a_key:&#x3D;&#96;&#96;0&#96;&#96;;&#96;&#96; &#96;&#96;integer b_key:&#x3D;&#96;&#96;0&#96;&#96;;&#96;&#96; &#96; &#96; &#96;&#96;while&#96; &#96;(a[a_key]!&#x3D;&#96;&#96;null&#96; &#96;or b[b_key]!&#x3D;&#96;&#96;null&#96;&#96;)&#96;&#96;  &#96;&#96;if&#96; &#96;(a[a_key] &lt; b[b_key])&#96;&#96;   &#96;&#96;a_key++;&#96;&#96;  &#96;&#96;else&#96; &#96;if&#96; &#96;(a[a_key] &gt; b[b_key])&#96;&#96;   &#96;&#96;b_key++;&#96;&#96;  &#96;&#96;else&#96; &#96;&#x2F;&#x2F;Join predicate satisfied&#96;&#96;  &#96;&#96;&#x2F;&#x2F;i.e. a[a_key] &#x3D;&#x3D; b[b_key]&#96; &#96;   &#96;&#96;&#x2F;&#x2F;count the number of duplicates in relation a&#96;&#96;   &#96;&#96;integer nb_dup_in_a &#x3D; &#96;&#96;1&#96;&#96;:&#96;&#96;   &#96;&#96;while&#96; &#96;(a[a_key]&#x3D;&#x3D;a[a_key+nb_dup_in_a])&#96;&#96;    &#96;&#96;nb_dup_in_a++;&#96;&#96;    &#96; &#96;   &#96;&#96;&#x2F;&#x2F;count the number of duplicates in relation b&#96;&#96;   &#96;&#96;integer dup_in_b &#x3D; &#96;&#96;1&#96;&#96;:&#96;&#96;   &#96;&#96;while&#96; &#96;(b[b_key]&#x3D;&#x3D;b[b_key+nb_dup_in_b])&#96;&#96;    &#96;&#96;nb_dup_in_b++;&#96;&#96;    &#96; &#96;   &#96;&#96;&#x2F;&#x2F;write the duplicates in output&#96;&#96;    &#96;&#96;for&#96; &#96;(&#96;&#96;int&#96; &#96;i &#x3D; &#96;&#96;0&#96; &#96;; i&lt; nb_dup_in_a ; i++)&#96;&#96;     &#96;&#96;for&#96; &#96;(&#96;&#96;int&#96; &#96;j &#x3D; &#96;&#96;0&#96; &#96;; i&lt; nb_dup_in_b ; i++)   &#96;&#96;      &#96;&#96;write_result_in_output(a[a_key+i],b[b_key+j])&#96;&#96;      &#96; &#96;   &#96;&#96;a_key&#x3D;a_key + nb_dup_in_a-&#96;&#96;1&#96;&#96;;&#96;&#96;   &#96;&#96;b_key&#x3D;b_key + nb_dup_in_b-&#96;&#96;1&#96;&#96;;&#96; &#96;  &#96;&#96;end &#96;&#96;if&#96;&#96; &#96;&#96;end &#96;&#96;while</span><br></pre></td></tr></table></figure>



<h4 id="Which-one-is-the-best"><a href="#Which-one-is-the-best" class="headerlink" title="Which one is the best?"></a>Which one is the best?</h4><p>If there was a best type of joins, there wouldn’t be multiple types. This question is very difficult because many factors come into play like:</p>
<ul>
<li>The <strong>amount of free memory</strong>: without enough memory you can say goodbye to the powerful hash join (at least the full in-memory hash join)</li>
<li>The <strong>size of the 2 data sets</strong>. For example if you have a big table with a very small one, a nested loop join will be faster than a hash join because the hash join has an expensive creation of hashes. If you have 2 very large tables the nested loop join will be very CPU expensive.</li>
<li>The <strong>presence</strong> <strong>of</strong> <strong>indexes</strong>. With 2 B+Tree indexes the smart choice seems to be the merge join</li>
<li>If <strong>the result need to be sorted</strong>: Even if you’re working with unsorted data sets, you might want to use a costly merge join (with the sorts) because at the end the result will be sorted and you’ll be able to chain the result with another merge join (or maybe because the query asks implicitly/explicitly for a sorted result with an ORDER BY/GROUP BY/DISTINCT operation)</li>
<li>If <strong>the relations are already sorted</strong>: In this case the merge join is the best candidate</li>
<li>The type of joins you’re doing: is it an <strong>equijoin</strong> (i.e.: tableA.col1 = tableB.col2)? Is it an <strong>inner join</strong>, an <strong>outer join,</strong> a <strong>cartesian product</strong> or a <strong>self-join</strong>? Some joins can’t work in certain situations.</li>
<li>The <strong>distribution of data</strong>. If the data on the join condition are <strong>skewed</strong> (For example you’re joining people on their last name but many people have the same), using a hash join will be a disaster because the hash function will create ill-distributed buckets.</li>
<li>If you want the join to be executed by <strong>multiple threads/process</strong></li>
</ul>
<p>For more information, you can read the <a target="_blank" rel="noopener" href="https://www-01.ibm.com/support/knowledgecenter/SSEPGG_9.7.0/com.ibm.db2.luw.admin.perf.doc/doc/c0005311.html">DB2</a>, <a target="_blank" rel="noopener" href="http://docs.oracle.com/cd/B28359_01/server.111/b28274/optimops.htm#i76330">ORACLE</a> or <a target="_blank" rel="noopener" href="https://technet.microsoft.com/en-us/library/ms191426(v=sql.105).aspx">SQL Server</a> documentations.</p>
<h3 id="Simplified-example"><a href="#Simplified-example" class="headerlink" title="Simplified example"></a>Simplified example</h3><p>We’ve just seen 3 types of join operations.</p>
<p>Now let’s say we need to join 5 tables to have a full view of a person. A PERSON can have:</p>
<ul>
<li>multiple MOBILES</li>
<li>multiple MAILS</li>
<li>multiple ADRESSES</li>
<li>multiple BANK_ACCOUNTS</li>
</ul>
<p>In other words we need a quick answer for the following query:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT&#96; &#96;* &#96;&#96;from&#96; &#96;PERSON, MOBILES, MAILS,ADRESSES, BANK_ACCOUNTS&#96;&#96;WHERE&#96;&#96;PERSON.PERSON_ID &#x3D; MOBILES.PERSON_ID&#96;&#96;AND&#96; &#96;PERSON.PERSON_ID &#x3D; MAILS.PERSON_ID&#96;&#96;AND&#96; &#96;PERSON.PERSON_ID &#x3D; ADRESSES.PERSON_ID&#96;&#96;AND&#96; &#96;PERSON.PERSON_ID &#x3D; BANK_ACCOUNTS.PERSON_ID</span><br></pre></td></tr></table></figure>

<p>As a query optimizer, I have to find the best way to process the data. But there are 2 problems:</p>
<ul>
<li>What kind of join should I use for each join?</li>
</ul>
<p>I have 3 possible joins (Hash Join, Merge Join, Nested Join) with the possibility to use 0,1 or 2 indexes (not to mention that there are different types of indexes).</p>
<ul>
<li>What order should I choose to compute the join?</li>
</ul>
<p>For example, the following figure shows different possible plans for only 3 joins on 4 tables</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/join_ordering_problem.png"><img src="../../public/images/join_ordering_problem-20200207203251393.png" alt="join ordering optimization problem in a database"></a></p>
<p>So here are my possibilities:</p>
<ul>
<li>1) I use a brute force approach</li>
</ul>
<p>Using the database statistics, I <strong>compute the cost for every possible plan</strong> and I keep the best one. But there are many possibilities. For a given order of joins, each join has 3 possibilities: HashJoin, MergeJoin, NestedJoin. So, for a given order of joins there are 34 possibilities. The join ordering is a <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Catalan_number">permutation problem on a binary tree</a> and there are (2<em>4)!/(4+1)! possible orders. For this very simplified problem, I end up with 34</em>(2*4)!/(4+1)! possibilities.</p>
<p>In non-geek terms, it means 27 216 possible plans. If I now add the possibility for the merge join to take 0,1 or 2 B+Tree indexes, the number of possible plans becomes 210 000. Did I forget to mention that this query is VERY SIMPLE?</p>
<ul>
<li>2) I cry and quit this job</li>
</ul>
<p>It’s very tempting but you wouldn’t get your result and I need money to pay the bills.</p>
<ul>
<li>3) I only try a few plans and take the one with the lowest cost.</li>
</ul>
<p>Since I’m not superman, I can’t compute the cost of every plan. Instead, I can <strong>arbitrary choose a subset of all the possible plans</strong>, compute their costs and give you the best plan of this subset.</p>
<ul>
<li>4) I apply smart <strong>rules to reduce the number of possible plans</strong>.</li>
</ul>
<p>There are 2 types of rules:</p>
<p>I can use “logical” rules that will remove useless possibilities but they won’t filter a lot of possible plans. For example: “the inner relation of the nested loop join must be the smallest data set”</p>
<p>I accept not finding the best solution and apply more aggressive rules to reduce a lot the number of possibilities. For example “If a relation is small, use a nested loop join and never use a merge join or a hash join”</p>
<p>In this simple example, I end up with many possibilities. But <strong>a real query can have other relational operators</strong> like OUTER JOIN, CROSS JOIN, GROUP BY, ORDER BY, PROJECTION, UNION, INTERSECT, DISTINCT … <strong>which means even more possibilities</strong>.</p>
<p>So, how a database does it?</p>
<h3 id="Dynamic-programming-greedy-algorithm-and-heuristic"><a href="#Dynamic-programming-greedy-algorithm-and-heuristic" class="headerlink" title="Dynamic programming, greedy algorithm and heuristic"></a>Dynamic programming, greedy algorithm and heuristic</h3><p>A relational database tries the multiple approaches I’ve just said. The real job of an optimizer is to find a good solution on a limited amount of time.</p>
<p><strong>Most of the time an optimizer doesn’t find the best solution but a “good” one</strong>.</p>
<p>For small queries, doing a brute force approach is possible. But there is a way to avoid unnecessary computations so that even medium queries can use the brute force approach. This is called dynamic programming.</p>
<h4 id="Dynamic-Programming"><a href="#Dynamic-Programming" class="headerlink" title="Dynamic Programming"></a>Dynamic Programming</h4><p>The idea behind these 2 words is that many executions plan are very similar. If you look at the following plans:</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/overlapping_trees.png"><img src="../../public/images/overlapping_trees-20200207203251396.png" alt="overlapping trees optimization dynamic programming"></a></p>
<p>They share the same (A JOIN B) subtree. So, instead of computing the cost of this subtree in every plan, we can compute it once, save the computed cost and reuse it when we see this subtree again. More formally, we’re facing an overlapping problem. To avoid the extra-computation of the partial results we’re using memoization.</p>
<p>Using this technique, instead of having a (2<em>N)!/(N+1)! time complexity, we “just” have 3N. In our previous example with 4 joins, it means passing from 336 ordering to 81. If you take a bigger *</em>query with 8 joins** (which is not big)<strong>, it means passing from 57 657 600 to 6561</strong>.</p>
<p>For the CS geeks, here is an algorithm I found on the <a target="_blank" rel="noopener" href="http://codex.cs.yale.edu/avi/db-book/db6/slide-dir/PPT-dir/ch13.ppt">formal course I already gave you</a>. I won’t explain this algorithm so read it only if you already know dynamic programming or if you’re good with algorithms (you’ve been warned!):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">procedure findbestplan(S)&#96;&#96;if&#96; &#96;(bestplan[S].cost infinite)&#96;&#96;  &#96;&#96;return&#96; &#96;bestplan[S]&#96;&#96;&#x2F;&#x2F; else bestplan[S] has not been computed earlier, compute it now&#96;&#96;if&#96; &#96;(S contains only &#96;&#96;1&#96; &#96;relation)&#96;&#96;     &#96;&#96;set bestplan[S].plan and bestplan[S].cost based on the best way&#96;&#96;     &#96;&#96;of accessing S &#96;&#96;&#x2F;* Using selections on S and indices on S *&#x2F;&#96;&#96;   &#96;&#96;else&#96; &#96;for&#96; &#96;each non-empty subset S1 of S such that S1 !&#x3D; S&#96;&#96;  &#96;&#96;P1&#x3D; findbestplan(S1)&#96;&#96;  &#96;&#96;P2&#x3D; findbestplan(S - S1)&#96;&#96;  &#96;&#96;A &#x3D; best algorithm &#96;&#96;for&#96; &#96;joining results of P1 and P2&#96;&#96;  &#96;&#96;cost &#x3D; P1.cost + P2.cost + cost of A&#96;&#96;  &#96;&#96;if&#96; &#96;cost &lt; bestplan[S].cost&#96;&#96;    &#96;&#96;bestplan[S].cost &#x3D; cost&#96;&#96;   &#96;&#96;bestplan[S].plan &#x3D; “execute P1.plan; execute P2.plan;&#96;&#96;         &#96;&#96;join results of P1 and P2 using A”&#96;&#96;return&#96; &#96;bestplan[S]</span><br></pre></td></tr></table></figure>



<p>For bigger queries you can still do a dynamic programming approach but with extra rules (or <strong>heuristics</strong>) to remove possibilities:</p>
<ul>
<li>If we analyze only a certain type of plan (for example: the left-deep trees) we end up with n*2n instead of 3n</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/left-deep-tree.png"><img src="../../public/images/left-deep-tree-20200207203251418.png" alt="left deep tree example"></a></p>
<ul>
<li>If we add logical rules to avoid plans for some patterns (like “if a table as an index for the given predicate, don’t try a merge join on the table but only on the index”) it will reduce the number of possibilities without hurting to much the best possible solution.</li>
<li>If we add rules on the flow (like “perform the join operations BEFORE all the other relational operations”) it also reduces a lot of possibilities.</li>
<li>…</li>
</ul>
<h4 id="Greedy-algorithms"><a href="#Greedy-algorithms" class="headerlink" title="Greedy algorithms"></a>Greedy algorithms</h4><p>But for a very big query or to have a very fast answer (but not a very fast query), another type of algorithms is used, the greedy algorithms.</p>
<p>The idea is to follow a rule (or <strong>heuristic</strong>) to build a query plan in an incremental way. With this rule, a greedy algorithm finds the best solution to a problem one step at a time. The algorithm starts the query plan with one JOIN. Then, at each step, the algorithm adds a new JOIN to the query plan using the same rule.</p>
<p>Let’s take a simple example. Let’s say we have a query with 4 joins on 5 tables (A, B, C, D and E). To simplify the problem we just take the nested join as a possible join. Let’s use the rule “use the join with the lowest cost”</p>
<ul>
<li>we arbitrary start on one of the 5 tables (let’s choose A)</li>
<li>we compute the cost of every join with A (A being the inner or outer relation).</li>
<li>we find that A JOIN B gives the lowest cost.</li>
<li>we then compute the cost of every join with the result of A JOIN B (A JOIN B being the inner or outer relation).</li>
<li>we find that (A JOIN B) JOIN C gives the best cost.</li>
<li>we then compute the cost of every join with the result of the (A JOIN B) JOIN C …</li>
<li>….</li>
<li>At the end we find the plan (((A JOIN B) JOIN C) JOIN D) JOIN E)</li>
</ul>
<p>Since we arbitrary started with A, we can apply the same algorithm for B, then C then D then E. We then keep the plan with the lowest cost.</p>
<p>By the way, this algorithm has a name: it’s called the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Nearest_neighbour_algorithm">Nearest neighbor algorithm</a>.</p>
<p>I won’t go into details, but with a good modeling and a sort in N<em>log(N) this problem can <a target="_blank" rel="noopener" href="http://www.google.fr/url?sa=t&rct=j&q=&esrc=s&source=web&cd=5&cad=rja&uact=8&ved=0CE0QFjAEahUKEwjR8OLUmv3GAhUJuxQKHdU-DAA&url=http%3A%2F%2Fwww.cs.bu.edu%2F~steng%2Fteaching%2FSpring2004%2Flectures%2Flecture3.ppt&ei=hyK3VZGRAYn2UtX9MA&usg=AFQjCNGL41kMNkG5cH">easily be solved</a>. The *</em>cost of this algorithm is in O(N*log(N)) vs O(3N) for the full dynamic programming version**. If you have a big query with 20 joins, it means 26 vs 3 486 784 401, a BIG difference!</p>
<p>The problem with this algorithm is that we assume that finding the best join between 2 tables will give us the best cost if we keep this join and add a new join. But:</p>
<ul>
<li>even if A JOIN B gives the best cost between A, B and C</li>
<li>(A JOIN C) JOIN B might give a better result than (A JOIN B) JOIN C.</li>
</ul>
<p>To improve the result, you can run multiple greedy algorithms using different rules and keep the best plan.</p>
<h4 id="Other-algorithms"><a href="#Other-algorithms" class="headerlink" title="Other algorithms"></a>Other algorithms</h4><p>[If you’re already fed up with algorithms, skip to the next part, what I’m going to say is not important for the rest of the article]</p>
<p>The problem of finding the best possible plan is an active research topic for many CS researchers. They often try to find better solutions for more precise problems/patterns. For example,</p>
<ul>
<li>if the query is a star join (it’s a certain type of multiple-join query), some databases will use a specific algorithm.</li>
<li>if the query is a parallel query, some databases will use a specific algorithm</li>
<li>…</li>
</ul>
<p>Other algorithms are also studied to replace dynamic programming for large queries. Greedy algorithms belong to larger family called <strong>heuristic algorithms</strong>. A greedy algorithm follows a rule (or heuristic), keeps the solution it found at the previous step and “appends” it to find the solution for the current step. Some algorithms follow a rule and apply it in a step-by-step way but don’t always keep the best solution found in the previous step. They are called heuristic algorithms.</p>
<p>For example, <strong>genetic algorithms</strong> follow a rule but the best solution of the last step is not often kept:</p>
<ul>
<li>A solution represents a possible full query plan</li>
<li>Instead of one solution (i.e. plan) there are P solutions (i.e. plans) kept at each step.</li>
<li>0) P query plans are randomly created</li>
<li>1) Only the plans with the best costs are kept</li>
<li>2) These best plans are mixed up to produce P news plans</li>
<li>3) Some of the P new plans are randomly modified</li>
<li>4) The step 1,2,3 are repeated T times</li>
<li>5) Then you keep the best plan from the P plans of the last loop.</li>
</ul>
<p>The more loops you do the better the plan will be.</p>
<p>Is it magic? No, it’s the laws of nature: only the fittest survives!</p>
<p>FYI, genetic algorithms are implemented in <a target="_blank" rel="noopener" href="http://www.postgresql.org/docs/9.4/static/geqo-intro.html">PostgreSQL</a> but I wasn’t able to find if they’re used by default.</p>
<p>There are other heuristic algorithms used in databases like Simulated Annealing, Iterative Improvement, Two-Phase Optimization… But I don’t know if they’re currently used in enterprise databases or if they’re only used in research databases.</p>
<p>For more information, you can read the following research article that presents more possible algorithms: <a target="_blank" rel="noopener" href="http://www.acad.bg/rismim/itc/sub/archiv/Paper6_1_2009.PDF">Review of Algorithms for the Join Ordering Problem in Database Query Optimization</a></p>
<h3 id="Real-optimizers"><a href="#Real-optimizers" class="headerlink" title="Real optimizers"></a>Real optimizers</h3><p>[You can skip to the next part, what I’m going to say is not important]</p>
<p>But, all this blabla is very theoretical. Since I’m a developer and not a researcher, I like <strong>concrete examples</strong>.</p>
<p>Let’s see how the <a target="_blank" rel="noopener" href="https://www.sqlite.org/optoverview.html">SQLite optimizer</a> works. It’s a light database so it uses a simple optimization based on a greedy algorithm with extra-rules to limit the number of possibilities:</p>
<ul>
<li>SQLite chooses to never reorder tables in a CROSS JOIN operator</li>
<li><strong>joins are implemented as nested joins</strong></li>
<li>outer joins are always evaluated in the order in which they occur</li>
<li>…</li>
<li>Prior to version 3.8.0, <strong>SQLite uses the “Nearest Neighbor” greedy algorithm when searching for the best query plan</strong></li>
</ul>
<p>Wait a minute … we’ve already seen this algorithm! What a coincidence!</p>
<ul>
<li>Since version 3.8.0 (released in 2015), SQLite uses the “<a target="_blank" rel="noopener" href="https://www.sqlite.org/queryplanner-ng.html">N Nearest Neighbors</a>” <strong>greedy algorithm</strong> when searching for the best query plan</li>
</ul>
<p>Let’s see how another optimizer does his job. IBM DB2 is like all the enterprise databases but I’ll focus on this one since it’s the last one I’ve really used before switching to Big Data.</p>
<p>If we look at the <a target="_blank" rel="noopener" href="https://www-01.ibm.com/support/knowledgecenter/SSEPGG_9.7.0/com.ibm.db2.luw.admin.perf.doc/doc/r0005278.html">official documentation</a>, we learn that the DB2 optimizer let you use 7 different levels of optimization:</p>
<ul>
<li>Use greedy algorithms for the joins<ul>
<li>0 – minimal optimization, use index scan and nested-loop join and avoid some Query Rewrite</li>
<li>1 – low optimization</li>
<li>2 – full optimization</li>
</ul>
</li>
<li>Use dynamic programming for the joins<ul>
<li>3 – moderate optimization and rough approximation</li>
<li>5 – full optimization, uses all techniques with heuristics</li>
<li>7 – full optimization similar to 5, without heuristics</li>
<li>9 – maximal optimization spare no effort/expense <strong>considers all possible join orders, including Cartesian products</strong></li>
</ul>
</li>
</ul>
<p>We can see that <strong>DB2 uses greedy algorithms and dynamic programming</strong>. Of course, they don’t share the heuristics they use since the query optimizer is the main power of a database.</p>
<p>FYI, <strong>the default level is 5.</strong> By default the optimizer uses the following characteristics:</p>
<ul>
<li><p><strong>All available statistics</strong>, including frequent-value and quantile statistics, are used.</p>
</li>
<li><p><strong>All query rewrite rules</strong> (including materialized query table routing) are applied, except computationally intensive rules that are applicable only in very rare cases.</p>
</li>
<li><p>Dynamic programming join enumeration</p>
</li>
</ul>
<p>  is used, with:</p>
<ul>
<li>Limited use of composite inner relation</li>
<li>Limited use of Cartesian products for star schemas involving lookup tables</li>
</ul>
<ul>
<li>A wide range of access methods is considered, including list prefetch (note: will see what is means), index ANDing (note: a special operation with indexes), and materialized query table routing.</li>
</ul>
<p>By default, <strong>DB2 uses dynamic programming limited by heuristics for the join ordering</strong>.</p>
<p>The others conditions (GROUP BY, DISTINCT…) are handled by simple rules.</p>
<h3 id="Query-Plan-Cache"><a href="#Query-Plan-Cache" class="headerlink" title="Query Plan Cache"></a>Query Plan Cache</h3><p>Since the creation of a plan takes time, most databases store the plan into a <strong>query plan cache</strong> to avoid useless re-computations of the same query plan. It’s kind of a big topic since the database needs to know when to update the outdated plans. The idea is to put a threshold and if the statistics of a table have changed above this threshold then the query plan involving this table is purged from the cache.</p>
<h2 id="Query-executor"><a href="#Query-executor" class="headerlink" title="Query executor"></a>Query executor</h2><p>At this stage we have an optimized execution plan. This plan is compiled to become an executable code. Then, if there are enough resources (memory, CPU) it is executed by the query executor. The operators in the plan (JOIN, SORT BY …) can be executed in a sequential or parallel way; it’s up to the executor. To get and write its data, the query executor interacts with the data manager, which is the next part of the article.</p>
<h1 id="Data-manager"><a href="#Data-manager" class="headerlink" title="Data manager"></a>Data manager</h1><p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/data_manager.png"><img src="../../public/images/data_manager-20200207203251432.png" alt="data manager in databases"></a></p>
<p>At this step, the query manager is executing the query and needs the data from the tables and indexes. It asks the data manager to get the data, but there are 2 problems:</p>
<ul>
<li>Relational databases use a transactional model. So, you can’t get any data at any time because someone else might be using/modifying the data at the same time.</li>
<li><strong>Data retrieval is the slowest operation in a database</strong>, therefore the data manager needs to be smart enough to get and keep data in memory buffers.</li>
</ul>
<p>In this part, we’ll see how relational databases handle these 2 problems. I won’t talk about the way the data manager gets its data because it’s not the most important (and this article is long enough!).</p>
<h2 id="Cache-manager"><a href="#Cache-manager" class="headerlink" title="Cache manager"></a>Cache manager</h2><p>As I already said, the main bottleneck of databases is disk I/O. To improve performance, modern databases use a cache manager.</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/cache_manager.png"><img src="../../public/images/cache_manager-20200207203251433.png" alt="cache manager in databases"></a></p>
<p>Instead of directly getting the data from the file system, the query executor asks for the data to the cache manager. The cache manager has an in-memory cache called <strong>buffer pool</strong>. <strong>Getting data from memory dramatically speeds up a database</strong>. It’s difficult to give an order of magnitude because it depends on the operation you need to do:</p>
<ul>
<li>sequential access (ex: full scan) vs random access (ex: access by row id),</li>
<li>read vs write</li>
</ul>
<p>and the type of disks used by the database:</p>
<ul>
<li>7.2k/10k/15k rpm HDD</li>
<li>SSD</li>
<li>RAID 1/5/…</li>
</ul>
<p>but I’d say <strong>memory is 100 to 100k times faster than disk</strong>.</p>
<p>But, this leads to another problem (as always with databases…). The cache manager needs to get the data in memory BEFORE the query executor uses them; otherwise the query manager has to wait for the data from the slow disks.</p>
<h3 id="Prefetching"><a href="#Prefetching" class="headerlink" title="Prefetching"></a>Prefetching</h3><p>This problem is called prefetching. A query executor knows the data it’ll need because it knows the full flow of the query and has knowledge of the data on disk with the statistics. Here is the idea:</p>
<ul>
<li>When the query executor is processing its first bunch of data</li>
<li>It asks the cache manager to pre-load the second bunch of data</li>
<li>When it starts processing the second bunch of data</li>
<li>It asks the CM to pre-load the third bunch and informs the CM that the first bunch can be purged from cache.</li>
<li>…</li>
</ul>
<p>The CM stores all these data in its buffer pool. In order to know if a data is still needed, the cache manager adds an extra-information about the cached data (called a <strong>latch</strong>).</p>
<p>Sometimes the query executor doesn’t know what data it’ll need and some databases don’t provide this functionality. Instead, they use a speculative prefetching (for example: if the query executor asked for data 1,3,5 it’ll likely ask for 7,9,11 in a near future) or a sequential prefetching (in this case the CM simply loads from disks the next contiguous data after the ones asked).</p>
<p>To monitor how well the prefetching is working, modern databases provide a metric called <strong>buffer/cache hit ratio</strong>. The hit ratio shows how often a requested data has been found in the buffer cache without requiring disk access.</p>
<p>Note: a poor cache hit ratio doesn’t always mean that the cache is ill-working. For more information, you can read the <a target="_blank" rel="noopener" href="http://docs.oracle.com/database/121/TGDBA/tune_buffer_cache.htm">Oracle documentation</a>.</p>
<p>But, a buffer is a <strong>limited</strong> amount of memory. Therefore, it needs to remove some data to be able to load new ones. Loading and purging the cache has a cost in terms of disk and network I/O. If you have a query that is often executed, it wouldn’t be efficient to always load then purge the data used by this query. To handle this problem, modern databases use a buffer replacement strategy.</p>
<h3 id="Buffer-Replacement-strategies"><a href="#Buffer-Replacement-strategies" class="headerlink" title="Buffer-Replacement strategies"></a>Buffer-Replacement strategies</h3><p>Most modern databases (at least SQL Server, MySQL, Oracle and DB2) use an LRU algorithm.</p>
<h4 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h4><p><strong>LRU</strong> stands for <strong>L</strong>east <strong>R</strong>ecently <strong>U</strong>sed. The idea behind this algorithm is to keep in the cache the data that have been recently used and, therefore, are more likely to be used again.</p>
<p>Here is a visual example:</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/LRU.png"><img src="../../public/images/LRU-20200207203251433.png" alt="LRU algorithm in a database"></a></p>
<p>For the sake of comprehension, I’ll assume that the data in the buffer are not locked by latches (and therefore can be removed). In this simple example the buffer can store 3 elements:</p>
<ul>
<li>1: the cache manager uses the data 1 and puts the data into the empty buffer</li>
<li>2: the CM uses the data 4 and puts the data into the half-loaded buffer</li>
<li>3: the CM uses the data 3 and puts the data into the half-loaded buffer</li>
<li>4: the CM uses the data 9. The buffer is full so <strong>data 1 is removed</strong> <strong>since it’s the last recently used data</strong>. Data 9 is added into the buffer</li>
<li>5: the CM uses the data 4. <strong>Data 4 is already in the buffer therefore it becomes the first recently used data again</strong>.</li>
<li>6: the CM uses the data 1. The buffer is full so <strong>data 9 is removed</strong> <strong>since it’s the last recently used data</strong>. Data 1 is added into the buffer</li>
<li>…</li>
</ul>
<p>This algorithm works well but there are some limitations. What if there is a full scan on a large table? In other words, what happens when the size of the table/index is above the size of the buffer? Using this algorithm will remove all the previous values in the cache whereas the data from the full scan are likely to be used only once.</p>
<h4 id="Improvements"><a href="#Improvements" class="headerlink" title="Improvements"></a>Improvements</h4><p>To prevent this to happen, some databases add specific rules. For example according to <a target="_blank" rel="noopener" href="http://docs.oracle.com/database/121/CNCPT/memory.htm#i10221">Oracle documentation</a>:</p>
<blockquote>
<p>“For very large tables, the database typically uses a direct path read, which loads blocks directly […], to avoid populating the buffer cache. For medium size tables, the database may use a direct read or a cache read. If it decides to use a cache read, then the database places the blocks at the end of the LRU list to prevent the scan from effectively cleaning out the buffer cache.”</p>
</blockquote>
<p>There are other possibilities like using an advanced version of LRU called LRU-K. For example SQL Server uses LRU-K for K =2.</p>
<p>This idea behind this algorithm is to take into account more history. With the simple LRU (which is also LRU-K for K=1), the algorithm only takes into account the last time the data was used. With the LRU-K:</p>
<ul>
<li>It takes into account the <strong>K last times the data was used</strong>.</li>
<li><strong>A weight is put</strong> on the number of times the data was used</li>
<li>If a bunch of new data is loaded into the cache, the old but often used data are not removed (because their weights are higher).</li>
<li>But the algorithm can’t keep old data in the cache if they aren’t used anymore.</li>
<li>So the <strong>weights decrease</strong> <strong>over time if the data is not used</strong>.</li>
</ul>
<p>The computation of the weight is costly and this is why SQL Server only uses K=2. This value performs well for an acceptable overhead.</p>
<p>For a more in-depth knowledge of LRU-K, you can read the original research paper (1993): <a target="_blank" rel="noopener" href="http://www.cs.cmu.edu/~christos/courses/721-resources/p297-o_neil.pdf">The LRU-K page replacement algorithm for database disk buffering</a>.</p>
<h4 id="Other-algorithms-1"><a href="#Other-algorithms-1" class="headerlink" title="Other algorithms"></a>Other algorithms</h4><p>Of course there are other algorithms to manage cache like</p>
<ul>
<li>2Q (a LRU-K like algorithm)</li>
<li>CLOCK (a LRU-K like algorithm)</li>
<li>MRU (most recently used, uses the same logic than LRU but with another rule)</li>
<li>LRFU (Least Recently and Frequently Used)</li>
<li>…</li>
</ul>
<p>Some databases let the possibility to use another algorithm than the default one.</p>
<h3 id="Write-buffer"><a href="#Write-buffer" class="headerlink" title="Write buffer"></a>Write buffer</h3><p>I only talked about read buffers that load data before using them. But in a database you also have write buffers that store data and flush them on disk by bunches instead of writing data one by one and producing many single disk accesses.</p>
<p>Keep in mind that buffers store <strong>pages</strong> (the smallest unit of data) and not rows (which is a logical/human way to see data). A page in a buffer pool is <strong>dirty</strong> if the page has been modified and not written on disk. There are multiple algorithms to decide the best time to write the dirty pages on disk but it’s highly linked to the notion of transaction, which is the next part of the article.</p>
<h2 id="Transaction-manager"><a href="#Transaction-manager" class="headerlink" title="Transaction manager"></a>Transaction manager</h2><p>Last but not least, this part is about the transaction manager. We’ll see how this process ensures that each query is executed in its own transaction. But before that, we need to understand the concept of ACID transactions.</p>
<h3 id="I’m-on-acid"><a href="#I’m-on-acid" class="headerlink" title="I’m on acid"></a>I’m on acid</h3><p>An ACID transaction is a <strong>unit of work</strong> that ensures 4 things:</p>
<ul>
<li><strong>Atomicity</strong>: the transaction is “all or nothing”, even if it lasts 10 hours. If the transaction crashes, the state goes back to before the transaction (the transaction is <strong>rolled back</strong>).</li>
<li><strong>Isolation</strong>: if 2 transactions A and B run at the same time, the result of transactions A and B must be the same whether A finishes before/after/during transaction B.</li>
<li><strong>Durability</strong>: once the transaction is <strong>committed</strong> (i.e. ends successfully), the data stay in the database no matter what happens (crash or error).</li>
<li><strong>Consistency</strong>: only valid data (in terms of relational constraints and functional constraints) are written to the database. The consistency is related to atomicity and isolation.</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/dollar_low.jpg"><img src="../../public/images/dollar_low-20200207203251437.jpg" alt="one dollar"></a></p>
<p>During the same transaction, you can run multiple SQL queries to read, create, update and delete data. The mess begins when two transactions are using the same data. The classic example is a money transfer from an account A to an account B. Imagine you have 2 transactions:</p>
<ul>
<li>Transaction 1 that takes 100$ from account A and gives them to account B</li>
<li>Transaction 2 that takes 50$ from account A and gives them to account B</li>
</ul>
<p>If we go back to the <strong>ACID</strong> properties:</p>
<ul>
<li><p><strong>Atomicity</strong> ensures that no matter what happens during T1 (a server crash, a network failure …), you can’t end up in a situation where the 100$ are withdrawn from A and not given to B (this case is an inconsistent state).</p>
</li>
<li><p>I<strong>solation</strong> ensures that if T1 and T2 happen at the same time, in the end A will be taken 150$ and B given 150$ and not, for example, A taken 150$ and B given just $50 because T2 has partially erased the actions of T1 (this case is also an inconsistent state).</p>
</li>
<li><p><strong>Durability</strong> ensures that T1 won’t disappear into thin air if the database crashes just after T1 is committed.</p>
</li>
<li><p><strong>Consistency</strong> ensures that no money is created or destroyed in the system.</p>
</li>
</ul>
<p>[You can skip to the next part if you want, what I’m going to say is not important for the rest of the article]</p>
<p>Many modern databases don’t use a pure isolation as a default behavior because it comes with a huge performance overhead. The SQL norm defines 4 levels of isolation:</p>
<ul>
<li><p><strong>Serializable</strong> (default behaviour in SQLite): The highest level of isolation. Two transactions happening at the same time are 100% isolated. Each transaction has its own “world”.</p>
</li>
<li><p><strong>Repeatable read</strong> (default behavior in MySQL): Each transaction has its own “world” except in one situation. If a transaction ends up successfully and adds new data, these data will be visible in the other and still running transactions. But if A modifies a data and ends up successfully, the modification won’t be visible in the still running transactions. So, this break of isolation between transactions is only about new data, not the existing ones.</p>
</li>
</ul>
<p>For example, if a transaction A does a “SELECT count(1) from TABLE_X” and then a new data is added and committed in TABLE_X by Transaction B, if transaction A does again a count(1) the value won’t be the same.</p>
<p>This is called a <strong>phantom read</strong>.</p>
<ul>
<li><strong>Read committed</strong> (default behavior in Oracle, PostgreSQL and SQL Server): It’s a repeatable read + a new break of isolation. If a transaction A reads a data D and then this data is modified (or deleted) and committed by a transaction B, if A reads data D again it will see the modification (or deletion) made by B on the data.</li>
</ul>
<p>This is called a <strong>non-repeatable read</strong>.</p>
<ul>
<li><strong>Read uncommitted</strong>: the lowest level of isolation. It’s a read committed + a new break of isolation. If a transaction A reads a data D and then this data D is modified by a transaction B (that is not committed and still running), if A reads data D again it will see the modified value. If transaction B is rolled back, then data D read by A the second time doesn’t make no sense since it has been modified by a transaction B that never happened (since it was rolled back).</li>
</ul>
<p>This is called a <strong>dirty read</strong>.</p>
<p>Most databases add their own custom levels of isolation (like the snapshot isolation used by PostgreSQL, Oracle and SQL Server). Moreover, most databases don’t implement all the levels of the SQL norm (especially the read uncommitted level).</p>
<p>The default level of isolation can be overridden by the user/developer at the beginning of the connection (it’s a very simple line of code to add).</p>
<h3 id="Concurrency-Control"><a href="#Concurrency-Control" class="headerlink" title="Concurrency Control"></a>Concurrency Control</h3><p>The real issue to ensure isolation, coherency and atomicity is the <strong>write operations on the same data</strong> (add, update and delete):</p>
<ul>
<li>if all transactions are only reading data, they can work at the same time without modifying the behavior of another transaction.</li>
<li>if (at least) one of the transactions is modifying a data read by other transactions, the database needs to find a way to hide this modification from the other transactions. Moreover, it also needs to ensure that this modification won’t be erased by another transaction that didn’t see the modified data.</li>
</ul>
<p>This problem is a called <strong>concurrency control</strong>.</p>
<p>The easiest way to solve this problem is to run each transaction one by one (i.e. sequentially). But that’s not scalable at all and only one core is working on the multi-processor/core server, not very efficient…</p>
<p>The ideal way to solve this problem is, every time a transaction is created or cancelled:</p>
<ul>
<li>to monitor all the operations of all the transactions</li>
<li>to check if the parts of 2 (or more) transactions are in conflict because they’re reading/modifying the same data.</li>
<li>to reorder the operations inside the conflicting transactions to reduce the size of the conflicting parts</li>
<li>to execute the conflicting parts in a certain order (while the non-conflicting transactions are still running concurrently).</li>
<li>to take into account that a transaction can be cancelled.</li>
</ul>
<p>More formally it’s a scheduling problem with conflicting schedules. More concretely, it’s a very difficult and CPU-expensive optimization problem. Enterprise databases can’t afford to wait hours to find the best schedule for each new transaction event. Therefore, they use less ideal approaches that lead to more time wasted between conflicting transactions.</p>
<h3 id="Lock-manager"><a href="#Lock-manager" class="headerlink" title="Lock manager"></a>Lock manager</h3><p>To handle this problem, most databases are using <strong>locks</strong> and/or <strong>data versioning</strong>. Since it’s a big topic, I’ll focus on the locking part then I’ll speak a little bit about data versioning.</p>
<h4 id="Pessimistic-locking"><a href="#Pessimistic-locking" class="headerlink" title="Pessimistic locking"></a>Pessimistic locking</h4><p>The idea behind locking is:</p>
<ul>
<li>if a transaction needs a data,</li>
<li>it locks the data</li>
<li>if another transaction also needs this data,</li>
<li>it’ll have to wait until the first transaction releases the data.</li>
</ul>
<p>This is called an <strong>exclusive lock</strong>.</p>
<p>But using an exclusive lock for a transaction that only needs to read a data is very expensive since <strong>it forces other transactions that only want to read the same data to wait</strong>. This is why there is another type of lock, the <strong>shared lock</strong>.</p>
<p>With the shared lock:</p>
<ul>
<li>if a transaction needs only to read a data A,</li>
<li>it “shared locks” the data and reads the data</li>
<li>if a second transaction also needs only to read data A,</li>
<li>it “shared locks” the data and reads the data</li>
<li>if a third transaction needs to modify data A,</li>
<li>it “exclusive locks” the data but it has to wait until the 2 other transactions release their shared locks to apply its exclusive lock on data A.</li>
</ul>
<p>Still, if a data as an exclusive lock, a transaction that just needs to read the data will have to wait the end of the exclusive lock to put a shared lock on the data.</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/lock_manager.png"><img src="../../public/images/lock_manager-20200207203251437.png" alt="lock manager in a database"></a></p>
<p>The lock manager is the process that gives and releases locks. Internally, it stores the locks in a hash table (where the key is the data to lock) and knows for each data:</p>
<ul>
<li>which transactions are locking the data</li>
<li>which transactions are waiting for the data</li>
</ul>
<h4 id="Deadlock"><a href="#Deadlock" class="headerlink" title="Deadlock"></a>Deadlock</h4><p>But the use of locks can lead to a situation where 2 transactions are waiting forever for a data:</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/deadlock.png"><img src="../../public/images/deadlock-20200207203251451.png" alt="deadlock with database transactions"></a></p>
<p>In this figure:</p>
<ul>
<li>transaction A has an exclusive lock on data1 and is waiting to get data2</li>
<li>transaction B has an exclusive lock on data2 and is waiting to get data1</li>
</ul>
<p>This is called a <strong>deadlock</strong>.</p>
<p>During a deadlock, the lock manager chooses which transaction to cancel (rollback) in order to remove the deadlock. This decision is not easy:</p>
<ul>
<li>Is it better to kill the transaction that modified the least amount of data (and therefore that will produce the least expensive rollback)?</li>
<li>Is it better to kill the least aged transaction because the user of the other transaction has waited longer?</li>
<li>Is it better to kill the transaction that will take less time to finish (and avoid a possible starvation)?</li>
<li>In case of rollback, how many transactions will be impacted by this rollback?</li>
</ul>
<p>But before making this choice, it needs to check if there are deadlocks.</p>
<p>The hash table can be seen as a graph (like in the previous figures). There is a deadlock if there is a cycle in the graph. Since it’s expensive to check for cycles (because the graph with all the locks is quite big), a simpler approach is often used: using a <strong>timeout</strong>. If a lock is not given within this timeout, the transaction enters a deadlock state.</p>
<p>The lock manager can also check before giving a lock if this lock will create a deadlock. But again it’s computationally expensive to do it perfectly. Therefore, these pre-checks are often a set of basic rules.</p>
<h4 id="Two-phase-locking"><a href="#Two-phase-locking" class="headerlink" title="Two-phase locking"></a>Two-phase locking</h4><p>The <strong>simplest way</strong> to ensure a pure isolation is if a lock is acquired at the beginning of the transaction and released at the end of the transaction. This means that a transaction has to wait for all its locks before it starts and the locks held by a transaction are released when the transaction ends. It works but it <strong>produces a lot of time wasted</strong> to wait for all locks.</p>
<p>A faster way is the <strong>Two-Phase Locking Protocol</strong> (used by DB2 and SQL Server) where a transaction is divided into 2 phases:</p>
<ul>
<li>the <strong>growing phase</strong> where a transaction can obtain locks, but can’t release any lock.</li>
<li>the <strong>shrinking phase</strong> where a transaction can release locks (on the data it has already processed and won’t process again), but can’t obtain new locks.</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/two-phase-locking.png"><img src="../../public/images/two-phase-locking-20200207203251473.png" alt="a problem avoided with two phase locking"></a></p>
<p>The idea behind these 2 simple rules is:</p>
<ul>
<li>to release the locks that aren’t used anymore to reduce the wait time of other transactions waiting for these locks</li>
<li>to prevent from cases where a transaction gets data modified after the transaction started and therefore aren’t coherent with the first data the transaction acquired.</li>
</ul>
<p>This protocol works well except if a transaction that modified a data and released the associated lock is cancelled (rolled back). You could end up in a case where another transaction reads the modified value whereas this value is going to be rolled back. To avoid this problem, <strong>all the exclusive locks must be released at the end of the transaction</strong>.</p>
<h4 id="A-few-words"><a href="#A-few-words" class="headerlink" title="A few words"></a>A few words</h4><p>Of course a real database uses a more sophisticated system involving more types of locks (like intention locks) and more granularities (locks on a row, on a page, on a partition, on a table, on a tablespace) but the idea remains the same.</p>
<p>I only presented the pure lock-based approach. <strong>Data versioning is another way to deal with this problem</strong>.</p>
<p>The idea behind versioning is that:</p>
<ul>
<li>every transaction can modify the same data at the same time</li>
<li>each transaction has its own copy (or version) of the data</li>
<li>if 2 transactions modify the same data, only one modification will be accepted, the other will be refused and the associated transaction will be rolled back (and maybe re-run).</li>
</ul>
<p>It increases the performance since:</p>
<ul>
<li><strong>reader transactions don’t block writer transactions</strong></li>
<li><strong>writer transactions don’t block reader transactions</strong></li>
<li>there is no overhead from the “fat and slow” lock manager</li>
</ul>
<p>Everything is better than locks except when 2 transactions write the same data. Moreover, you can quickly end up with a huge disk space overhead.</p>
<p>Data versioning and locking are two different visions: <strong>optimistic locking vs pessimistic locking</strong>. They both have pros and cons; it really depends on the use case (more reads vs more writes). For a presentation on data versioning, I recommend <a target="_blank" rel="noopener" href="http://momjian.us/main/writings/pgsql/mvcc.pdf">this very good presentation</a> on how PostgreSQL implements multiversion concurrency control.</p>
<p>Some databases like DB2 (until DB2 9.7) and SQL Server (except for snapshot isolation) are only using locks. Other like PostgreSQL, MySQL and Oracle use a mixed approach involving locks and data versioning. I’m not aware of a database using only data versioning (if you know a database based on a pure data versioning, feel free to tell me).</p>
<p>[UPDATE 08/20/2015] I was told by a reader that:</p>
<blockquote>
<p>Firebird and Interbase use versioning without record locking.<br>Versioning has an interesting effect on indexes: sometimes a unique index contains duplicates, the index can have more entries than the table has rows, etc.</p>
</blockquote>
<p>If you read the part on the different levels of isolation, when you increase the isolation level you increase the number of locks and therefore the time wasted by transactions to wait for their locks. This is why most databases don’t use the highest isolation level (Serializable) by default.</p>
<p>As always, you can check by yourself in the documentation of the main databases (for example <a target="_blank" rel="noopener" href="http://dev.mysql.com/doc/refman/5.7/en/innodb-transaction-model.html">MySQL</a>, <a target="_blank" rel="noopener" href="http://www.postgresql.org/docs/9.4/static/mvcc.html">PostgreSQL</a> or <a target="_blank" rel="noopener" href="http://docs.oracle.com/cd/B28359_01/server.111/b28318/consist.htm#i5337">Oracle</a>).</p>
<h3 id="Log-manager"><a href="#Log-manager" class="headerlink" title="Log manager"></a>Log manager</h3><p>We’ve already seen that to increase its performances, a database stores data in memory buffers. But if the server crashes when the transaction is being committed, you’ll lose the data still in memory during the crash, which breaks the Durability of a transaction.</p>
<p>You can write everything on disk but if the server crashes, you’ll end up with the data half written on disk, which breaks the Atomicity of a transaction.</p>
<p><strong>Any modification written by a transaction must be undone or finished</strong>.</p>
<p>To deal with this problem, there are 2 ways:</p>
<ul>
<li><strong>Shadow copies/pages</strong>: Each transaction creates its own copy of the database (or just a part of the database) and works on this copy. In case of error, the copy is removed. In case of success, the database switches instantly the data from the copy with a filesystem trick then it removes the “old” data.</li>
<li><strong>Transaction log</strong>: A transaction log is a storage space. Before each write on disk, the database writes an info on the transaction log so that in case of crash/cancel of a transaction, the database knows how to remove (or finish) the unfinished transaction.</li>
</ul>
<h4 id="WAL"><a href="#WAL" class="headerlink" title="WAL"></a>WAL</h4><p>The shadow copies/pages creates a huge disk overhead when used on large databases involving many transactions. That’s why modern databases use a <strong>transaction log</strong>. The transaction log must be stored on a <strong>stable storage</strong>. I won’t go deeper on storage technologies but using (at least) RAID disks is mandatory to prevent from a disk failure.</p>
<p>Most databases (at least Oracle, <a target="_blank" rel="noopener" href="https://technet.microsoft.com/en-us/library/ms186259(v=sql.105).aspx">SQL Server</a>, <a target="_blank" rel="noopener" href="http://www.ibm.com/developerworks/data/library/techarticle/0301kline/0301kline.html">DB2</a>, <a target="_blank" rel="noopener" href="http://www.postgresql.org/docs/9.4/static/wal.html">PostgreSQL</a>, MySQL and <a target="_blank" rel="noopener" href="https://www.sqlite.org/wal.html">SQLite</a>) deal with the transaction log using the <strong>Write-Ahead Logging protocol</strong> (WAL). The WAL protocol is a set of 3 rules:</p>
<ul>
<li>1) Each modification into the database produces a log record, and <strong>the log record must be written into the transaction log before the data is written on disk</strong>.</li>
<li>2) The log records must be written in order; a log record A that happens before a log record B must but written before B</li>
<li>3) When a transaction is committed, the commit order must be written on the transaction log before the transaction ends up successfully.</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/log_manager.png"><img src="../../public/images/log_manager-20200207203251465.png" alt="log manager in a database"></a></p>
<p>This job is done by a log manager. An easy way to see it is that between the cache manager and the data access manager (that writes data on disk) the log manager writes every update/delete/create/commit/rollback on the transaction log before they’re written on disk. Easy, right?</p>
<p>WRONG ANSWER! After all we’ve been through, you should know that everything related to a database is cursed by the “database effect”. More seriously, the problem is to find a way to write logs while keeping good performances. If the writes on the transaction log are too slow they will slow down everything.</p>
<h4 id="ARIES"><a href="#ARIES" class="headerlink" title="ARIES"></a>ARIES</h4><p>In 1992, IBM researchers “invented” an enhanced version of WAL called ARIES. ARIES is more or less used by most modern databases. The logic might not be the same but the concepts behind ARIES are used everywhere. I put the quotes on invented because, according to this <a target="_blank" rel="noopener" href="http://db.csail.mit.edu/6.830/lectures/lec15-notes.pdf">MIT course</a>, the IBM researchers did “nothing more than writing the good practices of transaction recovery”. Since I was 5 when the ARIES paper was published, I don’t care about this old gossip from bitter researchers. In fact, I only put this info to give you a break before we start this last technical part. I’ve read a huge part of the <a target="_blank" rel="noopener" href="http://www.cs.berkeley.edu/~brewer/cs262/Aries.pdf">research paper on ARIES</a> and I find it very interesting! In this part I’ll only give you an overview of ARIES but I strongly recommend to read the paper if you want a real knowledge.</p>
<p>ARIES stands for <strong>A</strong>lgorithms for <strong>R</strong>ecovery and <strong>I</strong>solation <strong>E</strong>xploiting <strong>S</strong>emantics.</p>
<p>The aim of this technique is double:</p>
<ul>
<li>1) Having <strong>good performances when writing logs</strong></li>
<li>2) Having a fast and <strong>reliable recovery</strong></li>
</ul>
<p>There are multiple reasons a database has to rollback a transaction:</p>
<ul>
<li>Because the user cancelled it</li>
<li>Because of server or network failures</li>
<li>Because the transaction has broken the integrity of the database (for example you have a UNIQUE constraint on a column and the transaction adds a duplicate)</li>
<li>Because of deadlocks</li>
</ul>
<p>Sometimes (for example, in case of network failure), the database can recover the transaction.</p>
<p>How is that possible? To answer this question, we need to understand the information stored in a log record.</p>
<h5 id="The-logs"><a href="#The-logs" class="headerlink" title="The logs"></a>The logs</h5><p>Each <strong>operation (add/remove/modify) during a transaction produces a log</strong>. This log record is composed of:</p>
<ul>
<li><strong>LSN:</strong> A unique <strong>L</strong>og <strong>S</strong>equence <strong>N</strong>umber. This LSN is given in a chronological order*. This means that if an operation A happened before an operation B the LSN of log A will be lower than the LSN of log B.</li>
<li><strong>TransID:</strong> the id of the transaction that produced the operation.</li>
<li><strong>PageID:</strong> the location on disk of the modified data. The minimum amount of data on disk is a page so the location of the data is the location of the page that contains the data.</li>
<li><strong>PrevLSN:</strong> A link to the previous log record produced by the same transaction.</li>
<li><strong>UNDO:</strong> a way to remove the effect of the operation</li>
</ul>
<p>For example, if the operation is an update, the UNDO will store either the value/state of the updated element before the update (physical UNDO) or the reverse operation to go back at the previous state (logical UNDO)**.</p>
<ul>
<li><strong>REDO</strong>: a way replay the operation</li>
</ul>
<p>Likewise, there are 2 ways to do that. Either you store the value/state of the element after the operation or the operation itself to replay it.</p>
<ul>
<li>…: (FYI, an ARIES log has 2 others fields: the UndoNxtLSN and the Type).</li>
</ul>
<p>Moreover, each page on disk (that stores the data, not the log) has id of the log record (LSN) of the last operation that modified the data.</p>
<p>*The way the LSN is given is more complicated because it is linked to the way the logs are stored. But the idea remains the same.</p>
<p>**ARIES uses only logical UNDO because it’s a real mess to deal with physical UNDO.</p>
<p>Note: From my little knowledge, only PostgreSQL is not using an UNDO. It uses instead a garbage collector daemon that removes the old versions of data. This is linked to the implementation of the data versioning in PostgreSQL.</p>
<p>To give you a better idea, here is a visual and simplified example of the log records produced by the query “UPDATE FROM PERSON SET AGE = 18;”. Let’s say this query is executed in transaction 18.</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/ARIES_logs.png"><img src="../../public/images/ARIES_logs-20200207203251473.png" alt="simplified logs of ARIES protocole"></a></p>
<p>Each log has a unique LSN. The logs that are linked belong to the same transaction. The logs are linked in a chronological order (the last log of the linked list is the log of the last operation).</p>
<h5 id="Log-Buffer"><a href="#Log-Buffer" class="headerlink" title="Log Buffer"></a>Log Buffer</h5><p>To avoid that log writing becomes a major bottleneck, a <strong>log buffer</strong> is used.</p>
<p><a target="_blank" rel="noopener" href="http://coding-geek.com/wp-content/uploads/2015/08/ARIES_log_writing.png"><img src="../../public/images/ARIES_log_writing-20200207203251473.png" alt="log writing process in databases"></a></p>
<p>When the query executor asks for a modification:</p>
<ul>
<li>1) The cache manager stores the modification in its buffer.</li>
<li>2) The log manager stores the associated log in its buffer.</li>
<li>3) At this step, the query executor considers the operation is done (and therefore can ask for other modifications)</li>
<li>4) Then (later) the log manager writes the log on the transaction log. The decision when to write the log is done by an algorithm.</li>
<li>5) Then (later) the cache manager writes the modification on disk. The decision when to write data on disk is done by an algorithm.</li>
</ul>
<p><strong>When a transaction is committed, it means that for every operation in the transaction the steps 1, 2, 3,4,5 are done</strong>. Writing in the transaction log is fast since it’s just “adding a log somewhere in the transaction log” whereas writing data on disk is more complicated because it’s “writing the data in a way that it’s fast to read them”.</p>
<h5 id="STEAL-and-FORCE-policies"><a href="#STEAL-and-FORCE-policies" class="headerlink" title="STEAL and FORCE policies"></a>STEAL and FORCE policies</h5><p>For performance reasons the <strong>step 5 might be done after the commit</strong> because in case of crashes it’s still possible to recover the transaction with the REDO logs. This is called a <strong>NO-FORCE policy</strong>.</p>
<p>A database can choose a FORCE policy (i.e. step 5 must be done before the commit) to lower the workload during the recovery.</p>
<p>Another issue is to choose whether <strong>the data are written step-by-step on disk (STEAL policy)</strong> or if the buffer manager needs to wait until the commit order to write everything at once (NO-STEAL). The choice between STEAL and NO-STEAL depends on what you want: fast writing with a long recovery using UNDO logs or fast recovery?</p>
<p>Here is a summary of the impact of these policies on recovery:</p>
<ul>
<li><strong>STEAL/NO-FORCE</strong> <strong>needs UNDO and REDO</strong>: <strong>highest performances</strong> but gives more complex logs and recovery processes (like ARIES). <strong>This is the choice made by most databases</strong>. Note: I read this fact on multiple research papers and courses but I couldn’t find it (explicitly) on the official documentations.</li>
<li>STEAL/ FORCE needs only UNDO.</li>
<li>NO-STEAL/NO-FORCE needs only REDO.</li>
<li>NO-STEAL/FORCE needs nothing: <strong>worst performances</strong> and a huge amount of ram is needed.</li>
</ul>
<h5 id="The-recovery-part"><a href="#The-recovery-part" class="headerlink" title="The recovery part"></a>The recovery part</h5><p>Ok, so we have nice logs, let’s use them!</p>
<p>Let’s say the new intern has crashed the database (rule n°1: it’s always the intern’s fault). You restart the database and the recovery process begins.</p>
<p>ARIES recovers from a crash in three passes:</p>
<ul>
<li><strong>1) The Analysis pass</strong>: The recovery process reads the full transaction log* to recreate the timeline of what was happening during the crash. It determines which transactions to rollback (all the transactions without a commit order are rolled back) and which data needed to be written on disk at the time of the crash.</li>
<li><strong>2) The Redo pass</strong>: This pass starts from a log record determined during analysis, and uses the REDO to update the database to the state it was before the crash.</li>
</ul>
<p>During the redo phase, the REDO logs are processed in a chronological order (using the LSN).</p>
<p>For each log, the recovery process reads the LSN of the page on disk containing the data to modify.</p>
<p>If LSN(page_on_disk)&gt;=LSN(log_record), it means that the data has already been written on disk before the crash (but the value was overwritten by an operation that happened after the log and before the crash) so nothing is done.</p>
<p>If LSN(page_on_disk)&lt;LSN(log_record) then the page on disk is updated.</p>
<p>The redo is done even for the transactions that are going to be rolled back because it simplifies the recovery process (but I’m sure modern databases don’t do that).</p>
<ul>
<li><strong>3) The Undo pass</strong>: This pass rolls back all transactions that were incomplete at the time of the crash. The rollback starts with the last logs of each transaction and processes the UNDO logs in an anti-chronological order (using the PrevLSN of the log records).</li>
</ul>
<p>During the recovery, the transaction log must be warned of the actions made by the recovery process so that the data written on disk are synchronized with what’s written in the transaction log. A solution could be to remove the log records of the transactions that are being undone but that’s very difficult. Instead, ARIES writes compensation logs in the transaction log that delete logically the log records of the transactions being removed.</p>
<p>When a transaction is cancelled “manually” or by the lock manager (to stop a deadlock) or just because of a network failure, then the analysis pass is not needed. Indeed, the information about what to REDO and UNDO is available in 2 in-memory tables:</p>
<ul>
<li>a <strong>transaction table</strong> (stores the state of all current transactions)</li>
<li>a <strong>dirty page table</strong> (stores which data need to be written on disk).</li>
</ul>
<p>These tables are updated by the cache manager and the transaction manager for each new transaction event. Since they are in-memory, they are destroyed when the database crashes.</p>
<p>The job of the analysis phase is to recreate both tables after a crash using the information in the transaction log. <em>To speed up the analysis pass, ARIES provides the notion of *</em>checkpoint**. The idea is to write on disk from time to time the content of the transaction table and the dirty page table and the last LSN at the time of this write so that during the analysis pass, only the logs after this LSN are analyzed.</p>
<h1 id="To-conclude"><a href="#To-conclude" class="headerlink" title="To conclude"></a>To conclude</h1><p>Before writing this article, I knew how big the subject was and I knew it would take time to write an in-depth article about it. It turned out that I was very optimistic and I spent twice more time than expected, but I learned a lot.</p>
<p>If you want a good overview about databases, I recommend reading the research paper “<a target="_blank" rel="noopener" href="http://db.cs.berkeley.edu/papers/fntdb07-architecture.pdf">Architecture of a Database System</a> “. This is a good introduction on databases (110 pages) and for once it’s readable by non-CS guys. This paper helped me a lot to find a plan for this article and it’s not focused on data structures and algorithms like my article but more on the architecture concepts.</p>
<p>If you read this article carefully you should now understand how powerful a database is. Since it was a very long article, let me remind you about what we’ve seen:</p>
<ul>
<li>an overview of the B+Tree indexes</li>
<li>a global overview of a database</li>
<li>an overview of the cost based optimization with a strong focus on join operators</li>
<li>an overview of the buffer pool management</li>
<li>an overview of the transaction management</li>
</ul>
<p>But a database contains even more cleverness. For example, I didn’t speak about some touchy problems like:</p>
<ul>
<li>how to manage clustered databases and global transactions</li>
<li>how to take a snapshot when the database is still running</li>
<li>how to efficiently store (and compress) data</li>
<li>how to manage memory</li>
</ul>
<p>So, think twice when you have to choose between a buggy NoSQL database and a rock-solid relational database. Don’t get me wrong, some NoSQL databases are great. But they’re still young and answering specific problems that concern a few applications.</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Database/" rel="tag">Database</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-The-Best-Programming-Language"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/02/07/The-Best-Programming-Language/"
    >The_Best_Programming_Language</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/02/07/The-Best-Programming-Language/" class="article-date">
  <time datetime="2020-02-08T01:26:11.000Z" itemprop="datePublished">2020-02-07</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>When I want to take a break at work, I sometimes read technology forums. And there is one kind of posts that I really like: the flame wars between programming languages. I like these posts because you can see passionate and smart people who are arguing as if their lives were at play.</p>
<p>These posts have 2 advantages:</p>
<ul>
<li>they make me laugh</li>
<li>I learn new stuff</li>
</ul>
<p>If I had to sum up this kind of posts, it would be something like:</p>
<p>Post Title “Java is the best language” by NewJavaFanBoy</p>
<blockquote>
<p><strong>NewJavaFanBoy</strong>: Java is the best language because of its community. Moreover, it has really cool features like lambdas. Why so many people hate Java?</p>
<p><strong>FormerJavaFanBoy</strong>: Oracle killed Java.</p>
<p><strong>DotNetFanBoy</strong>: The evolution of Java is too slow, C# had lambdas a while ago. Moreover, some critical features like optional and named parameters are not in Java. Now that dotnet is more open sourced and can be run on Linux with Mono, Java is going to die.</p>
<p><strong>TrollRoxxoR</strong>: BecauseJavaDevelopersDontKnowHowToWriteCode</p>
<p><strong>RealG33k</strong>: Both your languages are for kids, C++ is way better but it’s for real developers only. Do you even know what SOLID means?</p>
<p><strong>HipsterGeek</strong>: So old and lame … you should try Node.js, it’s based on asynchronous calls and it’s very fast.</p>
<p><strong>LinusTorvalds</strong>: Pussies, a real developer uses C or assembly. You can’t have performances with those high level shits.</p>
</blockquote>
<p>I hate PHP. I can’t explain why; it must be because I tried to learn it when I was 14 and it messed with my brain. But guess what, you’re reading this post on a server using PHP/NGINX (which is a kickass server by the way). I’m good with Java. So, I could have used a Java framework running on a fast fat JVM. But, WordPress is a great platform. It’s often looked down by purists but it clearly answers my needs. The aim of my blog is not to be the fastest in the world (though it has surprisingly but painfully survived 2 Hacker News and Reddit front pages involving 500 simultaneous connections). I just want a user-friendly interface where I can share my thoughts.</p>
<p>Which leads to my point: there is no best programming language, it depends on the situation.</p>
<p><strong>1) Do you need performances?</strong></p>
<p>If yes, what kind of performances are we talking about?</p>
<ul>
<li>Seconds? Every language can do it!</li>
<li>Milliseconds? Every language with good programmers can do it.</li>
<li>Microseconds? At this step, you can remove all the interpreted languages (like python, which is a good language). I know that a well-tuned JVM with very good Java programmers can do it. I imagine that it’s the same for C#. Of course, a pure-compiled language can deal with that.</li>
</ul>
<p>But in all these cases the programmer’s skills are more important than the language.</p>
<ul>
<li>Nanoseconds? Only assembly or maybe C can deal with that.</li>
</ul>
<p>So, in most situations developers’ skills are what matters.</p>
<p><strong>2) What’s about the ecosystem?</strong></p>
<p>More than the language itself, the ecosystem is important.</p>
<p>I’ve used Visual Studio during my scholarship and I have been amazed by the coherency of Microsoft’s ecosystem.</p>
<p>Now, I’m more an Eclipse guy. Even in the Java community, Eclipse is looked down by purists who now use IntelliJ IDEA. Eclipse is an open source software developed by different people and it’s clearly visible (in a bad way). Compared to the coherency of Visual Studio, you’ll find different logics in the different plugins of Eclipse.</p>
<p>But, if having tools is great, knowing how to use them is better. For example, when I started in Java, I was very slow. I learned by hearth some Eclipse keywords and it’s changed my developer life. I’ve also looked for useful plugins, and Eclipse has plenty of them, because it’s a rich ecosystem.</p>
<p><strong>3) What’s about the online help?</strong></p>
<p>Ok, you’re using your kickass programming language but don’t tell me you know every side of this language by hearth. Having a well known language is useful when you need help. A simple Google or StackOverflow search and you get your answer by Ninja_Guru_666 and I_AM_THE_EXPERT. If you’re more like an in-depth programmer, you can also check for the official documentation assuming it exists for the problem you’re looking for.</p>
<p><strong>4) What are the skills of the team?</strong></p>
<p>If the developers don’t really know how a computer works, using a compiled language is a suicidal move. And, compared to the purists, I don’t see why knowing (exactly) how a computer works makes you a good developer (though, I must admit, it helps; but there are more important skills).</p>
<p>It’s better not using the best tool but a known one. Moreover, many developers are fan boys. Using their preferred language will help them to stay motivated on the project.</p>
<p><strong>5) The business side</strong></p>
<p>An objective point of view is to see what the most in-demand languages are. It doesn’t mean they’re the best but at least you’ll get a job. In this case, Java, C#, PHP, SQL and JavaScript are clearly above all (at least in France).</p>
<p>Moreover, as a technical leader, it’s always good to check the skills in the market before choosing a technology. If you choose the best but rare technology to deal with your problem, good luck for finding skilled developers on the technology.</p>
<p>But what’s true in 2015 might change in 2018. ActionScript was a must have not so long ago. Likewise, with Swift, all the hours spent on Objective C will become obsolete in a few years.</p>
<p>To conclude, I’ll end up with a lame and (I hope) obvious conclusion: there are no best programming languages or best frameworks; what’s best now might not exist tomorrow. A programming language is just a tool; what matters is the way you overcome your problems.</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Language/" rel="tag">Language</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-计算机理论"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/02/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%90%86%E8%AE%BA/"
    >计算机理论</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/02/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%90%86%E8%AE%BA/" class="article-date">
  <time datetime="2020-02-06T21:58:37.000Z" itemprop="datePublished">2020-02-06</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="数据结构和算法"><a href="#数据结构和算法" class="headerlink" title="数据结构和算法"></a>数据结构和算法</h1><p>算法是比较难学习的，而且学习 “ 算法 “ 是需要智商的。数组、链表、哈希表、二叉树、排序算法等一些基础知识，对大多数人来说是没什么问题的。但是一旦进入到路径规划、背包问题、字符串匹配、动态规划、递归遍历等一些比较复杂的问题上，就会让很多人跟不上了，不但跟不上，而且还会非常痛苦。是的，解决算法问题的确是可以区分人类智商的一个比较好的方式，这也是为什么好些公司用算法题当面试题来找到智商比较高的程序员。</p>
<p>然而，在很多时候，我们在工作中却发现根本用不到算法，或是一些基本的算法也没有必要实现，只需要使用一下第三方的库就好了。于是，导致社会上出现很多 “ 算法无用论 “ 的声音。</p>
<p>对此，我想说，算法真的很重要。无论是做业务还是做底层系统，经常需要使用算法处理各种各样的问题。比如，业务上需要用算法比较两个数组中差异的布隆过滤器，或是在做监控系统时实时计算过去一分钟的 P99 统计时的蓄水池算法，或是数据库的 B+ 树索引，还有 Linux 内核中的 epoll 的红黑树，还有在做服务调度里的 “ 背包问题 “ 等都会用算法，真的是会本质上帮助到你，也是会让你非常有成就感的一件事。</p>
<p>虽然算法很难，需要智商，但我还是想鼓励你，这其中是有很多的套路是可以学习的，一旦学会这些套路，你会受益无穷的。</p>
<p>这里有几本书着重推荐一下。</p>
<ul>
<li><strong>基础知识</strong>。《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/10432347/">算法</a>》，是算法领域经典的参考书，不但全面介绍了关于算法和数据结构的必备知识，还给出了每位程序员应知应会的 50 个算法，并提供了实际代码。最不错的是，其深入浅出的算法介绍，让一些比较难的算法也变得容易理解，尤其是书中对红黑树的讲解非常精彩。其中，还有大量的图解，详尽的代码和讲解，也许是最好的数据结构入门图书。不好的是不深，缺乏进一步的算法设计内容，甚至连动态规划都未提及。另外，如果你觉得算法书比较枯燥的话，你可以看看这本有趣的《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/26979890/">算法图解</a>》。</li>
<li><strong>理论加持</strong>。如果说上面这本书偏于实践和工程，而你看完后，对算法和数据结构的兴趣更浓了，那么你可以再看看另一本也是很经典的偏于理论方面的书——《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/20432061/">算法导论</a>》。虽然其中的一些理论知识在《算法》那本书中也有提过，但《算法导论》这本书更为专业一些，是美国计算机科学本科生的教科书。</li>
<li><strong>思维改善</strong>。还有一本叫《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/3227098/">编程珠玑</a>》的书，写这本书的人是世界著名计算机科学家乔恩·本特利（Jon Bentley），被誉为影响算法发展的十位大师之一。你可能不认识这个人，但是你知道他的学生有多厉害吗？一个是 Tcl 语言设计者约翰·奥斯德奥特（John Ousterhout），另一个是 Java 语言设计者詹姆斯·高斯林（James Gosling），还有一个是《算法导论》作者之一查尔斯·雷斯尔森（Charles Leiserson），还有好多好多。这本书也是很经典的算法书，其中都是一些非常实际的问题，并以其独有的洞察力和创造力，来引导读者理解并学会解决这些问题的方法，也是一本可以改善你思维方式的书。</li>
</ul>
<p>然后，你需要去做一些题来训练一下自己的算法能力，这里就要推荐 <a target="_blank" rel="noopener" href="https://leetcode.com/">LeetCode</a> 这个网站了。它是一个很不错的做算法训练的地方。现在也越做越好了。基本上来说，这里会有两类题。</p>
<ul>
<li><strong>基础算法题</strong>。其中有大量的算法题，解这些题都是有套路的，不是用递归（深度优先 DFS，广度优先 BFS），就是要用动态规划（Dynamic Programming），或是折半查找（Binary Search），或是回溯（Back tracing），或是分治法（Divide and Conquer），还有大量的对树、数组、链表、字符串和 hash 表的操作。通过做这些题能让你对这些最基础的算法的思路有非常扎实的了解和训练。</li>
<li><strong>编程题</strong>。比如：atoi，strstr，add two nums，括号匹配，字符串乘法，通配符匹配，文件路径简化，Text Justification，反转单词等，这些题的 Edge Case 和 Corner Case 有很多。这些题需要你想清楚了再干，只要你稍有疏忽，就会有几个 case 让你痛不欲生，而且一不小心就会让你的代码写得又臭又长，无法阅读。通过做这些题，可以非常好地训练你对各种情况的考虑，以及你对程序代码组织的掌控（其实就是其中的状态变量）。</li>
</ul>
<p>我觉得每个程序员都应该花时间和精力做这些题，因为你会从这些题中得到很大的收益。</p>
<p>如果能够把这些算法能力都掌握了，那么你就有很大的概率可以很容易地通过这世界上最优的公司的面试，比如：Google、Amazon、Facebook 之类的公司。对你来说，如果能够进入到这些公司里工作，那么你未来的想像空间也会大得多得多。</p>
<p>最后，我们要知道这个世界上的数据结构和算法很多很多，下面给出了两个网站。</p>
<ul>
<li><strong><a target="_blank" rel="noopener" href="https://www.wikiwand.com/en/List_of_algorithms">List of Algorithms</a></strong> ，这个网站罗列了非常多的算法，完全可以当成一个算法字典，或是用来开阔眼界。</li>
<li>还有一个数据结构动画图的网站 <a target="_blank" rel="noopener" href="https://www.cs.usfca.edu/~galles/visualization/Algorithms.html">Data Structure Visualizations</a>。</li>
</ul>
<h1 id="其它理论基础知识"><a href="#其它理论基础知识" class="headerlink" title="其它理论基础知识"></a>其它理论基础知识</h1><p>下面这些书，基本上是计算机科学系的大学教材。如果你想有科班出生的理论基础，那么这些书是必读的。当然，这些理论基础知识比较枯燥，但我觉得如果你想成为专业的程序员，那么应该要找时间读一下。</p>
<ul>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/1139426/">数据结构与算法分析</a>》，这本书曾被评为 20 世纪顶尖的 30 部计算机著作之一，作者 Mark Allen Weiss 在数据结构和算法分析方面卓有建树，他在数据结构和算法分析等方面的著作尤其畅销，并广受好评，已被世界 500 余所大学用作教材。</li>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/1929984/">数据库系统概念</a>》，它是数据库系统方面的经典教材之一。国际上许多著名大学包括斯坦福大学、耶鲁大学、德克萨斯大学、康奈尔大学、伊利诺伊大学、印度理工学院等都采用本书作为教科书。这本书全面介绍了数据库系统的各种知识，透彻阐释数据库管理的基本概念。不仅讨论了数据库查询语言、模式设计、数据仓库、数据库应用开发、基于对象的数据库和 XML、数据存储和查询、事务管理、数据挖掘与信息检索以及数据库系统体系结构等方面的内容，而且对性能评测标准、性能调整、标准化以及空间与地理数据、事务处理监控等高级应用主题进行了广泛讨论。</li>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/3852290/">现代操作系统</a>》，这本书是操作系统领域的经典之作，书中集中讨论了操作系统的基本原理，包括进程、线程、存储管理、文件系统、输入 / 输出、死锁等，同时还包含了有关计算机安全、多媒体操作系统、掌上计算机操作系统、微内核、多核处理机上的虚拟机以及操作系统设计等方面的内容。</li>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/1391207/">计算机网络</a>》，这本书采用了独创的自顶向下方法，即从应用层开始沿协议栈向下讲解计算机网络的基本原理，强调应用层范例和应用编程接口，内容深入浅出，注重教学方法，理论与实践相结合。新版中还增加了无线和移动网络一章，并扩充了对等网络、BGP、MPLS、网络安全、广播选路和因特网编址及转发方面的材料。是一本不可多得的教科书。</li>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/1148282/">计算机程序的构造和解释</a>》，这本书也很经典，是 MIT 的计算机科学系的教材。这本书中主要证实了很多程序是怎么构造出来的，以及程序的本质是什么。整本书主要是使用 Scheme/Lisp 语言，从数据抽象、过程抽象、迭代、高阶函数等编程和控制系统复杂性的思想，到数据结构和算法，到编译器 / 解释器、编程语言设计。</li>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/3296317/">编译原理</a>》，这本书又叫 “ 龙书 “，其全面、深入地探讨了编译器设计方面的重要主题，包括词法分析、语法分析、语法制导定义和语法制导翻译、运行时刻环境、目标代码生成、代码优化技术、并行性检测以及过程间分析技术，并在相关章节中给出大量的实例。与上一版相比，本书进行了全面的修订，涵盖了编译器开发方面的最新进展。每章中都提供了大量的系统及参考文献。</li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Chinese/" rel="tag">Chinese</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-计算机编程语言"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/02/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"
    >计算机编程语言</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/02/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/" class="article-date">
  <time datetime="2020-02-06T21:55:49.000Z" itemprop="datePublished">2020-02-06</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p><strong>编程语言</strong>。你需要学习 C、C++ 和 Java 这三个工业级的编程语言。为什么说它们是工业级的呢？主要是，C 和 C++ 语言规范都由 ISO 标准化过，而且都有工业界厂商组成的标准化委员会来制定工业标准。次要原因是，它们已经在业界应用于许多重要的生产环境中。</p>
<ul>
<li>C 语言不用多说，现今这个世界上几乎所有重要的软件都跟 C 有直接和间接的关系，操作系统、网络、硬件驱动等等。说得霸气一点儿，这个世界就是在 C 语言之上运行的。</li>
<li>而对于 C++ 来说，现在主流的浏览器、数据库、Microsoft Office、主流的图形界面、著名的游戏引擎等都是用 C++ 编写的。而且，很多公司都用 C++ 开发核心架构，如 Google、腾讯、百度、阿里云等。</li>
<li>而金融电商公司则广泛地使用 Java 语言，因为 Java 的好处太多了，代码稳定性超过 C 和 C++，生产力远超 C 和 C++。有 JVM 在，可以轻松地跨平台，做代码优化，做 AOP 和 IoC 这样的高级技术。以 Spring 为首的由庞大的社区开发的高质量的各种轮子让你只需关注业务，是能够快速搭建企业级应用的不二之选。</li>
</ul>
<p>此外，推荐学习 Go 语言。一方面，Go 语言现在很受关注，它是取代 C 和 C++ 的另一门有潜力的语言。C 语言太原始了，C++ 太复杂了，Java 太高级了，所以 Go 语言就在这个夹缝中出现了。这门语言已经 10 多年了，其已成为云计算领域事实上的标准语言，尤其是在 Docker/Kubernetes 等项目中。Go 语言社区正在不断地从 Java 社区移植各种 Java 的轮子过来，Go 社区现在也很不错。</p>
<p>如果要写一些 PaaS 层的应用，Go 语言会比 C 和 C++ 更好，目前和 Java 有一拼。而且，Go 语言在国内外一些知名公司中有了一定的应用和实践，所以，是可以学习的（参看：《<a target="_blank" rel="noopener" href="https://coolshell.cn/articles/18190.html">Go 语言、Docker 和新技术</a>》一文）。此外，Go 语言语法特别简单，有了 C 和 C++ 的基础，学习 Go 的学习成本基本为零。</p>
<p><strong>理论学科</strong>。你需要学习像算法、数据结构、网络模型、计算机原理等计算机科学专业需要学习的知识。为什么要学好这些理论上的知识呢？</p>
<ul>
<li>其一，这些理论知识可以说是计算机科学这门学科最精华的知识了。说得大一点，这些是人类智慧的精华。你只要想成为高手，这些东西是你必需要掌握和学习的。</li>
<li>其二，当你在解决一些很复杂或是很难的问题时，这些基础理论知识可以帮到你很多。我过去这 20 年从这些基础理论知识中受益匪浅。</li>
<li>其三，这些理论知识的思维方式可以让你有触类旁通，一通百通的感觉。虽然知识比较难啃，但啃过以后，你将获益终生。</li>
</ul>
<p>另外，你千万不要觉得在你的日常工作或是生活当中根本用不上，学了也白学，这样的思维方式千万不要有，因为这是平庸的思维方式。如果你想等我用到了再学也不晚，那么你有必要看一下这篇文章《<a target="_blank" rel="noopener" href="https://coolshell.cn/articles/4235.html">程序员的荒谬之言还是至理名言？</a>》。</p>
<p><strong>系统知识</strong>。系统知识是理论知识的工程实践，这里面有很多很多的细节。比如像 Unix/Linux、TCP/IP、C10K 挑战等这样专业的系统知识。这些知识是你能不能把理论应用到实际项目当中，能不能搞定实际问题的重要知识。</p>
<p>当你在编程的时候，如何和系统进行交互或是获取操作系统的资源，如何进行通讯，当系统出了性能问题，当系统出了故障等，你有大量需要落地的事需要处理和解决。这个时候，这些系统知识就会变得尤为关键和重要了。</p>
<p>这些东西，你可以认为是计算机世界的物理世界，上层无论怎么玩，无论是 Java NIO，还是 Nginx，还是 Node.js，它们都逃脱不掉最下层的限制。所以，你要好好学习这方面的知识。</p>
<h1 id="编程语言"><a href="#编程语言" class="headerlink" title="编程语言"></a>编程语言</h1><h2 id="Java-语言"><a href="#Java-语言" class="headerlink" title="Java 语言"></a>Java 语言</h2><p>学习 Java 语言有以下<strong>入门级的书</strong>（注意：下面一些书在入门篇中有所提及，但为了完整性，还是要在这里提一下，因为可能有朋友是跳着看的）。</p>
<ul>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/26880667/">Java 核心技术：卷 1 基础知识</a>》，这本书本来是 Sun 公司的官方用书，是一本 Java 的入门参考书。对于 Java 初学者来说，是一本非常不错的值得时常翻阅的技术手册。书中有较多地方进行 Java 与 C++ 的比较，因为当时 Java 面世的时候，又被叫作 “C++ Killer”。而我在看这本书的时候，发现书中有很多 C++ 的东西，于是又去学习了 C++。学习 C++ 的时候，发现有很多 C 的东西不懂，又顺着去学习了 C。然后，C -&gt; C++ -&gt; Java 整条线融汇贯通，这对我未来的技术成长有非常大的帮助。</li>
<li>有了上述的入门后，Java 的 Spring 框架是你玩 Java 所无法回避的东西，所以接下来是两本 Spring 相关的书，《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/26767354/">Spring 实战</a>》和《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/26857423/">Spring Boot 实战</a>》。前者是传统的 Spring，后者是新式的微服务的 Spring。如果你只想看一本的话，那么就看后者吧。</li>
</ul>
<p>认真学习前面的书可以让你成功入门 Java，但想要进一步成长，就要看下面我推荐的几本<strong>提升级的书</strong>。</p>
<ul>
<li>接下来，你需要了解了一下如何编写高效的代码，于是必需看一下《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/27047716/">Effective Java</a>》（注意，这里我给的引用是第三版的，也是 2017 年末出版的书），这本书是模仿 Scott Meyers 的经典图书《Effective C++》的。Effective 这种书基本上都是各种经验之谈，所以，这是一本非常不错的书，你一定要读。这里需要推荐一下 <a target="_blank" rel="noopener" href="https://github.com/google/guava">Google Guava 库</a> ，这个库不但是 JDK 的升级库，其中有如：集合（collections）、缓存（caching）、原生类型支持（primitives support）、并发库（concurrency libraries）、通用注解（common annotations）、字符串处理（string processing）、I/O 等库，其还是 Effective Java 这本书中的那些经验的实践代表。</li>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/10484692/">Java 并发编程实战</a>》，是一本完美的 Java 并发参考手册。书中从并发性和线程安全性的基本概念出发，介绍了如何使用类库提供的基本并发构建块，用于避免并发危险、构造线程安全的类及验证线程安全的规则，如何将小的线程安全类组合成更大的线程安全类，如何利用线程来提高并发应用程序的吞吐量，如何识别可并行执行的任务，如何提高单线程子系统的响应性，如何确保并发程序执行预期任务，如何提高并发代码的性能和可伸缩性等内容。最后介绍了一些高级主题，如显式锁、原子变量、非阻塞算法以及如何开发自定义的同步工具类。</li>
<li>了解如何编写出并发的程序，你还需要了解一下如何优化 Java 的性能。我推荐《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/26740520/">Java 性能权威指南</a>》。通过学习这本书，你可以比较大程度地提升性能测试的效果。其中包括：使用 JDK 中自带的工具收集 Java 应用的性能数据，理解 JIT 编译器的优缺点，调优 JVM 垃圾收集器以减少对程序的影响，学习管理堆内存和 JVM 原生内存的方法，了解如何最大程度地优化 Java 线程及同步的性能，等等。看完这本书后，如果你还有余力，想了解更多的底层细节，那么，你有必要去读一下《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/24722612/">深入理解 Java 虚拟机</a>》。</li>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/2130190/">Java 编程思想</a>》，真是一本透着编程思想的书。上面的书让你从微观角度了解 Java，而这本书则可以让你从一个宏观角度了解 Java。这本书和 Java 核心技术的厚度差不多，但这本书的信息密度比较大。所以，读起来是非常耗大脑的，因为它会让你不断地思考。对于想学好 Java 的程序员来说，这是一本必读的书。</li>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/26952826/">精通 Spring 4.x</a>》，也是一本很不错的书，就是有点厚，一共有 800 多页，都是干货。我认为其中最不错的是在分析原理，尤其是针对前面提到的 Spring 技术，应用与原理都讲得很透彻，IOC 和 AOP 也分析得很棒，娓娓道来。其对任何一个技术都分析得很细致和全面，不足之处就是内容太多了，所以导致很厚，但这并不影响它是一本不错的工具书。</li>
</ul>
<p>当然，学 Java 你一定要学面向对象的设计模式，这里就只有一本经典的书《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/1052241/">设计模式</a>》。如果你觉得有点儿难度了，那么可以看一下《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/2243615/">Head First 设计模式</a>》。学习面向对象的设计模式时，你不要迷失在那 23 个设计模式中，你一定要明白这两个原则：</p>
<ul>
<li><strong>Program to an ‘interface’, not an ‘implementation’</strong><ul>
<li>使用者不需要知道数据类型、结构、算法的细节。</li>
<li>使用者不需要知道实现细节，只需要知道提供的接口。</li>
<li>利于抽象、封装，动态绑定，多态。符合面向对象的特质和理念。</li>
</ul>
</li>
<li><strong>Favor ‘object composition’ over ‘class inheritance’</strong><ul>
<li>继承需要给子类暴露一些父类的设计和实现细节。</li>
<li>父类实现的改变会造成子类也需要改变。</li>
<li>我们以为继承主要是为了代码重用，但实际上在子类中需要重新实现很多父类的方法。</li>
<li>继承更多的应该是为了多态。</li>
</ul>
</li>
</ul>
<p>至此，如果你把上面的这些知识都融汇贯通的话，那么，你已是一个高级的 Java 程序员了，我保证你已经超过了绝大多数程序员了。基本上来说，你在技术方面是可以进入到一线公司的，而且还不是一般的岗位，至少是高级程序员或是初级架构师的级别了。</p>
<h2 id="C-C-语言"><a href="#C-C-语言" class="headerlink" title="C/C++ 语言"></a>C/C++ 语言</h2><p>不像我出道那个时候，几乎所有的软件都要用 C 语言来写。现在，可能不会有多少人学习 C 语言了，因为一方面有 Java、Python 这样的高级语言为你屏蔽了很多的底层细节，另一方面也有像 Go 语言这样的新兴语言可以让你更容易地写出来也是高性能的软件。但是，我还是想说，C 语言是你必须学习的语言，因为这个世界上绝大多数编程语言都是 C-like 的语言，也是在不同的方面来解决 C 语言的各种问题。<strong>这里，我想放个比较武断话——如果你不学 C 语言，你根本没有资格说你是一个合格的程序员！</strong></p>
<ul>
<li>这里尤其推荐，已故的 C 语言之父 Dennis M. Ritchie 和著名科学家 Brian W. Kernighan 合作的圣经级的教科书《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/1139336/">C 程序设计语言</a>》。注意，这本书是 C 语言原作者写的，其 C 语言的标准不是我们平时常说的 ANSI 标准，而是原作者的标准，又被叫作 K&amp;R C。但是这本书很轻薄，也简洁，不枯燥，是一本你可以拿着躺在床上看还不会看着看着睡着的书。</li>
<li>然后，还有一本非常经典的 C 语言的书《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/2280547/">C 语言程序设计现代方法</a>》。有人说，这本书配合之前的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/The_C_Programming_Language">The C Programming Language</a> 那本书简真是无敌。我想说，这本书更实用，也够厚，完整覆盖了 C99 标准，习题的质量和水准也比较高。更好的是，探讨了现代编译器的实现，以及和 C++ 的兼容，还揭穿了各种古老的 C 语言的神话和信条……是相当相当干的一本学习 C 语言的书。</li>
</ul>
<p><strong>对了，千万不要看谭浩强的 C 语言的书。各种误导，我大学时就是用这本书学的 C，后来工作时被坑得不行</strong>。</p>
<p>在学习 C 语言的过程中，你一定会感到，C 语言这么底层，而且代码经常性地崩溃，经过一段时间的挣扎，你才开始觉得你从这个烂泥坑里快要爬出来了。但你还需要看看《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/2778632/">C 陷阱与缺陷</a>》这本书，你会发现，这里面的坑不是一般大。</p>
<p>此时，如果你看过我的《编程范式游记》那个系列文章，你可能会发现 C 语言在泛型编程上的各种问题，这个时候我推荐你学习一下 C++ 语言。可能会有很多人觉得我说的 C++ 是个大坑。是的，这是世界目前来说最复杂也是最难的编程语言了。但是，<strong>C++ 是目前世界上范式最多的语言了，其做得最好的范式就是 “ 泛型编程 “，这在静态语言中，是绝对地划时代的一个事</strong>。</p>
<p>所以，你有必要学习一下 C++，看看 C++ 是如何解决 C 语言中的各种问题的。你可以先看看我的这篇文章 “<a target="_blank" rel="noopener" href="https://coolshell.cn/articles/7992.html">C++ 的坑真的多吗？</a>” ，有个基本认识。下面推荐几本 C++ 的书。</p>
<ul>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/25708312/">C++ Primer 中文版</a>》，这本书是久负盛名的 C++ 经典教程。书是有点厚，前面 1/3 讲 C 语言，后面讲 C++。C++ 的知识点实在是太多了，而且又有点晦涩。但是你主要就看几个点，一个是面向对象的多态，一个是模板和重载操作符，以及一些 STL 的东西。看看 C++ 是怎么玩泛型和函数式编程的。</li>
<li>如果你想继续研究，你需要看另外两本更为经典的书《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/5387403/">Effective C++</a>》和《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/5908727/">More Effective C++</a>》。 这两本书不厚，但是我读了 10 多年，每过一段时间再读一下，就会发现有更多的收获。这两本书的内容会随着你经历的丰富而变得丰富，这也是对我影响最大的两本书，其中影响最大的不是书中的那些 C++ 的东西，而是作者的思维方式和不断求真的精神，这真是太赞了。</li>
<li>学习 C/C++ 都是需要好好了解一下编译器到底干了什么事的。就像 Java 需要了解 JVM 一样，所以，这里还有一本非常非常难啃的书你可以挑战一下《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/10427315/">深度探索 C++ 对象模型
</a>》。这本书是非常之经典的，看完后，C++ 对你来说就再也没有什么秘密可言。我以前写过的《<a target="_blank" rel="noopener" href="https://coolshell.cn/articles/12165.html">C++ 虚函数表解析</a>》，还有《<a target="_blank" rel="noopener" href="https://coolshell.cn/articles/12176.html">C++ 对象内存布局</a>》属于这个范畴。</li>
<li>还有 C++ 的作者 Bjarne Stroustrup 写的 <a target="_blank" rel="noopener" href="http://www.stroustrup.com/bs_faq.html">C++ FAQ</a> （<a target="_blank" rel="noopener" href="http://www.stroustrup.com/bsfaqcn.html">中文版</a>），也是非常值得一读的。</li>
</ul>
<h2 id="学习-Go-语言"><a href="#学习-Go-语言" class="headerlink" title="学习 Go 语言"></a>学习 Go 语言</h2><p>C 语言太原始了，C++ 太复杂了，Go 语言是不二之选。有了 C/C++ 的功底，学习 Go 语言非常简单。</p>
<p>首推 <a target="_blank" rel="noopener" href="https://gobyexample.com/">Go by Example</a> 作为你的入门教程。然后，<a target="_blank" rel="noopener" href="https://go101.org/article/101.html">Go 101</a> 也是一个很不错的在线电子书。如果你想看纸书的话，<a target="_blank" rel="noopener" href="https://book.douban.com/subject/26337545/">The Go Programming Language</a> 一书在豆瓣上有 9.2 分，但是国内没有卖的。（当然，我以前也写过两篇入门的供你参考 “<a target="_blank" rel="noopener" href="https://coolshell.cn/articles/8460.html">GO 语言简介（上）- 语法</a>” 和 “<a target="_blank" rel="noopener" href="https://coolshell.cn/articles/8489.html">GO 语言简介（下）- 特性</a>”）。</p>
<p>另外，Go 语言官方的 <a target="_blank" rel="noopener" href="https://golang.org/doc/effective_go.html">Effective Go</a> 是必读的，这篇文章告诉你如何更好地使用 Go 语言，以及 Go 语言中的一些原理。</p>
<p>Go 语言最突出之处是并发编程，Unix 老牌黑客罗勃·派克（Rob Pike）在 Google I/O 上的两个分享，可以让你学习到一些并发编程的模式。</p>
<ul>
<li>Go Concurrency Patterns（ <a target="_blank" rel="noopener" href="https://talks.golang.org/2012/concurrency.slide">幻灯片</a>和<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=f6kdp27TYZs">演讲视频</a>）。</li>
<li>Advanced Go Concurrency Patterns（<a target="_blank" rel="noopener" href="https://talks.golang.org/2013/advconc.slide">幻灯片</a>、<a target="_blank" rel="noopener" href="https://youtu.be/QDDwwePbDtw">演讲视频</a>）。</li>
</ul>
<p>然后，Go 在 GitHub 的 wiki 上有好多不错的学习资源，你可以从中学习到多。比如：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/golang/go/wiki/Articles">Go 精华文章列表</a>。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/golang/go/wiki/Blogs">Go 相关博客列表</a>。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/golang/go/wiki/GoTalks">Go Talks</a>。</li>
</ul>
<p>此外，还有个内容丰富的 Go 资源列表 <a target="_blank" rel="noopener" href="https://github.com/avelino/awesome-go">Awesome Go</a>，推荐看看。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>在编程语言方面，推荐学习 C、C++、Java 和 Go 四门语言，并分别阐释了推荐的原因。</p>
<ul>
<li>我认为，C 语言是必须学习的语言，因为这个世界上绝大多数编程语言都是 C-like 的语言，也是在不同的方面来解决 C 语言的各种问题。</li>
<li>而 C++ 虽然复杂难学，但它几乎是目前世界上范式最多的语言了，其做得最好的范式就是 “ 泛型编程 “，这在静态语言中，是绝对地划时代的一个事。尤其要看看 C++ 是如何解决 C 语言中的各种问题的。</li>
<li>Java 是综合能力最强的语言。其实我是先学了 Java，然后又去学了 C++，之后去学了 C 语言的。C -&gt; C++ -&gt; Java 整条线融汇贯通，这对我未来的技术成长有非常大的帮助。</li>
<li>在文章最末，我推荐了 Go 语言，并给出了相关的学习资料。</li>
</ul>
<p>一个合格的程序员应该掌握几门语言。一方面，这会让你对不同的语言进行比较，让你有更多的思考。另一方面，这也是一种学习能力的培养，会让你对于未来的新技术学习得更快。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Chinese/" rel="tag">Chinese</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-系统知识"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/02/06/%E7%B3%BB%E7%BB%9F%E7%9F%A5%E8%AF%86/"
    >计算机系统知识</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/02/06/%E7%B3%BB%E7%BB%9F%E7%9F%A5%E8%AF%86/" class="article-date">
  <time datetime="2020-02-06T21:50:40.000Z" itemprop="datePublished">2020-02-06</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>首先推荐的是翻译版图书《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/5333562/">深入理解计算机系统</a>》，原书名为《Computer Systems A Programmer’s Perspective》。不过，这本书叫做《程序员所需要了解的计算机知识》更为合适。</p>
<p>本书的最大优点是为程序员描述计算机系统的实现细节，帮助其在大脑中构造一个层次型的计算机系统。从最底层的数据在内存中的表示到流水线指令的构成，到虚拟存储器，到编译系统，到动态加载库，到最后的用户态应用。通过掌握程序是如何映射到系统上，以及程序是如何执行的，你能够更好地理解程序的行为为什么是这样的，以及效率低下是如何造成的。</p>
<p><strong>再强调一下，这本书是程序员必读的一本书！</strong></p>
<p>然后就是美国计算机科学家 <a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/理查德·史蒂文斯">理查德·史蒂文斯（Richard Stevens）</a> 的三套巨经典无比的书。（理查德·史蒂文斯于 1999 年 9 月 1 日离世，终年 48 岁。死因不详，有人说是滑雪意外，有人说是攀岩意外，有人说是滑翔机意外。总之，家人没有透露。大师的 <a target="_blank" rel="noopener" href="http://www.kohala.com/start/">个人主页</a> 今天还可以访问。）</p>
<ul>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/1788421/">Unix 高级环境编程</a>》。</li>
<li>《Unix 网络编程》 <a target="_blank" rel="noopener" href="https://book.douban.com/subject/1500149/">第 1 卷 套接口 API</a> 、<a target="_blank" rel="noopener" href="https://book.douban.com/subject/4118577/">第 2 卷 进程间通信</a> 。</li>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/1088054/">TCP/IP 详解 卷 I 协议</a>》。</li>
</ul>
<p>这几书的地位我就不多说了，你可以自己看相关的书评。但是，这三本书可能都不容易读，一方面是比较厚，另一方面是知识的密度太大了，所以，读起来有点枯燥和乏味。但是，这没办法，你得忍住。</p>
<p>这里要重点说一下《TCP/IP 详解》这本书，是一本很奇怪的书。这本书迄今至少被 <a target="_blank" rel="noopener" href="http://portal.acm.org/citation.cfm?id=161724">近五百篇学术论文引用过</a> 。这本写给工程师看的书居然被各种学院派的论文来引用，也是很神奇的一件事了。而且，虽然理查德·史蒂文斯不是 TCP 的发明人，但是这本书中把这个协议深入浅出地讲出来，还画了几百张时序图，也是令人叹为观止了。</p>
<p>如果你觉得上面这几本经典书比较难啃，你可以试试下面这些通俗易懂的（当然，如果读得懂上面那三本的，下面的这些也就不需要读了）。</p>
<ul>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/4141733/">Linux C 编程一站式学习</a>》。</li>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/25911735/">TCP/IP 网络编程</a>》。</li>
<li>《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/24737674/">图解 TCP/IP</a>》，这本书其实并不是只讲了 TCP/IP，应该是叫《计算机网络》才对，主要是给想快速入门的人看的。</li>
<li>《<a target="_blank" rel="noopener" href="http://www.tcpipguide.com/free/index.htm">The TCP/IP Guide</a>》，这本书在豆瓣上的评分 9.2，这里给的链接是这本书的 HTML 英文免费版的，里面的图画得很精彩。</li>
</ul>
<p>另外，学习网络协议不单只是看书，最好用个抓包工具看看这些网络包是什么样的。所以，这里推荐一本书《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/21691692/">Wireshark 数据包分析实战</a>》。在这本书中，作者结合一些简单易懂的实际网络案例，图文并茂地演示使用 Wireshark 进行数据包分析的技术方法，可以让我们更好地了解和学习网络协议。当然，也拥有了一定的黑客的技能。</p>
<p>看完《Unix 高级环境编程》后，你可以趁热打铁看看《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/25809330/">Linux/Unix 系统编程手册</a>》或是罗伯特·拉姆（Robert Love）的 <a target="_blank" rel="noopener" href="http://igm.univ-mlv.fr/~yahya/progsys/linux.pdf">Linux System Programming 英文电子版</a> 。其中文翻译版<a target="_blank" rel="noopener" href="https://book.douban.com/subject/25828773/">Linux 系统编程</a> 也值得一读，虽然和《Unix 高级环境编程》很像，不过其主要突出的是 Linux 的一些关键技术和相关的系统调用。</p>
<p>关于 TCP 的东西，你还可以看看下面这一系列的文章。</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://www.saminiir.com/lets-code-tcp-ip-stack-1-ethernet-arp/">Let’s code a TCP/IP stack, 1: Ethernet &amp; ARP</a></li>
<li><a target="_blank" rel="noopener" href="http://www.saminiir.com/lets-code-tcp-ip-stack-2-ipv4-icmpv4/">Let’s code a TCP/IP stack, 2: IPv4 &amp; ICMPv4</a></li>
<li><a target="_blank" rel="noopener" href="http://www.saminiir.com/lets-code-tcp-ip-stack-3-tcp-handshake/">Let’s code a TCP/IP stack, 3: TCP Basics &amp; Handshake</a></li>
<li><a target="_blank" rel="noopener" href="http://www.saminiir.com/lets-code-tcp-ip-stack-4-tcp-data-flow-socket-api/">Let’s code a TCP/IP stack, 4: TCP Data Flow &amp; Socket API</a></li>
<li><a target="_blank" rel="noopener" href="http://www.saminiir.com/lets-code-tcp-ip-stack-5-tcp-retransmission/">Let’s code a TCP/IP stack, 5: TCP Retransmission</a></li>
</ul>
<p><strong>对于系统知识，主要有以下一些学习要点。</strong></p>
<ul>
<li>用这些系统知识操作一下文件系统，实现一个可以拷贝目录树的小程序。</li>
<li>用 fork / wait / waitpid 写一个多进程的程序，用 pthread 写一个多线程带同步或互斥的程序。比如，多进程购票的程序。</li>
<li>用 signal / kill / raise / alarm / pause / sigprocmask 实现一个多进程间的信号量通信的程序。</li>
<li>学会使用 gcc 和 gdb 来编程和调试程序（参看《<strong>用 gdb 调试程序</strong>》<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2879">一</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2880">二</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2881">三</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2882">四</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2883">五</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2884">六</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2885">七</a>）。</li>
<li>学会使用 makefile 来编译程序（参看《<strong>跟我一起写 makefile</strong>》<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2886">一</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2887">二</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2888">三</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2889">四</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2890">五</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2891">六</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2892">七</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2893">八</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2894">九</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2895">十</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2896">十一</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2897">十二</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2898">十三</a>、<a target="_blank" rel="noopener" href="https://blog.csdn.net/haoel/article/details/2899">十四</a>）。</li>
<li>Socket 的进程间通信。用 C 语言写一个 1 对 1 的聊天小程序，或是一个简单的 HTTP 服务器。</li>
</ul>
<h1 id="C10K-问题"><a href="#C10K-问题" class="headerlink" title="C10K 问题"></a>C10K 问题</h1><p>然后，当你读完《Unix 网络编程》后，千万要去读一下 “<a target="_blank" rel="noopener" href="http://www.kegel.com/c10k.html">C10K Problem</a> （<a target="_blank" rel="noopener" href="https://www.oschina.net/translate/c10k">中文翻译版</a>）”。提出这个问题的人叫丹·凯格尔（Dan Kegel），目前工作在美国 Google 公司。</p>
<p>他从 1978 年起开始接触计算机编程，是 Winetricks 的作者，也是 Wine 1.0 的管理员，同时也是 Crosstool（ 一个让 gcc/glibc 编译器更易用的工具套件）的作者。还是 Java JSR 51 规范的提交者并参与编写了 Java 平台的 NIO 和文件锁，同时参与了 RFC 5128 标准中有关 NAT 穿越（P2P 打洞）技术的描述和定义。</p>
<p>C10K 问题本质上是操作系统处理大并发请求的问题。对于 Web 时代的操作系统而言，对于客户端过来的大量的并发请求，需要创建相应的服务进程或线程。这些进程或线程多了，导致数据拷贝频繁（缓存 I/O、内核将数据拷贝到用户进程空间、阻塞）， 进程 / 线程上下文切换消耗大，从而导致资源被耗尽而崩溃。这就是 C10K 问题的本质。</p>
<p>了解这个问题，并了解操作系统是如何通过多路复用的技术来解决这个问题的，有助于你了解各种 I/O 和异步模型，这对于你未来的编程和架构能力是相当重要的。</p>
<p>另外，现在，整个世界都在解决 C10M 问题，推荐看看 <a target="_blank" rel="noopener" href="http://highscalability.com/blog/2013/5/13/the-secret-to-10-million-concurrent-connections-the-kernel-i.html">The Secret To 10 Million Concurrent Connections -The Kernel Is The Problem, Not The Solution</a> 一文。</p>
<h1 id="实践项目"><a href="#实践项目" class="headerlink" title="实践项目"></a>实践项目</h1><p>学习完了编程语言、理论学科和系统知识三部分内容，下面就来做几个实践项目，小试牛刀一下。实现语言可以用 C、C++ 或 Java。</p>
<p>实现一个 telnet 版本的聊天服务器，主要有以下需求。</p>
<ul>
<li>每个客户端可以用使用<code>telnet ip:port</code>的方式连接到服务器上。</li>
<li>新连接需要用用户名和密码登录，如果没有，则需要注册一个。</li>
<li>然后可以选择一个聊天室加入聊天。</li>
<li>管理员有权创建或删除聊天室，普通人员只有加入、退出、查询聊天室的权力。</li>
<li>聊天室需要有人数限制，每个人发出来的话，其它所有的人都要能看得到。</li>
</ul>
<p>实现一个简单的 HTTP 服务器，主要有以下需求。</p>
<ul>
<li>解释浏览器传来的 HTTP 协议，只需要处理 URL path。</li>
<li>然后把所代理的目录列出来。</li>
<li>在浏览器上可以浏览目录里的文件和下级目录。</li>
<li>如果点击文件，则把文件打开传给浏览器（浏览器能够自动显示图片、PDF，或 HTML、CSS、JavaScript 以及文本文件）。</li>
<li>如果点击子目录，则进入到子目录中，并把子目录中的文件列出来。</li>
</ul>
<p>实现一个生产者 / 消费者消息队列服务，主要有以下需求。</p>
<ul>
<li>消息队列采用一个 Ring-buffer 的数据结构。</li>
<li>可以有多个 topic 供生产者写入消息及消费者取出消息。</li>
<li>需要支持多个生产者并发写。</li>
<li>需要支持多个消费者消费消息（只要有一个消费者成功处理消息就可以删除消息）。</li>
<li>消息队列要做到不丢数据（要把消息持久化下来）。</li>
<li>能做到性能很高。</li>
</ul>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>学习完了专业编程方面最为重要的三部分内容：编程语言、理论学科和系统知识，针对这些内容做个小结。如果想看完推荐的那些书和知识，并能理解和掌握，估计怎么也得需要 4-5 年的时间。嗯，是的，就是一个计算机科学系科班出身的程序员需要学习的一些东西。这其中，最重要的是下面这几点。</p>
<p><strong>编程语言</strong>。以工业级的 C、C++、Java 这三门语言为主，这三门语言才是真正算得上工业级的编程语言，因为有工业级的标准化组织在控制着这几门语言，而且也有工业级的企业应用。尤其是 Java，还衍生出了大量的企业级架构上的开源生态。你至少需要掌握 C 语言和 Java 语言，这对你以后面对各式各样的编程语言是非常重要的。</p>
<p>此外，还推荐学习 Go 语言，它已成为云计算领域事实上的标准语言，尤其是在 Docker、Kubernetes 等项目中。而且，Go 语言在国内外一些知名公司中有了一定的应用和实践，并且其生态圈也越来越好。</p>
<p><strong>算法和数据结构</strong>。这个太重要了，尤其是最基础的算法和数据结构，这是任何一个称职的程序员都需要学习和掌握的。你必需要掌握。</p>
<p><strong>计算机的相关系统</strong>。你至少要掌握三个系统的基础知识，一个是操作系统，一个是网络系统，还有一个是数据库系统。它们分别代表着计算机基础构架的三大件——计算、存储、网络。</p>
<p>如果你能够走到这里，把前面的那些知识都了解了（不用精通，因为精通是需要时间和实践来慢慢锤炼出来的，所以，你也不用着急），那么你已经是一个非常非常合格的程序员了，而且你的潜力和可能性是非常非常高的。</p>
<p>如果经历过这些比较枯燥的理论知识，而且你还能有热情和成就感，那么我要恭喜你了。因为你已经超过了绝大多数人，而且还是排在上游的比较抢手的程序员了。我相信你至少可以找到年薪 50 万以上的工作了。</p>
<p>但是，你还需要很多的经验或是一些实践，以及一些大系统大项目的实际动手的经验。没关系，我们后面会有教你怎么实操的方法和攻略。</p>
<p>但是，往后面走，你需要开始需要术业有专攻了。下面给一些建议的方向。</p>
<ul>
<li><strong>底层方向</strong>：操作系统、文件系统、数据库、网络……</li>
<li><strong>架构方向</strong>：分布式系统架构、微服务、DevOps、Cloud Native……</li>
<li><strong>数据方向</strong>：大数据、机器学习、人工智能……</li>
<li><strong>前端方向</strong>：你对用户体验或是交互更感兴趣，那么你走前端的路吧。</li>
<li><strong>其它方向</strong>：比如，安全开发、运维开发、嵌入式开发……</li>
</ul>
<p>这些方向你要仔细选择，因为一旦选好，就要勇往直前地走下去，当然，你要回头转别的方向也没什么问题，因为你有前面的这些基础知识在身，所以，不用害怕。只是不同的方向上会有不同的经验积累，经验积累是看书看不来的，这个是转方向的成本。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Chinese/" rel="tag">Chinese</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-数据库"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/02/05/%E6%95%B0%E6%8D%AE%E5%BA%93/"
    >数据库</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/02/05/%E6%95%B0%E6%8D%AE%E5%BA%93/" class="article-date">
  <time datetime="2020-02-05T21:26:32.000Z" itemprop="datePublished">2020-02-05</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>对于数据库方向，重点就是两种数据库，一种是以 SQL 为代表的关系型数据库，另一种是以非 SQL 为代表的 NoSQL 数据库。关系型数据库主要有三个：Oracle、MySQL 和 Postgres。</p>
<p>在这里，只讨论越来越主流的 MySQL 数据库。首先，我们要了解数据库的一些实现原理和内存的一些细节，然后我们要知道数据的高可用和数据复制这些比较重要的话题，了解一下关系型数据库的一些实践和难点。然后，我们会进入到 NoSQL 数据库的学习。</p>
<p>NoSQL 数据库千奇百怪，其主要是解决了关系型数据库中的各种问题。第一个大问题就是数据的 Schema 非常多，用关系型数据库来表示不同的 Data Schema 是非常笨拙的，所以要有不同的数据库（如时序型、键值对型、搜索型、文档型、图结构型等）。另一个大问题是，关系型数据库的 ACID 是一件很讨厌的事，这极大地影响了数据库的性能和扩展性，所以 NoSQL 在这上面做了相应的妥协以解决大规模伸缩的问题。</p>
<p>对于一个程序员，你可能觉得数据库的事都是 DBA 的事，然而，这些事才真正是程序员的事。因为程序是需要和数据打交道的，所以程序员或架构师不仅需要设计数据模型，还要保证整体系统的稳定性和可用性，数据是整个系统中关键中的关键。所以，作为一个架构师或程序员，你必须了解最重要的数据存储——数据库。</p>
<h1 id="关系型数据库"><a href="#关系型数据库" class="headerlink" title="关系型数据库"></a>关系型数据库</h1><p>今天，关系型数据库最主要的两个代表是闭源的 Oracle 和开源的 MySQL。当然，还有很多了，比如微软的 SQL Server，IBM 的 DB2 等，还有开源的 PostgreSQL。关系型数据库的世界中有好多好多产品。当然，还是 Oracle 和 MySQL 是比较主流的。所以，这里主要介绍更为开放和主流的 MySQL。</p>
<p>如果你要玩 Oracle，这里只推荐一本书《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/5402711/">Oracle Database  编程艺术</a>》，无论是开发人员还是 DBA，它都是必读的书。这本书的作者是 Oracle 公司的技术副总裁托马斯·凯特（Thomas Kyte），他也是世界顶级的 Oracle 专家。</p>
<p>这本书中深入分析了 Oracle 数据库体系结构，包括文件、内存结构以及构成 Oracle 数据库和实例的底层进程，利用具体示例讨论了一些重要的数据库主题，如锁定、并发控制、事务等。同时分析了数据库中的物理结构，如表、索引和数据类型，并介绍采用哪些技术能最优地使用这些物理结构。</p>
<ul>
<li><p>学习 MySQL，首先一定是要看<a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/">MySQL 官方手册</a>。</p>
</li>
<li><p>然后，官方还有几个 PPT 也要学习一下。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.mysql.com/cn/why-mysql/presentations/tune-mysql-queries-performance/">How to Analyze and Tune MySQL Queries for Better Performance</a></li>
<li><a target="_blank" rel="noopener" href="https://www.mysql.com/cn/why-mysql/presentations/mysql-performance-tuning101/">MySQL Performance Tuning 101</a></li>
<li><a target="_blank" rel="noopener" href="https://www.mysql.com/cn/why-mysql/presentations/mysql-performance-sys-schema/">MySQL Performance Schema &amp; Sys Schema</a></li>
<li><a target="_blank" rel="noopener" href="https://www.mysql.com/cn/why-mysql/presentations/mysql-performance-tuning-best-practices/">MySQL Performance: Demystified Tuning &amp; Best Practices</a></li>
<li><a target="_blank" rel="noopener" href="https://www.mysql.com/cn/why-mysql/presentations/mysql-security-best-practices/">MySQL Security Best Practices</a></li>
<li><a target="_blank" rel="noopener" href="https://www.mysql.com/cn/why-mysql/presentations/mysql-cluster-deployment-best-practices/">MySQL Cluster Deployment Best Practices</a></li>
<li><a target="_blank" rel="noopener" href="https://www.mysql.com/cn/why-mysql/presentations/mysql-high-availability-innodb-cluster/">MySQL High Availability with InnoDB Cluster</a></li>
</ul>
</li>
<li><p>然后推荐《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/23008813/">高性能 MySQL</a>》，这本书是 MySQL 领域的经典之作，拥有广泛的影响力。不但适合数据库管理员（DBA）阅读，也适合开发人员参考学习。不管是数据库新手还是专家，都能从本书中有所收获。</p>
</li>
<li><p>如果你对 MySQL 的内部原理有兴趣的话，可以看一下这本书《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/24708143/">MySQL 技术内幕：InnoDB 存储引擎</a>》。当然，还有官网的<a target="_blank" rel="noopener" href="https://dev.mysql.com/doc/internals/en/">MySQL Internals Manual</a> 。</p>
</li>
<li><p>数据库的索引设计和优化也是非常关键的，这里还有一本书《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/26419771/">数据库的索引设计与优化</a>》也是很不错的。虽然不是讲 MySQL 的，但是原理都是相通的。这也是上面推荐过的《高性能 MySQL》在其索引部分推荐的一本好书。</p>
<p>你千万不要觉得只有做数据库你才需要学习这种索引技术。不是的！在系统架构上，在分布式架构中，索引技术也是非常重要的。这本书对于索引性能进行了非常清楚的估算，不像其它书中只是模糊的描述，你一定会收获很多。</p>
</li>
</ul>
<p>下面还有一些不错的和 MySQL 相关的文章。</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://blog.codinglabs.org/articles/theory-of-mysql-index.html">MySQL 索引背后的数据结构及算法原理</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@kousiknath/data-structures-database-storage-internals-1f5ed3619d43">Some study on database storage internals</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@Pinterest_Engineering/sharding-pinterest-how-we-scaled-our-mysql-fleet-3f341e96ca6f">Sharding Pinterest: How we scaled our MySQL fleet</a></li>
<li><a target="_blank" rel="noopener" href="https://www.mysql.com/cn/why-mysql/white-papers/mysql-guide-to-high-availability-solutions/">Guide to MySQL High Availability</a></li>
<li><a target="_blank" rel="noopener" href="https://dzone.com/articles/choosing-mysql-high-availability-solutions">Choosing MySQL High Availability Solutions</a></li>
<li><a target="_blank" rel="noopener" href="https://mariadb.com/sites/default/files/content/Whitepaper_High_availability_with_MariaDB-TX.pdf">High availability with MariaDB TX: The definitive guide</a></li>
</ul>
<p>最后，还有一个 MySQL 的资源列表 <a target="_blank" rel="noopener" href="https://shlomi-noach.github.io/awesome-mysql/">Awesome MySQL</a>，这个列表中有很多的工具和开发资源，可以帮助你做很多事。</p>
<p>MySQL 有两个比较有名的分支，一个是 Percona，另一个是 MariaDB，其官网上的 Resources 页面中有很多不错的资源和文档，可以经常看看。 <a target="_blank" rel="noopener" href="https://www.percona.com/resources">Percona Resources</a>、<a target="_blank" rel="noopener" href="https://mariadb.com/resources">MariaDB Resources</a> ，以及它们的开发博客中也有很多不错的文章，分别为 <a target="_blank" rel="noopener" href="https://www.percona.com/blog/">Percona Blog</a> 和 <a target="_blank" rel="noopener" href="https://mariadb.com/resources/blog">MariaDB Blog</a>。</p>
<p>然后是关于 MySQL 的一些相关经验型的文章。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.percona.com/live/mysql-conference-2015/sessions/bookingcom-evolution-mysql-system-design">Booking.com: Evolution of MySQL System Design</a> ，Booking.com 的 MySQL 数据库使用的演化，其中有很多不错的经验分享，也是很多公司会遇到的的问题。</li>
<li><a target="_blank" rel="noopener" href="https://medium.com/airbnb-engineering/tracking-the-money-scaling-financial-reporting-at-airbnb-6d742b80f040">Tracking the Money - Scaling Financial Reporting at Airbnb</a> ，Airbnb 的数据库扩展的经验分享。</li>
<li><a target="_blank" rel="noopener" href="https://eng.uber.com/mysql-migration/">Why Uber Engineering Switched from Postgres to MySQL</a> ，无意比较两个数据库谁好谁不好，推荐这篇 Uber 的长文，主要是想让你从中学习到一些经验和技术细节，这是一篇很不错的文章。</li>
</ul>
<p>关于 MySQL 的集群复制，下面有这些文章供你学习一下，都是很不错的实践性比较强的文章。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://engineering.imvu.com/2013/01/09/monitoring-delayed-replication-with-a-focus-on-mysql/">Monitoring Delayed Replication, With A Focus On MySQL</a></li>
<li><a target="_blank" rel="noopener" href="https://githubengineering.com/mitigating-replication-lag-and-reducing-read-load-with-freno/">Mitigating replication lag and reducing read load with freno</a></li>
<li>另外，Booking.com 给了一系列的文章可以看看：<ul>
<li><a target="_blank" rel="noopener" href="https://medium.com/booking-com-infrastructure/better-parallel-replication-for-mysql-14e2d7857813">Better Parallel Replication for MySQL</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/booking-com-infrastructure/evaluating-mysql-parallel-replication-part-2-slave-group-commit-459026a141d2">Evaluating MySQL Parallel Replication Part 2: Slave Group Commit</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/booking-com-infrastructure/evaluating-mysql-parallel-replication-part-3-benchmarks-in-production-db5811058d74">Evaluating MySQL Parallel Replication Part 3: Benchmarks in Production</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/booking-com-infrastructure/evaluating-mysql-parallel-replication-part-4-more-benchmarks-in-production-49ee255043ab">Evaluating MySQL Parallel Replication Part 4: More Benchmarks in Production
</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/booking-com-infrastructure/evaluating-mysql-parallel-replication-part-4-annex-under-the-hood-eb456cf8b2fb">Evaluating MySQL Parallel Replication Part 4, Annex: Under the Hood</a></li>
</ul>
</li>
</ul>
<p>对于 MySQL 的数据分区来说，还有下面几篇文章你可以看看。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/5541421/mysql-sharding-approaches">StackOverflow: MySQL sharding approaches?</a></li>
<li><a target="_blank" rel="noopener" href="https://www.percona.com/blog/2009/08/06/why-you-dont-want-to-shard/">Why you don’t want to shard</a></li>
<li>[How to Scale Big Data Applications](<a target="_blank" rel="noopener" href="https://www.percona.com/sites/default/files/presentations/How">https://www.percona.com/sites/default/files/presentations/How</a> to Scale Big Data Applications.pdf)</li>
<li><a target="_blank" rel="noopener" href="https://www.percona.com/blog/2016/08/30/mysql-sharding-with-proxysql/">MySQL Sharding with ProxySQL</a></li>
</ul>
<p>然后，再看看各个公司做 MySQL Sharding 的一些经验分享。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://devs.mailchimp.com/blog/using-shards-to-accommodate-millions-of-users/">MailChimp: Using Shards to Accommodate Millions of Users
</a></li>
<li><a target="_blank" rel="noopener" href="https://eng.uber.com/schemaless-rewrite/">Uber: Code Migration in Production: Rewriting the Sharding Layer of Uber’s Schemaless Datastore</a></li>
<li><a target="_blank" rel="noopener" href="https://instagram-engineering.com/sharding-ids-at-instagram-1cf5a71e5a5c">Sharding &amp; IDs at Instagram</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/airbnb-engineering/how-we-partitioned-airbnb-s-main-database-in-two-weeks-55f7e006ff21">Airbnb: How We Partitioned Airbnb’s Main Database in Two Weeks</a></li>
</ul>
<h1 id="NoSQL-数据库"><a href="#NoSQL-数据库" class="headerlink" title="NoSQL 数据库"></a>NoSQL 数据库</h1><p>关于 NoSQL 数据库，其最初目的就是解决大数据的问题。然而，也有人把其直接用来替换掉关系型数据库。所以在学习这个技术之前，我们需要对这个技术的一些概念和初衷有一定的了解。下面是一些推荐资料。</p>
<ul>
<li>Martin Fowler 在 YouTube 上分享的 NoSQL 介绍 <a target="_blank" rel="noopener" href="https://youtu.be/qI_g07C_Q5I">Introduction To NoSQL</a>， 以及他参与编写的 <a target="_blank" rel="noopener" href="https://book.douban.com/subject/25662138/">NoSQL Distilled - NoSQL 精粹</a>，这本书才 100 多页，是本难得的关于 NoSQL 的书，很不错，非常易读。</li>
<li><a target="_blank" rel="noopener" href="https://medium.com/baqend-blog/nosql-databases-a-survey-and-decision-guidance-ea7823a822d#.nhzop4d23">NoSQL Databases: a Survey and Decision Guidance</a>，这篇文章可以带你自上而下地从 CAP 原理到开始了解 NoSQL 的种种技术，是一篇非常不错的文章。</li>
<li><a target="_blank" rel="noopener" href="https://resources.sei.cmu.edu/asset_files/WhitePaper/2014_019_001_90915.pdf">Distribution, Data, Deployment: Software Architecture Convergence in Big Data Systems</a>，这是卡内基·梅隆大学的一篇讲分布式大数据系统的论文。其中主要讨论了在大数据时代下的软件工程中的一些关键点，也说到了 NoSQL 数据库。</li>
<li><a target="_blank" rel="noopener" href="http://ianvarley.com/UT/MR/Varley_MastersReport_Full_2009-08-07.pdf">No Relation: The Mixed Blessings of Non-Relational Databases</a>，这篇论文虽然有点年代久远。但这篇论文是 HBase 的基础，你花上一点时间来读读，就可以了解到，对各种非关系型数据存储优缺点的一个很好的比较。</li>
<li><a target="_blank" rel="noopener" href="https://highlyscalable.wordpress.com/2012/03/01/nosql-data-modeling-techniques/">NoSQL Data Modeling Techniques</a> ，NoSQL 建模技术。这篇文章曾经翻译在了 CoolShell 上，标题为 <a target="_blank" rel="noopener" href="https://coolshell.cn/articles/7270.htm">NoSQL 数据建模技术</a>。<ul>
<li><a target="_blank" rel="noopener" href="https://docs.mongodb.com/manual/core/data-modeling-introduction/">MongoDB - Data Modeling Introduction</a> ，虽然这是 MongoDB 的数据建模介绍，但是其很多观点可以用于其它的 NoSQL 数据库。</li>
<li><a target="_blank" rel="noopener" href="https://firebase.google.com/docs/database/android/structure-data">Firebase - Structure Your Database</a> ，Google 的 Firebase 数据库使用 JSON 建模的一些最佳实践。</li>
</ul>
</li>
<li>因为 CAP 原理，所以当你需要选择一个 NoSQL 数据库的时候，你应该看看这篇文档 <a target="_blank" rel="noopener" href="http://blog.nahurst.com/visual-guide-to-nosql-systems">Visual Guide to NoSQL Systems</a>。</li>
</ul>
<p>选 SQL 还是 NoSQL，这里有两篇文章，值得你看看。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.upwork.com/hiring/data/sql-vs-nosql-databases-whats-the-difference/">SQL vs. NoSQL Databases: What’s the Difference?</a></li>
<li><a target="_blank" rel="noopener" href="https://engineering.salesforce.com/sql-or-nosql-9eaf1d92545b">Salesforce: SQL or NoSQL</a></li>
</ul>
<h1 id="各种-NoSQL-数据库"><a href="#各种-NoSQL-数据库" class="headerlink" title="各种 NoSQL 数据库"></a>各种 NoSQL 数据库</h1><p>学习使用 NoSQL 数据库其实并不是一件很难的事，只要你把官方的文档仔细地读一下，是很容易上手的，而且大多数 NoSQL 数据库都是开源的，所以，也可以通过代码自己解决问题。下面我主要给出一些典型的 NoSQL 数据库的一些经验型的文章，供你参考。</p>
<p><strong>列数据库 Column Database</strong></p>
<ul>
<li>Cassandra 相关<ul>
<li>沃尔玛实验室有两篇文章值得一读。<ul>
<li><a target="_blank" rel="noopener" href="https://medium.com/walmartlabs/avoid-pitfalls-in-scaling-your-cassandra-cluster-lessons-and-remedies-a71ca01f8c04">Avoid Pitfalls in Scaling Cassandra Cluster at Walmart</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/walmartlabs/building-object-store-storing-images-in-cassandra-walmart-scale-a6b9c02af593">Storing Images in Cassandra at Walmart</a></li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://engineeringblog.yelp.com/2016/08/how-we-scaled-our-ad-analytics-with-cassandra.html">Yelp: How We Scaled Our Ad Analytics with Apache Cassandra</a> ，Yelp 的这篇博客也有一些相关的经验和教训。</li>
<li><a target="_blank" rel="noopener" href="https://blog.discordapp.com/how-discord-stores-billions-of-messages-7fa6ec7ee4c7">Discord: How Discord Stores Billions of Messages</a> ，Discord 公司分享的一个如何存储十亿级消息的技术文章。</li>
<li><a target="_blank" rel="noopener" href="https://www.slideshare.net/DataStax/cassandra-at-instagram-2016">Cassandra at Instagram</a> ，Instagram 的一个 PPT，其中介绍了 Instagram 中是怎么使用 Cassandra 的。</li>
<li><a target="_blank" rel="noopener" href="https://medium.com/netflix-techblog/benchmarking-cassandra-scalability-on-aws-over-a-million-writes-per-second-39f45f066c9e">Netflix: Benchmarking Cassandra Scalability on AWS - Over a million writes per second</a> ，Netflix 公司在 AWS 上给 Cassandra 做的一个 Benchmark。</li>
</ul>
</li>
<li>HBase 相关<ul>
<li><a target="_blank" rel="noopener" href="https://medium.com/imgur-engineering/imgur-notifications-from-mysql-to-hbase-9dba6fc44183">Imgur Notification: From MySQL to HBASE</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@Pinterest_Engineering/improving-hbase-backup-efficiency-at-pinterest-86159da4b954">Pinterest: Improving HBase Backup Efficiency</a></li>
<li><a target="_blank" rel="noopener" href="https://www.ibm.com/support/knowledgecenter/en/SSPT3X_2.1.2/com.ibm.swg.im.infosphere.biginsights.analyze.doc/doc/bigsql_TuneHbase.html">IBM : Tuning HBase performance</a></li>
<li><a target="_blank" rel="noopener" href="http://www.larsgeorge.com/2010/05/hbase-file-locality-in-hdfs.html">HBase File Locality in HDFS</a></li>
<li><a target="_blank" rel="noopener" href="http://borthakur.com/ftp/RealtimeHadoopSigmod2011.pdf">Apache Hadoop Goes Realtime at Facebook</a></li>
<li><a target="_blank" rel="noopener" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.294.8459&rep=rep1&type=pdf">Storage Infrastructure Behind Facebook Messages: Using HBase at Scale</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/rayokota/awesome-hbase">GitHub: Awesome HBase</a></li>
</ul>
</li>
</ul>
<p>针对于 HBase 有两本书你可以考虑一下。</p>
<ul>
<li>首先，先推荐两本书，一本是偏实践的《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/25706541/">HBase 实战</a>》，另一本是偏大而全的手册型的《<a target="_blank" rel="noopener" href="https://book.douban.com/subject/10748460/">HBase 权威指南</a>》。</li>
<li>当然，你也可以看看官方的 <a target="_blank" rel="noopener" href="http://hbase.apache.org/0.94/book/book.html">The Apache HBase™ Reference Guide</a></li>
<li>另外两个列数据库：<ul>
<li><a target="_blank" rel="noopener" href="https://clickhouse.yandex/">ClickHouse - Open Source Distributed Column Database at Yandex</a></li>
<li><a target="_blank" rel="noopener" href="https://engineering.giphy.com/scaling-redshift-without-scaling-costs/">Scaling Redshift without Scaling Costs at GIPHY</a></li>
</ul>
</li>
</ul>
<p><strong>文档数据库 Document Database - MongoDB, SimpleDB, CouchDB</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://msdn.microsoft.com/en-us/magazine/hh547103.aspx">Data Points - What the Heck Are Document Databases?</a></li>
<li><a target="_blank" rel="noopener" href="https://www.mongodb.com/blog/post/ebay-building-mission-critical-multi-data-center-applications-with-mongodb">eBay: Building Mission-Critical Multi-Data Center Applications with MongoDB</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.baqend.com/parse-is-gone-a-few-secrets-about-their-infrastructure-91b3ab2fcf71">The AWS and MongoDB Infrastructure of Parse: Lessons Learned</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/build-addepar/migrating-mountains-of-mongo-data-63e530539952">Migrating Mountains of Mongo Data</a></li>
<li><a target="_blank" rel="noopener" href="https://engineering.linkedin.com/blog/2017/12/couchbase-ecosystem-at-linkedin">Couchbase Ecosystem at LinkedIn</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/zendesk-engineering/resurrecting-amazon-simpledb-9404034ec506">SimpleDB at Zendesk</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/ramnes/awesome-mongodb">Github: Awesome MongoDB</a></li>
</ul>
<p><strong>数据结构数据库 Data structure Database - Redis</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="http://tech.trivago.com/2017/01/25/learn-redis-the-hard-way-in-production/">Learn Redis the hard way (in production) at Trivago</a></li>
<li><a target="_blank" rel="noopener" href="http://highscalability.com/blog/2014/9/8/how-twitter-uses-redis-to-scale-105tb-ram-39mm-qps-10000-ins.html">Twitter: How Twitter Uses Redis To Scale - 105TB RAM, 39MM QPS, 10,000+ Instances</a></li>
<li><a target="_blank" rel="noopener" href="https://slack.engineering/scaling-slacks-job-queue-687222e9d100">Slack: Scaling Slack’s Job Queue - Robustly Handling Billions of Tasks in Milliseconds Using Kafka and Redis</a></li>
<li><a target="_blank" rel="noopener" href="https://githubengineering.com/moving-persistent-data-out-of-redis/">GitHub: Moving persistent data out of Redis at GitHub</a></li>
<li><a target="_blank" rel="noopener" href="https://engineering.instagram.com/storing-hundreds-of-millions-of-simple-key-value-pairs-in-redis-1091ae80f74c">Instagram: Storing Hundreds of Millions of Simple Key-Value Pairs in Redis</a></li>
<li><a target="_blank" rel="noopener" href="https://www.infoq.com/presentations/twitch-pokemon">Redis in Chat Architecture of Twitch (from 27:22)</a></li>
<li><a target="_blank" rel="noopener" href="https://deliveroo.engineering/2016/10/07/optimising-session-key-storage.html">Deliveroo: Optimizing Session Key Storage in Redis</a></li>
<li><a target="_blank" rel="noopener" href="https://deliveroo.engineering/2017/01/19/optimising-membership-queries.html">Deliveroo: Optimizing Redis Storage</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/JamzyWang/awesome-redis">GitHub: Awesome Redis</a></li>
</ul>
<p><strong>时序数据库 Time-Series Database</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.timescale.com/what-the-heck-is-time-series-data-and-why-do-i-need-a-time-series-database-dcf3b1b18563">What is Time-Series Data &amp; Why We Need a Time-Series Database</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.timescale.com/time-series-data-why-and-how-to-use-a-relational-database-instead-of-nosql-d0cd6975e87c">Time Series Data: Why and How to Use a Relational Database instead of NoSQL</a></li>
<li><a target="_blank" rel="noopener" href="https://code.facebook.com/posts/952820474848503/beringei-a-high-performance-time-series-storage-engine/">Beringei: High-performance Time Series Storage Engine @Facebook</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/netflix-techblog/introducing-atlas-netflixs-primary-telemetry-platform-bd31f4d8ed9a">Introducing Atlas: Netflix’s Primary Telemetry Platform @Netflix</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.timescale.com/when-boring-is-awesome-building-a-scalable-time-series-database-on-postgresql-2900ea453ee2">Building a Scalable Time Series Database on PostgreSQL</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/netflix-techblog/scaling-time-series-data-storage-part-i-ec2b6d44ba39">Scaling Time Series Data Storage - Part I @Netflix</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@leventov/design-of-a-cost-efficient-time-series-store-for-big-data-88c5dc41af8e">Design of a Cost Efficient Time Series Store for Big Data</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/xephonhq/awesome-time-series-database">GitHub: Awesome Time-Series Database</a></li>
</ul>
<p><strong>图数据库 - Graph Platform</strong></p>
<ul>
<li>首先是 IBM Devloperworks 上的两个简介性的 PPT。<ul>
<li><a target="_blank" rel="noopener" href="https://www.ibm.com/developerworks/library/cl-graph-database-1/cl-graph-database-1-pdf.pdf">Intro to graph databases, Part 1, Graph databases and the CRUD operations</a></li>
<li><a target="_blank" rel="noopener" href="https://www.ibm.com/developerworks/library/cl-graph-database-2/cl-graph-database-2-pdf.pdf">Intro to graph databases, Part 2, Building a recommendation engine with a graph database</a></li>
</ul>
</li>
<li>然后是一本免费的电子书《<a target="_blank" rel="noopener" href="http://graphdatabases.com">Graph Database</a>》。</li>
<li>接下来是一些图数据库的介绍文章。<ul>
<li><a target="_blank" rel="noopener" href="https://www.infoq.com/presentations/graph-database-scalability">Handling Billions of Edges in a Graph Database</a></li>
<li><a target="_blank" rel="noopener" href="https://neo4j.com/customers/">Neo4j case studies with Walmart, eBay, AirBnB, NASA, etc</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.twitter.com/engineering/en_us/a/2010/introducing-flockdb.html">FlockDB: Distributed Graph Database for Storing Adjacency Lists at Twitter</a></li>
<li><a target="_blank" rel="noopener" href="https://architecht.io/google-ibm-back-new-open-source-graph-database-project-janusgraph-1d74fb78db6b">JanusGraph: Scalable Graph Database backed by Google, IBM and Hortonworks</a></li>
<li><a target="_blank" rel="noopener" href="https://aws.amazon.com/neptune/">Amazon Neptune</a></li>
</ul>
</li>
</ul>
<p><strong>搜索数据库 - ElasticSearch</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.elastic.co/guide/en/elasticsearch/guide/master/index.html">Elasticsearch: The Definitive Guide</a> 这是官网方的 ElasticSearch 的学习资料，基本上来说，看这个就够了。</li>
<li>接下来是 4 篇和性能调优相关的工程实践。<ul>
<li><a target="_blank" rel="noopener" href="https://www.ebayinc.com/stories/blogs/tech/elasticsearch-performance-tuning-practice-at-ebay/">Elasticsearch Performance Tuning Practice at eBay</a></li>
<li><a target="_blank" rel="noopener" href="https://kickstarter.engineering/elasticsearch-at-kickstarter-db3c487887fc">Elasticsearch at Kickstarter</a></li>
<li><a target="_blank" rel="noopener" href="https://www.loggly.com/blog/nine-tips-configuring-elasticsearch-for-high-performance/">9 tips on ElasticSearch configuration for high performance</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@abhidrona/elasticsearch-deployment-best-practices-d6c1323b25d7">Elasticsearch In Production - Deployment Best Practices</a></li>
</ul>
</li>
<li>最后是 GitHub 上的资源列表 <a target="_blank" rel="noopener" href="https://github.com/dzharii/awesome-elasticsearch">GitHub: Awesome ElasticSearch</a> 。</li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Chinese/" rel="tag">Chinese</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Database/" rel="tag">Database</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-前端优化"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/02/04/%E5%89%8D%E7%AB%AF%E4%BC%98%E5%8C%96/"
    >前端优化</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/02/04/%E5%89%8D%E7%AB%AF%E4%BC%98%E5%8C%96/" class="article-date">
  <time datetime="2020-02-04T22:55:14.000Z" itemprop="datePublished">2020-02-04</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="前端性能优化"><a href="#前端性能优化" class="headerlink" title="前端性能优化"></a>前端性能优化</h1><p>首先是推荐几本前端性能优化方面的图书。</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="http://www.allitebooks.in/web-performance-action/">Web Performance in Action</a> ，这本书目前国内没有卖的。可以看电子版本，是一本很不错的书，其中有 CSS、图片、字体、JavaScript 性能调优等。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="http://designingforperformance.com/">Designing for Performance</a> ，这本在线的电子书很不错，其中讲了很多网页优化的技术和相关的工具，可以让你对整体网页性能优化有所了解。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://book.douban.com/subject/5362856/">High Performance JavaScript</a> ，这本书在国内可以买到，能让你了解如何提升各方面的性能，包括代码的加载、运行、DOM 交互、页面生存周期等。雅虎的前端工程师尼古拉斯·扎卡斯（Nicholas C. Zakas）和其他五位 JavaScript 专家介绍了页面代码加载的最佳方法和编程技巧，来帮助你编写更为高效和快速的代码。你还会了解到构建和部署文件到生产环境的最佳实践，以及有助于定位线上问题的工具。</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://book.douban.com/subject/26411563/">High Performance Web Sites: Essential Knowledge for Front-End Engineers</a> ，这本书国内也有卖，翻译版为《高性能网站建设指南：前端工程师技能精髓》。作者给出了 14 条具体的优化原则，每一条原则都配以范例佐证，并提供了在线支持。</p>
<p>全书内容丰富，主要包括减少 HTTP 请求、Edge Computing 技术、Expires Header 技术、gzip 组件、CSS 和 JavaScript 最佳实践、主页内联、Domain 最小化、JavaScript 优化、避免重定向的技巧、删除重复 JavaScript 的技巧、关闭 ETags 的技巧、Ajax 缓存技术和最小化技术等。</p>
</li>
<li><p>除了上面这几本书之外，Google 的 <a target="_blank" rel="noopener" href="https://developers.google.com/web/fundamentals/">Web Fundamentals</a> 里的 <a target="_blank" rel="noopener" href="https://developers.google.com/web/fundamentals/performance/why-performance-matters/">Performance</a> 这一章节也有很多非常不错的知识和经验。</p>
</li>
</ul>
<p>接下来是一些最佳实践性的文档。</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://browserdiet.com/zh/">Browser Diet</a> ，前端权威性能指南（中文版）。这是一群为大型站点工作的专家们建立的一份前端性能的工作指南。</li>
<li><a target="_blank" rel="noopener" href="https://developers.google.com/speed/docs/insights/rules">PageSpeed Insights Rules</a> ，谷歌给的一份性能指南和最佳实践。</li>
<li><a target="_blank" rel="noopener" href="https://developer.yahoo.com/performance/rules.html">Best Practices for Speeding Up Your Web Site</a> ，雅虎公司给的一份 7 个分类共 35 个最佳实践的文档。</li>
</ul>
<p>接下来，重点推荐一个性能优化的案例学习网站 <a target="_blank" rel="noopener" href="https://wpostats.com/">WPO Stats</a> 。WPO 是 Web Performance Optimization 的缩写，这个网站上有很多很不错的性能优化的案例分享，一定可以帮助你很多。</p>
<p>然后是一些文章和案例。</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://blog.httpwatch.com/2015/01/16/a-simple-performance-comparison-of-https-spdy-and-http2/">A Simple Performance Comparison of HTTPS, SPDY and HTTP/2</a> ，这是一篇比较浏览器的 HTTPS、SPDY 和 HTTP/2 性能的文章，除了比较之外，还可以让你了解一些技术细节。</li>
<li><a target="_blank" rel="noopener" href="https://www.nginx.com/blog/7-tips-for-faster-http2-performance/">7 Tips for Faster HTTP/2 Performance</a> ，对于 HTTP/2 来说，Nginx 公司给出的 7 个增加其性能的小提示。</li>
<li><a target="_blank" rel="noopener" href="https://slack.engineering/reducing-slacks-memory-footprint-4480fec7e8eb">Reducing Slack’s memory footprint</a> ，Slack 团队减少内存使用量的实践。</li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@Pinterest_Engineering/driving-user-growth-with-performance-improvements-cfc50dafadd7">Pinterest: Driving user growth with performance improvements</a> ，Pinterest 关于性能调优的一些分享，其中包括了前后端的一些性能调优实践。其实也是一些比较通用的玩法，这篇文章主要是想让前端的同学了解一下如何做整体的性能调优。</li>
<li><a target="_blank" rel="noopener" href="http://jonraasch.com/blog/10-javascript-performance-boosting-tips-from-nicholas-zakas">10 JavaScript Performance Boosting Tips</a> ，10 个提高 JavaScript 运行效率的小提示，挺有用的。</li>
<li><a target="_blank" rel="noopener" href="http://www.guypo.com/17-statistics-to-sell-web-performance-optimization/">17 Statistics to Sell Web Performance Optimization</a> ，这个网页上收集了好些公司的 Web 性能优化的工程分享，都是非常有价值的。</li>
<li><a target="_blank" rel="noopener" href="http://deanhume.com/Home/BlogPost/getting-started-with-the-picture-element/8109">Getting started with the Picture Element</a> ，这篇文章讲述了 Responsive 布局所带来的一些负面的问题。主要是图像适配的问题，其中引出了一篇文章 “<a target="_blank" rel="noopener" href="https://dev.opera.com/articles/native-responsive-images/">Native Responsive Images</a>“ ，值得一读。</li>
<li><a target="_blank" rel="noopener" href="http://www.deanhume.com/Home/BlogPost/improve-page-load-times-with-dns-prefetching/80">Improve Page Load Times With DNS Prefetching</a> ，这篇文章教了你一个如何降低 DNS 解析时间的小技术——DNS prefetching。</li>
<li><a target="_blank" rel="noopener" href="http://www.html5rocks.com/en/tutorials/speed/rendering/">Jank Busting for Better Rendering Performance</a> ，这是一篇 Google I/O 上的分享，关于前端动画渲染性能提升。</li>
<li><a target="_blank" rel="noopener" href="https://developer.chrome.com/devtools/docs/javascript-memory-profiling">JavaScript Memory Profiling</a> ，这是一篇谷歌官方教你如何使用 Chrome 的开发工具来分析 JavaScript 内存问题的文章。</li>
</ul>
<p>接下来是一些性能工具。在线性能测试分析工具太多，这里只推荐比较权威的。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://developers.google.com/speed/pagespeed/">PageSpeed</a> ，谷歌有一组 PageSpeed 工具来帮助你分析和优化网站的性能。Google 出品的，质量相当有保证。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/marcelduran/yslow">YSlow</a> ，雅虎的一个网页分析工具。</li>
<li><a target="_blank" rel="noopener" href="https://gtmetrix.com/">GTmetrix</a> ，是一个将 PageSpeed 和 YSlow 合并起来的一个网页分析工具，并且加上一些 Page load 或是其它的一些分析。也是一个很不错的分析工具。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/davidsonfellipe/awesome-wpo">Awesome WPO</a> ，在 GitHub 上的这个 Awesome 中，你可以找到更多的性能优化工具和资源。</li>
</ul>
<p>另外，中国的网络有各种问题（你懂的），所以，你不能使用 Google 共享的 JavaScript 链接来提速，你得用中国自己的。你可以到这里看看中国的共享库资源，<a target="_blank" rel="noopener" href="http://chineseseoshifu.com/blog/china-hosted-javascript-libraries-jquery-dojo-boostrap.html">Forget Google and Use These Hosted JavaScript Libraries in China</a> 。</p>
<h1 id="前端框架"><a href="#前端框架" class="headerlink" title="前端框架"></a>前端框架</h1><p>接下来，要学习的是 Web 前端的几大框架。目前而言，前端社区有三大框架 Angular.js、React.js 和 Vue.js。React 和 Vue 更为强劲一些，所以，这里只写和 React 和 Vue 相关的攻略。关于两者的比较，网上有好多文章。这里推荐几篇供你参考。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://medium.com/unicorn-supplies/angular-vs-react-vs-vue-a-2017-comparison-c5c52d620176">Angular vs. React vs. Vue: A 2017 comparison</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/js-dojo/react-or-vue-which-javascript-ui-library-should-you-be-using-543a383608d">React or Vue: Which JavaScript UI Library Should You Be Using?</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@TechMagic/reactjs-vs-angular5-vs-vue-js-what-to-choose-in-2018-b91e028fa91d">ReactJS vs Angular5 vs Vue.js - What to choose in 2018?</a></li>
</ul>
<p>其实，比较这些框架的优缺点还有利弊并不是要比出个输赢，而是让你了解一下不同框架的优缺点。这些框架都是可以学习的。而在我们生活工作中具体要用哪个框架，最好还是要有一些出发点，比如，你是为了找份好的工作，为了快速地搭一个网站，为了改造一个大规模的前端系统，还是纯粹地为了学习……</p>
<p>不同的目的会导致不同的决定。并不希望上述的这些比较会让你进入 “ 二选一 “ 或是 “ 三选一 “ 的境地。只是想通过这些文章让你知道这些框架的设计思路和实现原理，这些才是让你受益一辈子的事。</p>
<h2 id="React-js-框架"><a href="#React-js-框架" class="headerlink" title="React.js 框架"></a>React.js 框架</h2><p>下面先来学习一下 React.js 框架。</p>
<p><strong>入门</strong></p>
<p>React 学起来并不复杂，就看 <a target="_blank" rel="noopener" href="https://reactjs.org/tutorial/tutorial.html">React 官方教程</a> 和其文档就好了（ <a target="_blank" rel="noopener" href="https://doc.react-china.org/">React 的中文教程</a> ）。</p>
<p>然后，下面的文章会带你了解一下 React.js 的基本原理。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://medium.freecodecamp.org/all-the-fundamental-react-js-concepts-jammed-into-this-single-medium-article-c83f9b53eac2">All the fundamental React.js concepts</a> ，这篇文章讲了所有的 React.js 的基本原理。</li>
<li><a target="_blank" rel="noopener" href="https://blog.kentcdodds.com/learn-react-fundamentals-and-advanced-patterns-eac90341c9db">Learn React Fundamentals and Advanced Patterns</a> ，这篇文章中有几个短视频，每个视频不超过 5 分钟，是学习 React 的一个很不错的地方。</li>
<li><a target="_blank" rel="noopener" href="https://reactjs.org/docs/thinking-in-react.html">Thinking in React</a>，这篇文章将引导你完成使用 React 构建可搜索产品数据表的思考过程。</li>
</ul>
<p><strong>提高</strong></p>
<p>学习一个技术最重要的是要学到其中的思想和方法。下面是一些学习 React 中最重要的东西。</p>
<ul>
<li><p><strong>状态</strong>，对于富客户端来说是非常麻烦也是坑最多的地方，这里有几篇文章你可以一读。</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://reactkungfu.com/2015/09/common-react-dot-js-mistakes-unneeded-state/">Common React.js mistakes: Unneeded state</a> ，React.js 编程的常见错误——不必要的状态。</li>
<li><a target="_blank" rel="noopener" href="https://www.reddit.com/r/reactjs/comments/3bjdoe/state_is_an_antipattern/">State is an Anti-Pattern</a> ，关于如何做一个不错的组件的思考，很有帮助。</li>
<li><a target="_blank" rel="noopener" href="https://www.safaribooksonline.com/blog/2015/10/29/react-local-component-state/">Why Local Component State is a Trap</a> ，一些关于 “Single state tree” 的想法。</li>
<li><a target="_blank" rel="noopener" href="https://daveceddia.com/thinking-statefully/">Thinking Statefully</a> ，几个很不错的例子让你对声明式的有状态的技术有更好的理解。</li>
<li>传统上，解决 React 的状态问题一般用 Redux。在这里推荐 <a target="_blank" rel="noopener" href="https://www.robinwieruch.de/tips-to-learn-react-redux/">Tips to learn React + Redux in 2018</a> 。Redux 是一个状态粘合组件，一般来说，我们会用 Redux 来做一些数据状态和其上层 Component 上的同步。这篇教程很不错。</li>
<li>最后是 “State Architecture Patterns in React “ 系列文章，非常值得一读。<ul>
<li><a target="_blank" rel="noopener" href="https://medium.com/@skylernelson_64801/state-architecture-patterns-in-react-a-review-df02c1e193c6">Part 1: A Review</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@skylernelson_64801/state-architecture-patterns-in-react-part-2-the-top-heavy-architecture-flux-and-performance-a388b928ce89">Part 2: The Top-Heavy Architecture, Flux and Performance</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@skylernelson_64801/state-architecture-patterns-in-react-part-3-articulation-points-zine-and-an-overall-strategy-cf076f906391">Part 3: Articulation Points, zine and An Overall Strategy</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@skylernelson_64801/state-architecture-patterns-in-react-part-4-purity-flux-duality-and-dataflow-d06016b3379a">Part 4: Purity, Flux-duality and Dataflow</a></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>函数式编程</strong>。从 jQuery 过来的同学一定非常不习惯 React，而从 Java 等后端过来的程序员就会很习惯了。所以，React 就是后端人员开发的，或者说是做函数式编程的人开发的。对此，你需要学习一下 JavaScript 函数式编程的东西。</p>
<p>这里推荐一本免费的电子书 《<a target="_blank" rel="noopener" href="https://github.com/MostlyAdequate/mostly-adequate-guide">Professor Frisby’s Mostly Adequate Guide to Functional Programming</a>》，其中译版为《<a target="_blank" rel="noopener" href="https://jigsawye.gitbooks.io/mostly-adequate-guide/content/">JS 函数式编程指南中文版</a>》。</p>
<p>下面有几篇文章非常不错。前两篇和函数式编程有关的文章非常值得一读。后三篇是一些比较实用的函数式编程和 React 结合的文章。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://medium.com/javascript-scene/master-the-javascript-interview-what-is-functional-programming-7f218c68b3a0?utm_source=mybridge&utm_medium=email&utm_campaign=read_more">Master the JavaScript Interview: What is Functional Programming?</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/javascript-scene/the-rise-and-fall-and-rise-of-functional-programming-composable-software-c2d91b424c8c">The Rise and Fall and Rise of Functional Programming (Composing Software)</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.risingstack.com/functional-ui-and-components-as-higher-order-functions/">Functional UI and Components as Higher Order Functions</a></li>
<li><a target="_blank" rel="noopener" href="http://banderson.github.io/functional-js-reverse-engineering-the-hype/">Functional JavaScript: Reverse-Engineering the Hype</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/javascript-inside/some-thoughts-on-function-components-in-react-cb2938686bc7">Some Thoughts on Function Components in React</a></li>
</ul>
</li>
<li><p><strong>设计相关</strong>。接下来是学习一些 React 的设计模式。<a target="_blank" rel="noopener" href="https://reactpatterns.com/">React Pattern</a> 是一个不错的学习 React 模式的地方。除此之外，还有如下的一些不错的文章也会对你很有帮助的。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://medium.com/@franleplant/react-higher-order-components-in-depth-cf9032ee6c3e">React Higher Order Components in depth</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@dan_abramov/smart-and-dumb-components-7ca2f9a7c7d0">Presentational and Container Components</a></li>
<li><a target="_blank" rel="noopener" href="https://goshakkk.name/controlled-vs-uncontrolled-inputs-react/">Controlled and uncontrolled form inputs in React don’t have to be complicated</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/merrickchristensen/function-as-child-components-5f3920a9ace9">Function as Child Components</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/styled-components/component-folder-pattern-ee42df37ec68">Writing Scalable React Apps with the Component Folder Pattern</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.freecodecamp.org/reusable-web-application-strategies-d51517ea68c8">Reusable Web Application Strategies</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@robftw/characteristics-of-an-ideal-react-architecture-883b9b92be0b">Characteristics of an Ideal React Architecture</a></li>
</ul>
</li>
<li><p><strong>实践和经验</strong></p>
</li>
</ul>
<p>还有一些不错的实践和经验。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://camjackson.net/post/9-things-every-reactjs-beginner-should-know">9 things every React.js beginner should know</a></li>
<li><a target="_blank" rel="noopener" href="https://engineering.siftscience.com/best-practices-for-building-large-react-applications/">Best practices for building large React applications</a></li>
<li><a target="_blank" rel="noopener" href="https://americanexpress.io/clean-code-dirty-code/">Clean Code vs. Dirty Code: React Best Practices</a></li>
<li><a target="_blank" rel="noopener" href="https://dev.to/jakoblind/how-to-become-a-more-productive-react-developer">How to become a more productive React Developer</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.freecodecamp.org/8-key-react-component-decisions-cc965db11594">8 Key React Component Decisions</a></li>
</ul>
<p><strong>资源列表</strong></p>
<p>最后就是 React 的资源列表。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/enaqx/awesome-react">Awesome React</a> ，这是一些 React 相关资源的列表，很大很全。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/markerikson/react-redux-links">React/Redux Links</a> ，这也是 React 相关的资源列表，与上面不一样的是，这个列表主要收集了大量的文章，其中讲述了很多 React 知识和技术，比上面的列表好很多。</li>
<li><a target="_blank" rel="noopener" href="https://react.rocks/">React Rocks</a> ，这个网站主要收集各种 React 的组件示例，可以让你大开眼界。</li>
</ul>
<h2 id="Vue-js-框架"><a href="#Vue-js-框架" class="headerlink" title="Vue.js 框架"></a>Vue.js 框架</h2><p>Vue 可能是一个更符合前端工程师习惯的框架。不像 React.js 那样使用函数式编程方式，是后端程序员的思路。</p>
<ul>
<li>通过文章 “<a target="_blank" rel="noopener" href="https://medium.com/vue-mastery/why-43-of-front-end-developers-want-to-learn-vue-js-7f23348bc5be">Why 43% of Front-End Developers want to learn Vue.js</a>” ，你可以看出其编程方式和 React 是大相径庭的，符合传统的前端开发的思维方式。</li>
<li>通过文章 <a target="_blank" rel="noopener" href="https://www.smashingmagazine.com/2018/02/jquery-vue-javascript/">Replacing jQuery With Vue.js: No Build Step Necessary</a> ，我们可以看到，从 jQuery 是可以平滑过度到 Vue 的。</li>
<li>另外，我们可以通过 “<a target="_blank" rel="noopener" href="https://medium.com/@dalaidunc/10-things-i-love-about-vue-505886ddaff2">10 things I love about Vue</a>” ，了解 Vue 的一些比较优秀的特性。</li>
</ul>
<p>最令人高兴的是，Vue 的作者是尤雨溪（Evan You），最近一次对他的采访 “<a target="_blank" rel="noopener" href="https://blog.hackages.io/https-blog-hackages-io-evanyoubhack2017-cc5559806157">Vue on 2018 - Interview with Evan You</a>” 当中有很多故事以及对 Vue 的展望。（<strong>注意：Vue 是完全由其支持者和用户资助的，这意味着它更接近社区而不受大公司的控制。</strong>）</p>
<p>要学习 Vue 并不难，上官网看文档（ <a target="_blank" rel="noopener" href="http://vuejs.org/guide/">Vue 官方文档</a>（<a target="_blank" rel="noopener" href="https://cn.vuejs.org/v2/guide/">中文版</a>）），照着搞一搞就可以很快上手了。<a target="_blank" rel="noopener" href="https://laracasts.com/series/learn-vue-2-step-by-step">Vue.js screencasts</a> 是一个很不错的英文视频教程。</p>
<p>另外，推荐 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/23134551">新手向：Vue 2.0 的建议学习顺序</a> ，这是 Vue 作者写的，所以有特殊意义。</p>
<p>Vue 的确比较简单，有 Web 开发经验的人上手也比较快，所以这里也不会像 React 那样给出很多的资料。下面是一些还不错的内容，推荐给你。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://itnext.io/how-not-to-vue-18f16fe620b5">How not to Vue</a> ，任何技术都有坑，了解 Vue 的短板，你就能扬长避短，就能用得更好。</li>
<li><a target="_blank" rel="noopener" href="https://alligator.io/vuejs/component-communication/">Vue.js Component Communication Patterns</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/js-dojo/4-ajax-patterns-for-vue-js-apps-add915fc9168">4 AJAX Patterns For Vue.js Apps</a></li>
<li><a target="_blank" rel="noopener" href="https://vuejsdevelopers.com/2017/05/20/vue-js-safely-jquery-plugin/">How To (Safely) Use A jQuery Plugin With Vue.js</a></li>
<li><a target="_blank" rel="noopener" href="https://vuejsdevelopers.com/2017/03/24/vue-js-component-templates/">7 Ways To Define A Component Template in Vue.js</a></li>
<li><a target="_blank" rel="noopener" href="https://vuejsdevelopers.com/2017/04/22/vue-js-libraries-plugins/">Use Any Javascript Library With Vue.js</a></li>
<li><a target="_blank" rel="noopener" href="https://lobotuerto.com/blog/dynamic-and-async-components-made-easy-with-vuejs/">Dynamic and async components made easy with Vue.js</a></li>
</ul>
<p>当然，最后一定还有 <a target="_blank" rel="noopener" href="https://github.com/vuejs/awesome-vue">Awesome Vue</a> ，Vue.js 里最为巨大最为优秀的资源列表。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Chinese/" rel="tag">Chinese</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Front-end/" rel="tag">Front-end</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-如何阅读代码"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/02/03/%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%BB%A3%E7%A0%81/"
    >如何阅读代码</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/02/03/%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%BB%A3%E7%A0%81/" class="article-date">
  <time datetime="2020-02-03T23:50:07.000Z" itemprop="datePublished">2020-02-03</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="读文档还是读代码"><a href="#读文档还是读代码" class="headerlink" title="读文档还是读代码"></a>读文档还是读代码</h1><p>杰夫·阿特伍德（Jeff Atwood）说过这么一句话：“<a target="_blank" rel="noopener" href="https://blog.codinghorror.com/code-tells-you-how-comments-tell-you-why/">Code Tells You How, Comments Tell You Why</a>”。扩展一下：</p>
<ul>
<li><strong>代码 =&gt; What, How &amp; Details</strong></li>
<li><strong>文档 / 书 =&gt; What, How &amp; Why</strong></li>
</ul>
<p>可见，<strong>代码并不会告诉你 Why</strong>，看代码只能靠猜测或推导来估计 Why，是揣测，不准确，所以会有很多误解。<strong>而且，我们每个人都知道，Why 是能让人一通百通的东西，也是能让人醍醐灌顶的东西</strong>。</p>
<p>但是，<strong>代码会告诉你细节</strong>，这是书和文档不能给你的。<strong>细节是魔鬼，细节决定成败</strong>。这样的话我们不但听过很多，我们做技术的也应该体会过很多。当然，我们也要承认，这些代码细节给人带来的快感毕竟不如知道 Why 后的快感大。</p>
<p><strong>书和文档是人对人说的话，代码是人对机器说的话</strong>（注：代码中有一部份逻辑是控制流程的逻辑，不是业务逻辑）。所以，</p>
<ol>
<li><strong>如果你想知道人为什么要这么搞，那么应该去看书</strong>（像 Effective C++、Code Complete、Design Pattern、Thinking in Java 等），<strong>看文档</strong>。</li>
<li><strong>如果你要知道让机器干了什么？那你应该看代码！</strong>（就像 Linus 去看 zlib 的代码来找性能问题。）</li>
</ol>
<p>因此，我认为都比较重要，关键看你的目的是什么了。</p>
<ul>
<li><strong>如果你想了解一种思想，一种方法，一种原理，一种思路，一种经验，恐怕，读书和读文档会更有效率一些</strong>，因为其中会有作者的思路描述。像 Effective C++ 之类的书，里面有很多对不同用法和设计的推敲，TCP/IP 详解里面也会有对 TCP 算法好坏的比较……这些思维方式能让你对技术的把握力更强，而光看代码很难达到这种级别。</li>
<li><strong>如果你想了解的就是具体细节，比如某协程的实现，某个模块的性能，某个算法的实现，那么你还是要去读代码的</strong>，因为代码中会有更具体的处理（尤其是对于一些 edge case 或是代码技巧方面的内容）。</li>
</ul>
<p>另外，看看下面的几个现象，你可以自己比较一下。</p>
<ul>
<li>很多时候，我们去读代码，那是因为没有文档，或是文档写得太差。</li>
<li>很多时候，<strong>在 Google、Stack Overflow、GitHub 过后，你会发现，你掌握的知识就是一块一块的碎片，既不系统，也不结构化，更别说融汇贯通了。你会觉得自己需要好好地读一本书，系统地掌握知识。</strong></li>
<li>很多时候，在读别人代码的时候，你会因为基础知识或是原理不懂，或是你在不知道为什么的情况下，要么完全读不懂代码，要么会误解代码。比如，如果你没有 C 语言和 TCP 原理方面的基础知识，就根本读不懂 Linux 下 TCP 的相关代码。我们因为误解代码用意而去修改代码造成的故障还少吗？</li>
<li>很多时候，看到一个算法或是一个设计时，比如 Paxos，你是不是会想去看一下这个算法的实现代码是什么样的？思考一下如何才能实现得好？（但是如果你没看过 Paxos 的算法思想，我不认为你光看代码实现，就能收获 Paxos 的思想。）</li>
<li>很多时候，<strong>当你写代码的时候，你能感觉得到自己写的代码有点别扭，怎么写都别扭，这个时候，你也会有想去看别人的代码是怎么实现的冲动</strong>。</li>
</ul>
<p>类似的情况还有很多，但从代码中收获大，还是从书中收获大，在不同的场景、不同的目的下，会有不同的答案。这里，谈一谈人的学习过程吧。从学习的过程中，我们来分析一下看代码和看书这两个活动。人对新事物的学习过程基本都是从“感性认识”到“理性认识”的。</p>
<ul>
<li><strong>如果你是个新手，那应该多读代码，多动手写代码</strong>，因为你需要的是“感性认识”，这个时候“理性认识”你体会不到。一是因为，你没有切身的感受，即便告诉你 Why 你也体会不到。另一方面，这个阶段，你要的不是做漂亮，而是做出来。所以，在<strong>新手阶段，你会喜欢 GitHub 这样的东西</strong>。</li>
<li><strong>如果你是个老手，你有多年的“感性认识”了，那么你的成长需要更多的“理性认识”</strong>。因为这个阶段，一方面，你会不满足于做出来，你会想去做更牛更漂亮的东西；另一方面，你知道的越多，你的问题也越多，你迫切地需要知道 Why！这时，你需要大量地找牛人交流（读牛人的书，是一种特殊的人与人的交流），所以，<strong>这个阶段，你会喜欢读好的书和文章</strong>。</li>
</ul>
<p>然而，对于计算机行业这个技术创新能力超强、技术种类繁多的行业来说，我们每个人都既是新手，也是老手。</p>
<h1 id="如何阅读源代码"><a href="#如何阅读源代码" class="headerlink" title="如何阅读源代码"></a>如何阅读源代码</h1><p>很多人问过我，如何读代码。因为我在外企里工作的时间较长，所以，我经常接手一些国外团队写的代码。我发现，虽然老外写的代码比国人好一点儿（有 Code Review），但依然有文档缺失、代码注释不清、代码风格混乱等一些问题，这些都是阅读代码的障碍。这里，我把我的一些阅读源代码的经验分享给你，希望对你有用。</p>
<p>首先，在阅读代码之前，我建议你需要有下面的这些前提再去阅读代码，这样你读起代码来会很顺畅。</p>
<ol>
<li><strong>基础知识</strong>。相关的语言和基础技术的知识。</li>
<li><strong>软件功能</strong>。你先要知道这个软件完成的是什么样的功能，有哪些特性，哪些配置项。你先要读一遍用户手册，然后让软件跑起来，自己先用一下感受一下。</li>
<li><strong>相关文档</strong>。读一下相关的内部文档，Readme 也好，Release Notes 也好，Design 也好，Wiki 也好，这些文档可以让你明白整个软件的方方面面。如果你的软件没有文档，那么，你只能指望这个软件的原作者还在，而且他还乐于交流。</li>
<li><strong>代码的组织结构</strong>。也就是代码目录中每个目录是什么样的功能，每个文档是干什么的。如果你要读的程序是在某种标准的框架下组织的，比如：Java 的 Spring 框架，那么恭喜你，这些代码不难读了。</li>
</ol>
<p>接下来，你要了解这个软件的代码是由哪些部分构成的，我在这里给你一个列表，供你参考。</p>
<ol>
<li><strong>接口抽象定义</strong>。任何代码都会有很多接口或抽象定义，其描述了代码需要处理的数据结构或者业务实体，以及它们之间的关系，理清楚这些关系是非常重要的。</li>
<li><strong>模块粘合层</strong>。我们的代码有很多都是用来粘合代码的，比如中间件（middleware）、Promises 模式、回调（Callback）、代理委托、依赖注入等。这些代码模块间的粘合技术是非常重要的，因为它们会把本来平铺直述的代码给分裂开来，让你不容易看明白它们的关系。</li>
<li><strong>业务流程</strong>。这是代码运行的过程。一开始，我们不要进入细节，但需要在高层搞清楚整个业务的流程是什么样的，在这个流程中，数据是怎么被传递和处理的。一般来说，我们需要画程序流程图或者时序处理图。</li>
<li><strong>具体实现</strong>。了解上述的三个方面的内容，相信你对整个代码的框架和逻辑已经有了总体认识。这个时候，你就可以深入细节，开始阅读具体实现的代码了。对于代码的具体实现，一般来说，你需要知道下面一些事实，这样有助于你在阅读代码时找到重点。<ul>
<li><strong>代码逻辑</strong>。代码有两种逻辑，一种是业务逻辑，这种逻辑是真正的业务处理逻辑；另一种是控制逻辑，这种逻辑只是用控制程序流转的，不是业务逻辑。比如：flag 之类的控制变量，多线程处理的代码，异步控制的代码，远程通讯的代码，对象序列化反序列化的代码等。这两种逻辑你要分开，很多代码之所以混乱就是把这两种逻辑混在一起了（详情参看《编程范式游记》）。</li>
<li><strong>出错处理</strong>。根据 2：8 原则，20% 的代码是正常的逻辑，80% 的代码是在处理各种错误，所以，你在读代码的时候，完全可以把处理错误的代码全部删除掉，这样就会留下比较干净和简单的正常逻辑的代码。排除干扰因素，可以更高效地读代码。</li>
<li><strong>数据处理</strong>。只要你认真观察，就会发现，我们好多代码就是在那里倒腾数据。比如 DAO、DTO，比如 JSON、XML，这些代码冗长无聊，不是主要逻辑，可以不理。</li>
<li><strong>重要的算法</strong>。一般来说，我们的代码里会有很多重要的算法，我说的并不一定是什么排序或是搜索算法，可能会是一些其它的核心算法，比如一些索引表的算法，全局唯一 ID 的算法，信息推荐的算法、统计算法、通读算法（如 Gossip）等。这些比较核心的算法可能会非常难读，但它们往往是最有技术含量的部分。</li>
<li><strong>底层交互</strong>。有一些代码是和底层系统的交互，一般来说是和操作系统或是 JVM 的交互。因此，读这些代码通常需要一定的底层技术知识，不然，很难读懂。</li>
</ul>
</li>
<li><strong>运行时调试</strong>。很多时候，代码只有运行起来了，才能知道具体发生了什么事，所以，我们让代码运行进来，然后用日志也好，debug 设置断点跟踪也好。实际看一下代码的运行过程，是了解代码的一种很好的方式。</li>
</ol>
<p>总结一下，阅读代码的方法如下。</p>
<ul>
<li>一般采用自顶向下，从总体到细节的“剥洋葱皮”的读法。</li>
<li>画图是必要的，程序流程图，调用时序图，模块组织图……</li>
<li>代码逻辑归一下类，排除杂音，主要逻辑才会更清楚。</li>
<li>debug 跟踪一下代码是了解代码在执行中发生了什么的最好方式。</li>
</ul>
<p>对了，阅读代码你需要一个很好的 IDE。以前读 C 和 C++ 代码时，有一个叫 source insight 的工具就大大提高了的代码阅读效率。说白了就是可以查看代码间相互的调用 reference 的工具，这方面 Visual Studio 做得是非常好的。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Chinese/" rel="tag">Chinese</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-前端基础"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/02/02/%E5%89%8D%E7%AB%AF%E5%9F%BA%E7%A1%80/"
    >前端基础</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/02/02/%E5%89%8D%E7%AB%AF%E5%9F%BA%E7%A1%80/" class="article-date">
  <time datetime="2020-02-03T01:54:13.000Z" itemprop="datePublished">2020-02-02</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>首先，前端的三个最基本的东西 HTML5、CSS3 和 JavaScript（ES6）是必需要学好的。这其中有很多很多的技术，比如，CSS3 引申出来的 Canvas（位图）、SVG（矢量图） 和 WebGL（3D 图），以及 CSS 的各种图形变换可以让你做出非常丰富的渲染效果和动画效果。</p>
<p>ES6 简直就是把 JavaScript 带到了一个新的台阶，JavaScript 语言的强大，大大释放了前端开发人员的生产力，让前端得以开发更为复杂的代码和程序，于是像 React 和 Vue 这样的框架开始成为前端编程的不二之选。</p>
<p>学习任何知识都要从基础出发，所以会有很大的篇幅在讲各种技术的基础知识和基本原理，尤其是如下的这些知识，都是前端程序员需要一块一块啃掉的硬骨头。</p>
<ul>
<li><strong>JavaScript 的核心原理</strong>。这里会给出好些网上很不错的讲 JavaScript 的原理的文章或图书，你一定要学好语言的特性和其中的各种坑。</li>
<li><strong>浏览器的工作原理</strong>。这也是一块硬骨头，这是前端程序员需要了解和明白的东西，不然，你将无法深入下去。</li>
<li><strong>网络协议 HTTP</strong>。也是要着重了解的，尤其是 HTTP/2，还有 HTTP 的几种请求方式：短连接、长连接、Stream 连接、WebSocket 连接。</li>
<li><strong>前端性能调优</strong>。有了以上的这些基础后，你就可以进入前端性能调优的主题了，你可以很容易上手各种性能调优技术的。</li>
<li><strong>框架学习</strong>。 关键是React 和 Vue 两个框架。就这两个框架来说，Virtual DOM 技术是其底层技术，组件化是其思想，管理组件的状态是其重点。而对于 React 来说，函数式编程又是其编程思想，所以，这些基础技术都是你需要好好研究和学习的。</li>
<li><strong>UI 设计</strong>。设计也是前端需要做的一个事，比如像 Google 的 Material UI，或是比较流行的 Atomic Design 等应该是前端工程师需要学习的。</li>
</ul>
<p>而对于工具类的东西，这里基本没怎么涉及，因为本文主要还是从原理和基础入手。那些工具都很简单，就像学习 Java 没有让你去学习 Maven 一样，因为只要你去动手了，这种知识你自然就会获得，还是把精力重点放在更重要的地方。</p>
<p>下面从前端基础和底层原理开始讲起。先来讲讲 HTML5 相关的内容。</p>
<h1 id="HTML5"><a href="#HTML5" class="headerlink" title="HTML5"></a>HTML5</h1><p>HTML5 主要有以下几本书推荐。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://book.douban.com/subject/25786074/">HTML5 权威指南</a> ，本书面向初学者和中等水平 Web 开发人员，是牢固掌握 HTML5、CSS3 和 JavaScript 的必读之作。书看起来比较厚，是因为里面的代码很多。</li>
<li><a target="_blank" rel="noopener" href="https://book.douban.com/subject/24533314/">HTML5 Canvas 核心技术</a> ，如果你要做 HTML5 游戏的话，这本书必读。</li>
</ul>
<p>对于 SVG、Canvas 和 WebGL 这三个对应于矢量图、位图和 3D 图的渲染来说，给前端开发带来了重武器，很多 HTML5 小游戏也因此蓬勃发展。所以，你可以学习一下。</p>
<p>学习这三个技术，个人觉得最好的地方是 MDN。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://developer.mozilla.org/en-US/docs/Web/SVG">SVG: Scalable Vector Graphics</a></li>
<li><a target="_blank" rel="noopener" href="https://developer.mozilla.org/kab/docs/Web/API/Canvas_API">Canvas API</a></li>
<li><a target="_blank" rel="noopener" href="https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API">The WebGL API: 2D and 3D graphics for the web</a></li>
</ul>
<p>最后是几个资源列表。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/diegocard/awesome-html5">Awesome HTML5</a> 。GitHub 上的 Awesome HTML5，其中有大量的资源和技术文章。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/willianjusten/awesome-svg">Awesome SVG</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/raphamorim/awesome-canvas">Awesome Canvas</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/sjfricke/awesome-webgl">Awesome WebGL</a></li>
</ul>
<h1 id="CSS"><a href="#CSS" class="headerlink" title="CSS"></a>CSS</h1><p>这里再推荐一下 <a target="_blank" rel="noopener" href="https://developer.mozilla.org/zh-CN/docs/Web/CSS">MDN Web Doc - CSS</a> 。个人觉得只要你仔细读一下文档，CSS 并不难学。绝大多数觉得难的，一方面是文档没读透，另一方面是浏览支持的标准不一致。所以，学好 CSS 最关键的还是要仔细地读文档。</p>
<p>之后，在写 CSS 的时候，你会发现，你的 CSS 中有很多看起来相似的东西。你的 DRY - Don’t Repeat Yourself 洁癖告诉你，这是不对的。所以，你需要学会使用 <a target="_blank" rel="noopener" href="http://lesscss.org/">LESS</a> 和 <a target="_blank" rel="noopener" href="http://sass-lang.com">SaSS</a> 这两个 CSS 预处理工具，其可以帮你提高很多效率。</p>
<p>然后，你需要学习一下 CSS 的书写规范，前面的《程序员修养》一文中提到过一些，这里再补充几个。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/necolas/idiomatic-css">Principles of writing consistent, idiomatic CSS</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/grvcoelho/css-styleguide">Opinionated CSS styleguide for scalable applications</a></li>
<li><a target="_blank" rel="noopener" href="https://google.github.io/styleguide/htmlcssguide.html">Google HTML/CSS Style Guide</a></li>
</ul>
<p>如果你需要更有效率，那么你还需要使用一些 CSS Framework，其中最著名的就是 Twitter 公司的 <a target="_blank" rel="noopener" href="http://getbootstrap.com/">Bootstrap</a>，其有很多不错的 UI 组件，页面布局方案，可以让你非常方便也非常快速地开发页面。除此之外，还有，主打清新 UI 的 <a target="_blank" rel="noopener" href="https://semantic-ui.com/">Semantic UI</a> 、主要响应式界面的 <a target="_blank" rel="noopener" href="http://foundation.zurb.com/">Foundation</a> 和基于 Flexbox 的 <a target="_blank" rel="noopener" href="http://bulma.io/">Bulma</a>。</p>
<p>当然，在使用 CSS 之前，你需要把你浏览器中的一些 HTML 标签给标准化掉。所以，推荐几个 Reset 或标准化的 CSS 库：<a target="_blank" rel="noopener" href="https://github.com/necolas/normalize.css">Normalize</a>、<a target="_blank" rel="noopener" href="https://github.com/jgthms/minireset.css">MiniRest.css</a>、<a target="_blank" rel="noopener" href="https://github.com/jonathantneal/sanitize.css/">sanitize.css</a> 和 <a target="_blank" rel="noopener" href="https://github.com/Martin-Pitt/css-unstyle">unstyle.css</a>。</p>
<p>关于更多的 CSS 框架，你可以参看<a target="_blank" rel="noopener" href="https://github.com/troxler/awesome-css-frameworks">Awesome CSS Frameworks</a> 上的列表。</p>
<p>接下来，是几个公司的 CSS 相关实践。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://codepen.io/chriscoyier/post/codepens-css">CodePen’s CSS</a></li>
<li><a target="_blank" rel="noopener" href="http://markdotto.com/2014/07/23/githubs-css/">Github 的 CSS</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@fat/mediums-css-is-actually-pretty-fucking-good-b8e2a6c78b06">Medium’s CSS is actually pretty f***ing good</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/bbc-design-engineering/css-at-bbc-sport-part-1-bab546184e66">CSS at BBC Sport</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.trello.com/refining-the-way-we-structure-our-css-at-trello">Refining The Way We Structure Our CSS At Trello</a></li>
</ul>
<p>最后是一个可以写出可扩展的 CSS 的阅读列表 <a target="_blank" rel="noopener" href="https://github.com/davidtheclark/scalable-css-reading-list">A Scalable CSS Reading List</a> 。</p>
<h1 id="JavaScript"><a href="#JavaScript" class="headerlink" title="JavaScript"></a>JavaScript</h1><p>下面是学习 JavaScript 的一些图书和文章。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://book.douban.com/subject/11874748/">JavaScript: The Good Parts</a> ，中文翻译版为《JavaScript 语言精粹》。这是一本介绍 JavaScript 语言本质的权威图书，值得任何正在或准备从事 JavaScript 开发的人阅读，并且需要反复阅读。学习、理解、实践大师的思想，才可能站在巨人的肩上，才有机会超越大师，这本书就是开始。</li>
<li><a target="_blank" rel="noopener" href="https://book.douban.com/subject/26638316/">Secrets of the JavaScript Ninja</a> ，中文翻译版为《JavaScript 忍者秘籍》，本书是 jQuery 库创始人编写的一本深入剖析 JavaScript 语言的书。适合具备一定 JavaScript 基础知识的读者阅读，也适合从事程序设计工作并想要深入探索 JavaScript 语言的读者阅读。这本书有很多晦涩难懂的地方，需要仔细阅读，反复琢磨。</li>
<li><a target="_blank" rel="noopener" href="https://book.douban.com/subject/25786138/">Effective JavaScript</a> ，Ecma 的 JavaScript 标准化委员会著名专家撰写，作者凭借多年标准化委员会工作和实践经验，深刻辨析 JavaScript 的内部运作机制、特性、陷阱和编程最佳实践，将它们高度浓缩为极具实践指导意义的 68 条精华建议。</li>
<li>接下来是 ES6 的学习，这里给三个学习手册源。<ul>
<li><a target="_blank" rel="noopener" href="https://hacks.mozilla.org/category/es6-in-depth/">ES6 in Depth</a>，InfoQ 上有相关的中文版 - <a target="_blank" rel="noopener" href="http://www.infoq.com/cn/es6-in-depth/">ES6 深入浅出</a>。还可以看看 <a target="_blank" rel="noopener" href="https://codetower.github.io/es6-features?utm_source=mybridge&utm_medium=email&utm_campaign=read_more">A simple interactive ES6 Feature list</a> ，或是看一下 <a target="_blank" rel="noopener" href="http://es6.ruanyifeng.com">阮一峰翻译的 ES6 的教程</a> 。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/addyosmani/es6-tools">ECMAScript 6 Tools</a> ，这是一堆 ES6 工具的列表，可以帮助你提高开发效率。</li>
<li><a target="_blank" rel="noopener" href="https://mbeaudru.github.io/modern-js-cheatsheet/">Modern JS Cheatsheet</a> ，这个 Cheatsheet 在 GitHub 上有 1 万 6 千颗星，你就可见其影响力了。</li>
</ul>
</li>
<li>然后，还有一组很不错的《<a target="_blank" rel="noopener" href="https://github.com/getify/You-Dont-Know-JS">You Don’t Know JS 系列</a>》 的书。<ul>
<li><strong>You Don’t Know JS: “Up &amp; Going”</strong></li>
<li><strong>You Don’t Know JS: “Scope &amp; Closures”</strong></li>
<li><strong>You Don’t Know JS: “this &amp; Object Prototypes”</strong></li>
<li><strong>You Don’t Know JS: “Types &amp; Grammar”</strong></li>
<li><strong>You Don’t Know JS: “Async &amp; Performance”</strong></li>
<li><strong>You Don’t Know JS: “ES6 &amp; Beyond”</strong></li>
</ul>
</li>
<li>接下来是一些和编程范式相关的文章。<ul>
<li><a target="_blank" rel="noopener" href="https://auth0.com/blog/glossary-of-modern-javascript-concepts/">Glossary of Modern JavaScript Concepts: Part 1</a> ，首先推荐这篇文章，其中收集了一些编程范式方面的内容，比如纯函数、状态、可变性和不可变性、指令型语言和声明式语言、函数式编程、响应式编程、函数式响应编程。</li>
<li><a target="_blank" rel="noopener" href="https://auth0.com/blog/glossary-of-modern-javascript-concepts-part-2/">Glossary of Modern JavaScript Concepts: Part 2</a> ，在第二部分中主要讨论了作用域和闭包，数据流，变更检测，组件化……</li>
</ul>
</li>
<li>下面三篇文章是德米特里·索什尼科夫（Dmitry Soshnikov）个人网站上三篇讲 JavaScript 内在的文章。<ul>
<li><a target="_blank" rel="noopener" href="http://dmitrysoshnikov.com/ecmascript/javascript-the-core-2nd-edition/">JavaScript. The Core: 2nd Edition</a></li>
<li><a target="_blank" rel="noopener" href="http://dmitrysoshnikov.com/ecmascript/javascript-the-core/">JavaScript. The Core (older ES3 version)</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@DmitrySoshnikov/js-scope-static-dynamic-and-runtime-augmented-5abfee6223fe">JS scope: static, dynamic, and runtime-augmented</a></li>
</ul>
</li>
<li>“<strong>How JavaScript Works</strong>” 是一组非常不错的文章（可能还没有写完），强烈推荐。这一系列的文章是 SessionStake 的 CEO 写的，现在有 13 篇，可能还没有写完。这个叫 <a target="_blank" rel="noopener" href="https://blog.sessionstack.com/@zlatkov">亚历山大·兹拉特科夫（Alexander Zlatkov）</a> 的 CEO 太猛了。<ul>
<li><a target="_blank" rel="noopener" href="https://blog.sessionstack.com/how-does-javascript-actually-work-part-1-b0bacc073cf">An overview of the engine, the runtime, and the call stack</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.sessionstack.com/how-javascript-works-inside-the-v8-engine-5-tips-on-how-to-write-optimized-code-ac089e62b12e">Inside the V8 engine + 5 tips on how to write optimized code</a> ，了解 V8 引擎。这里，也推荐 <a target="_blank" rel="noopener" href="https://medium.com/dailyjs/understanding-v8s-bytecode-317d46c94775">Understanding V8’s Bytecode</a> 这篇文章可以让你了解 V8 引擎的底层字节码。</li>
<li><a target="_blank" rel="noopener" href="https://blog.sessionstack.com/how-javascript-works-memory-management-how-to-handle-4-common-memory-leaks-3f28b94cfbec">Memory management + how to handle 4 common memory leaks</a> ，内存管理和 4 种常见的内存泄露问题。</li>
<li><a target="_blank" rel="noopener" href="https://blog.sessionstack.com/how-javascript-works-event-loop-and-the-rise-of-async-programming-5-ways-to-better-coding-with-2f077c4438b5">Event loop and the rise of Async programming + 5 ways to better coding with async/await</a> ，Event Loop 和异步编程。</li>
<li><a target="_blank" rel="noopener" href="https://blog.sessionstack.com/how-javascript-works-deep-dive-into-websockets-and-http-2-with-sse-how-to-pick-the-right-path-584e6b8e3bf7">Deep dive into WebSockets and HTTP/2 with SSE + how to pick the right path</a> ，WebSocket 和 HTTP/2。</li>
<li><a target="_blank" rel="noopener" href="https://blog.sessionstack.com/how-javascript-works-a-comparison-with-webassembly-why-in-certain-cases-its-better-to-use-it-d80945172d79">A comparison with WebAssembly + why in certain cases it’s better to use it over JavaScript</a> ，JavaScript 内在原理。</li>
<li><a target="_blank" rel="noopener" href="https://blog.sessionstack.com/how-javascript-works-the-building-blocks-of-web-workers-5-cases-when-you-should-use-them-a547c0757f6a">The building blocks of Web Workers + 5 cases when you should use them</a> ，Web Workers 技术。</li>
<li><a target="_blank" rel="noopener" href="https://blog.sessionstack.com/how-javascript-works-service-workers-their-life-cycle-and-use-cases-52b19ad98b58">Service Workers, their lifecycle and use cases</a> ，Service Worker 技术。</li>
<li><a target="_blank" rel="noopener" href="https://blog.sessionstack.com/how-javascript-works-the-mechanics-of-web-push-notifications-290176c5c55d">The mechanics of Web Push Notifications</a> ，Web 端 Push 通知技术。</li>
<li><a target="_blank" rel="noopener" href="https://blog.sessionstack.com/how-javascript-works-tracking-changes-in-the-dom-using-mutationobserver-86adc7446401">Tracking changes in the DOM using MutationObserver</a> ，Mutation Observer 技术。</li>
<li><a target="_blank" rel="noopener" href="https://blog.sessionstack.com/how-javascript-works-the-rendering-engine-and-tips-to-optimize-its-performance-7b95553baeda">The rendering engine and tips to optimize its performance</a> ，渲染引擎和性能优化。</li>
<li><a target="_blank" rel="noopener" href="https://blog.sessionstack.com/how-javascript-works-inside-the-networking-layer-how-to-optimize-its-performance-and-security-f71b7414d34c">Inside the Networking Layer + How to Optimize Its Performance and Security</a> ，网络性能和安全相关。</li>
<li><a target="_blank" rel="noopener" href="https://blog.sessionstack.com/how-javascript-works-under-the-hood-of-css-and-js-animations-how-to-optimize-their-performance-db0e79586216">Under the hood of CSS and JS animations + how to optimize their performance</a> ，CSS 和 JavaScript 动画性能优化。</li>
</ul>
</li>
<li>接下来是 Google Chrome 工程经理 <a target="_blank" rel="noopener" href="https://medium.com/@addyosmani">阿迪·奥斯马尼（Addy Osmani）</a> 的几篇 JavaScript 性能相关的文章，也是非常好的。<ul>
<li><a target="_blank" rel="noopener" href="https://medium.com/dev-channel/the-cost-of-javascript-84009f51e99e">The Cost Of JavaScript</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/reloading/javascript-start-up-performance-69200f43b201">JavaScript Start-up Performance</a></li>
</ul>
</li>
<li>其它与 JavaScript 相关的资源。<ul>
<li><a target="_blank" rel="noopener" href="https://mathiasbynens.be/notes/javascript-unicode">JavScript has Unicode Problem</a> ，这是一篇很有价值的 JavaScript 处理 Unicode 的文章。</li>
<li><a target="_blank" rel="noopener" href="https://mgechev.github.io/javascript-algorithms/index.html">JavaScript Algorithms</a> ，用 JavaScript 实现的各种基础算法库。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/Chalarangelo/30-seconds-of-code">JavaScript 30 秒代码</a> ，一堆你可以在 30 秒内看懂各种有用的 JavaScript 的代码，在 GitHub 上有 2 万颗星了。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/denysdovhan/wtfjs">What the f*ck JavaScript</a> ，一堆 JavaScript 搞笑和比较 tricky 的样例。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/airbnb/javascript">Airbnb JavaScript Style Guide</a> ，Airbnb 的 JavaScript 的代码规范，GitHub 上有 7 万多颗星。</li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=hO7mzO83N1Q">JavaScript Patterns for 2017</a> ，YouTube 上的一个 JavaScript 模式分享，值得一看。</li>
</ul>
</li>
</ul>
<h1 id="浏览器原理"><a href="#浏览器原理" class="headerlink" title="浏览器原理"></a>浏览器原理</h1><p>你需要了解一下浏览器是怎么工作的，所以，你必需要看《<a target="_blank" rel="noopener" href="http://taligarsiel.com/Projects/howbrowserswork1.htm">How browsers work</a>》。这篇文章受众之大，后来被人重新整理并发布为《<a target="_blank" rel="noopener" href="https://www.html5rocks.com/en/tutorials/internals/howbrowserswork/">How Browsers Work: Behind the scenes of modern web browsers</a>》，其中还包括中文版。这篇文章非常非常长，所以，你要有耐心看完。如果你想看个精简版的，可以看《<a target="_blank" rel="noopener" href="https://coolshell.cn/articles/9666.html">浏览器的渲染原理简介</a>》或是看一下<a target="_blank" rel="noopener" href="http://arvindr21.github.io/howBrowserWorks">这个幻灯片</a>。</p>
<p>然后，是对 Virtual DOM 的学习。Virtual DOM 是 React 的一个非常核心的技术细节，它也是前端渲染和性能的关键技术。所以，你有必要要好好学习一下这个技术的实现原理和算法。当然，前提条件是你需要学习过前面所推荐过的浏览器的工作原理。下面是一些不错的文章可以帮你学习这一技术。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://medium.com/@deathmood/how-to-write-your-own-virtual-dom-ee74acc13060">How to write your own Virtual DOM</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@deathmood/write-your-virtual-dom-2-props-events-a957608f5c76">Write your Virtual DOM 2: Props &amp; Events</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@gethylgeorge/how-virtual-dom-and-diffing-works-in-react-6fc805f9f84e">How Virtual-DOM and diffing works in React</a></li>
<li><a target="_blank" rel="noopener" href="https://medium.com/@rajaraodv/the-inner-workings-of-virtual-dom-666ee7ad47cf">The Inner Workings Of Virtual DOM</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/livoras/blog/issues/13">深度剖析：如何实现一个 Virtual DOM 算法</a></li>
<li>以及两个 Vitual-DOM 实现供你参考：<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/Matt-Esch/virtual-dom">Matt-Esch/Virtual-DOM</a></li>
<li><a target="_blank" rel="noopener" href="https://maquettejs.org/">Maquette</a></li>
</ul>
</li>
</ul>
<h1 id="网络协议"><a href="#网络协议" class="headerlink" title="网络协议"></a>网络协议</h1><ul>
<li><p><a target="_blank" rel="noopener" href="https://book.douban.com/subject/25856314/">High Performance Browser Networking</a> ，本书是谷歌公司高性能团队核心成员的权威之作，堪称实战经验与规范解读完美结合的产物。本书目标是涵盖 Web 开发者技术体系中应该掌握的所有网络及性能优化知识。</p>
<p>全书以性能优化为主线，从 TCP、UDP 和 TLS 协议讲起，解释了如何针对这几种协议和基础设施来优化应用。然后深入探讨了无线和移动网络的工作机制。最后，揭示了 HTTP 协议的底层细节，同时详细介绍了 HTTP 2.0、 XHR、SSE、WebSocket、WebRTC 和 DataChannel 等现代浏览器新增的能力。</p>
</li>
<li><p>另外，<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/HTTP/2">HTTP/2</a>也是 HTTP 的一个新的协议，于 2015 年被批准通过，现在基本上所有的主流浏览器都默认启用这个协议。所以，你有必要学习一下这个协议。下面相关的学习资源。</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://legacy.gitbook.com/book/ye11ow/http2-explained/details">Gitbook - HTTP/2 详解</a></li>
<li><a target="_blank" rel="noopener" href="http://daniel.haxx.se/http2/">http2 explained</a>（<a target="_blank" rel="noopener" href="https://www.gitbook.com/book/ye11ow/http2-explained/details">中译版</a>）</li>
<li><a target="_blank" rel="noopener" href="https://cascadingmedia.com/insites/2015/03/http-2.html">HTTP/2 for a Faster Web</a></li>
<li><a target="_blank" rel="noopener" href="https://www.nginx.com/wp-content/uploads/2015/09/NGINX_HTTP2_White_Paper_v4.pdf">Nginx HTTP/2 白皮书</a></li>
<li>HTTP/2 的两个 RFC：<ul>
<li><a target="_blank" rel="noopener" href="https://httpwg.org/specs/rfc7540.html">RFC 7540 - Hypertext Transfer Protocol Version 2 (HTTP/2)</a> ，HTTP/2 的协议本身。</li>
<li><a target="_blank" rel="noopener" href="https://httpwg.org/specs/rfc7541.html">RFC 7541 - HPACK: Header Compression for HTTP/2</a> ，HTTP/2 的压缩算法。</li>
</ul>
</li>
</ul>
</li>
<li><p>新的 HTML5 支持 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/WebSocket">WebSocket</a>，所以，这也是你要学的一个重要协议。</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://www.websocket.org/quantum.html">HTML5 WebSocket: A Quantum Leap in Scalability for the Web</a> ，这篇文章比较了 HTTP 的几种链接方式，Polling、Long Polling 和 Streaming，并引入了终级解决方案 WebSocket。你知道的，了解一个技术的缘由是非常重要的。</li>
<li><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/12555043/my-understanding-of-http-polling-long-polling-http-streaming-and-websockets">StackOverflow: My Understanding of HTTP Polling, Long Polling, HTTP Streaming and WebSockets</a> ，这是 StackOverflow 上的一个 HTTP 各种链接方式的比较，也可以让你有所认识。</li>
<li><a target="_blank" rel="noopener" href="http://blog.teamtreehouse.com/an-introduction-to-websockets">An introduction to Websockets</a> ，一个 WebSocket 的简单教程。</li>
<li><a target="_blank" rel="noopener" href="https://github.com/facundofarias/awesome-websockets">Awesome Websockets</a> ，GitHub 的 Awesome 资源列表。</li>
<li>一些和 WebSocket 相关的想法，可以开阔你的思路：<ul>
<li><a target="_blank" rel="noopener" href="https://www.html5rocks.com/en/tutorials/websockets/basics/">Introducing WebSockets: Bringing Sockets to the Web</a></li>
<li><a target="_blank" rel="noopener" href="http://lucumr.pocoo.org/2012/9/24/websockets-101/">Websockets 101</a></li>
<li><a target="_blank" rel="noopener" href="https://banksco.de/p/state-of-realtime-web-2016.html">Real-Time Web by Paul Banks</a></li>
<li><a target="_blank" rel="noopener" href="https://samsaffron.com/archive/2015/12/29/websockets-caution-required">Are WebSockets the future?</a></li>
</ul>
</li>
</ul>
</li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%89%8D%E7%AB%AF/" rel="tag">前端</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
    <article
  id="post-为什么说GraphQL可以取代REST-API"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/02/01/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AF%B4GraphQL%E5%8F%AF%E4%BB%A5%E5%8F%96%E4%BB%A3REST-API/"
    >为什么说GraphQL可以取代REST_API</a> 
</h2>
 

    </header>
     
    <div class="article-meta">
      <a href="/2020/02/01/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AF%B4GraphQL%E5%8F%AF%E4%BB%A5%E5%8F%96%E4%BB%A3REST-API/" class="article-date">
  <time datetime="2020-02-02T00:03:02.000Z" itemprop="datePublished">2020-02-01</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>几年前，我在 DocuSign 带领了一个开发团队，任务是重写一个有数千万个用户在使用的 Web 应用程序。当时还没有可以支持前端的 API，因为从一开始，Web 应用程序就是一个.NET 大单体。西雅图的 API 团队在将拆分单体，并逐步暴露出 RESTful API。这个 API 团队由两名工程师组成，发布周期为一个月，而我们在旧金山的前端团队每周都会发布新版本。</p>
<p>API 团队的发布周期太长，因为很多（几乎所有）功能都必须进行手动测试，这是可以理解的。它毕竟是一个单体，而且没有适当的自动化测试——如果他们修改了一个地方，不知道在应用程序的其他地方会出现什么问题。</p>
<p>我记得有一次，我们的前端团队面临为某大会交付新版本的压力，但我们忘记跟进一个重要的 API 变更，这个变更未被包含在即将发布的 API 版本中。我们要么一直等待，直到错过截止日期，要么有人愿意放弃优先权，以便让我们的变更包括在即将发布的版本中。所幸的是，这个变更最后被包含在新版本中，我们也及时发布了新的前端版本。我真的希望当时我们已经使用了 GraphQL，因为它可以消除对外部团队及其发布周期的重度依赖。</p>
<p>在这篇文章中，我将介绍 GraphQL 的优势，以及为什么它会变得如此受欢迎。</p>
<p>很多公司已经在内部从 RESTful 转向了 GraphQL API：IBM、Twitter、Walmart Labs、纽约时报、Intuit、Coursera，等等。</p>
<p>其他一些公司不仅是在内部而且还将外部 API 也转为 GraphQL：AWS、Yelp、GitHub、Facebook 和 Shopify，等等。GitHub 甚至打算停止使用 REST API，他们的 v4 版本只使用 GraphQL。</p>
<p>GraphQL 究竟是一个炒作流行语还是真正会带来一场变革？有趣的是，我之前列出的大多数从 GraphQL 获益的公司都有以下这些共同点。</p>
<ul>
<li>他们拥有包括移动端在内的多个客户端；</li>
<li>他们正在转向或者已经采用了微服务架构；</li>
<li>他们的遗留 REST API 数量暴增，变得十分复杂；</li>
<li>他们希望消除客户端团队对 API 团队的依赖；</li>
<li>他们注重良好的 API 文档和开发者体验。</li>
</ul>
<p>GitHub 工程团队表明了他们的动机：</p>
<blockquote>
<p>“GraphQL 弥合了发布的内容与可以使用的内容之间的差距。我们真的很期待能够同时发布它们。GraphQL 代表了 API 开发的巨大飞跃。类型安全、内省、生成文档和可预测的响应都为我们平台的维护者和消费者带来了好处。我们期待着由 GraphQL 提供支持的平台进入新时代，也希望你们也这样做！”</p>
</blockquote>
<p>GraphQL 加速了开发速度，提升了开发者体验，并提供了更好的工具。我并不是说这绝对是这样的，但我会尽力说明 GraphQL 与 REST 之间的争论点及其原因。</p>
<h2 id="超级数据聚合器"><a href="#超级数据聚合器" class="headerlink" title="超级数据聚合器"></a>超级数据聚合器</h2><p>我是 Indeed（世界排名第一的求职网站）的软件工程负责人，所以让我们先来看看 Indeed.com 的主页和职位查询结果页面。它们分别发出了 10 和 11 个 XHR 请求。</p>
<p>需要注意的是，在 REST 中使用 POST 进行页面浏览并不是很“正规”。</p>
<p>以下是其中的一些调用：</p>
<ul>
<li>GET <a target="_blank" rel="noopener" href="https://inbox.indeed.com/api/getConversationCount">https://inbox.indeed.com/api/getConversationCount</a></li>
<li>GET <a target="_blank" rel="noopener" href="https://www.indeed.com/rpc/jobdescs">https://www.indeed.com/rpc/jobdescs</a></li>
<li>GET <a target="_blank" rel="noopener" href="https://www.indeed.com/rpc/vjslog">https://www.indeed.com/rpc/vjslog</a></li>
<li>GET <a target="_blank" rel="noopener" href="https://www.indeed.com/rpc/preccount">https://www.indeed.com/rpc/preccount</a></li>
<li>POST <a target="_blank" rel="noopener" href="https://www.indeed.com/rpc/jobalert">https://www.indeed.com/rpc/jobalert</a></li>
<li>POST <a target="_blank" rel="noopener" href="https://www.indeed.com/rpc/count">https://www.indeed.com/rpc/count</a></li>
</ul>
<p>在使用 GraphQL 时，上面的这些请求可以被包含在单个查询和单个请求中。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">query HomePage &#123;</span><br><span class="line">  getConversationCount(...) &#123;</span><br><span class="line">     ...</span><br><span class="line">  &#125;</span><br><span class="line">  jobdescs(...) &#123;</span><br><span class="line">     ...</span><br><span class="line">  &#125;</span><br><span class="line">  vjslog(...) &#123;</span><br><span class="line">     ...</span><br><span class="line">  &#125;</span><br><span class="line">  preccount(...) &#123;</span><br><span class="line">     …</span><br><span class="line">  &#125;</span><br><span class="line">  jobalert(...) &#123;</span><br><span class="line">     …</span><br><span class="line">  &#125;</span><br><span class="line">  count(...) &#123;</span><br><span class="line">     …</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>响应结果可能是这样的</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">&quot;data&quot;</span>: &#123;</span><br><span class="line">    <span class="attr">&quot;getConversationCount&quot;</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;vjslog&quot;: [...],</span><br><span class="line">    &quot;preccount&quot;: [...],</span><br><span class="line">      &quot;jobalert&quot;: [...],</span><br><span class="line">    &quot;count&quot;: &#123;&#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;errors&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通常，单个调用比多个调用更方便、更有效，因为它需要更少的代码和更少的网络开销。来自 PayPal 过程团队的开发体验还证实，很多 UI 工作实际上不是 UI 工作，而是其他任务，例如前端和后端之间的通信：</p>
<blockquote>
<p>“我们发现，UI 开发人员实际用于构建 UI 的时间不到三分之一，剩下的时间用于确定在何处以及如何获取数据、过滤 / 映射数据以及编排 API 调用，还有一些用于构建和部署。”</p>
</blockquote>
<p>需要注意的是，有实时使多个请求也是有必要的，例如多个单独的请求可以快速且异步独立地获取不同的数据，如果采用了微服务架构，它们会增加部署灵活性，而且它们的故障点是多个，而不是一个。</p>
<p>此外，如果页面是由多个团队开发的，GraphQL 提供了一个功能，可以将查询分解称为片段。稍后我们将详细介绍这方面的内容。</p>
<p>从更大的角度来看，GraphQL API 的主要应用场景是 API 网关，在客户端和服务之间提供了一个抽象层。</p>
<p>微服务架构很好，但也存在一些问题，GraphQL 可以用来解决这些问题。以下是来自 IBM 在微服务架构中使用 GraphQL 的经验：</p>
<blockquote>
<p>“总的来说，GraphQL 微服务的开发和部署都非常快。他们 5 月份开始开发，7 月份就进入了生产环境。因为他们不需要征得许可，直接开干。他强烈推荐这个方案，比开会讨论好太多了。”</p>
</blockquote>
<p>接下来，让我们逐一讨论 GraphQL 的每一个好处。</p>
<h2 id="提高开发速度"><a href="#提高开发速度" class="headerlink" title="提高开发速度"></a>提高开发速度</h2><p>首先，GraphQL 有助于减少发出的请求数。通过单个调用来获取所需的数据比使用多个请求要容易得多。从工程师的角度来看，这加快了开发速度。后面我会解释更多有关为什么会提升开发速度的原因，但现在我想先说明另一个问题。</p>
<p>后端和客户端团队需要通过密切合作来定义 API、测试它们，并做出更改。前端、移动、物联网（例如 Alexa）等客户端团队不断迭代功能，并尝试使用新的 UX 和设计。他们的数据需求经常发生变化，后端团队必须跟上他们的节奏。如果客户端和后端代码由同一团队负责，那么问题就没那么严重了。Indeed 的大多数工程团队都是由全栈工程师组成，但并非全部都是这样。对于非全栈团队，客户端团队经常因为依赖了后端团队开发速度受到影响。</p>
<p>当我转到 Job Seeker API 团队时，移动团队开始我们的开发进度。我们之间有很多关于参数、响应字段和测试的事情需要沟通。</p>
<p>在使用了 GraphQL 之后，客户端工程师就可以完全控制前端，不需要依赖任何人，因为他们可以告诉后端他们需要什么以及响应结构应该是怎样的。他们使用了 GraphQL 查询，它们会告诉后端 API 应该要提供哪些数据。</p>
<p>客户端工程师不需要花时间让后端 API 团队添加或修改某些内容。GraphQL 具有自文档的特点，所以可以节省一些用于查找文档以便了解如何使用 API 的时间。我相信大多数人曾经在找出确切的请求参数方面浪费了很多时间。GraphQL 协议本身及其社区在文档方面为我们提供了一些有用的工具。在某些情况下，可以从模式自动生成文档。其他时候，只需使用 GraphiQL Web 界面就足以编写一个查询。</p>
<p>来自纽约时报的工程师表示，他们在转到 GraphQL 和 Relay 之后，在做出变更时不需要改太多的东西：</p>
<blockquote>
<p>“当我们想要更新所有产品的设计时，不再需要修改多个代码库。这就是我们想要的。我们认为 Relay 和 GraphQL 是帮助我们实现这个伟大目标的完美工具。”</p>
</blockquote>
<p>当一家公司已经拥有大量 GraphQL API，然后有人想出了一个新的产品创意，这也是我最喜欢 GraphQL 的应用场景。使用已有的 GraphQL API 实现原型比调用各种 REST 端点（将提供太少或太多的数据）或为新应用程序构建新的 REST API 要快得多。</p>
<p>开发速度的提升与开发者体验的提升密切相关。</p>
<h2 id="提升开发者体验"><a href="#提升开发者体验" class="headerlink" title="提升开发者体验"></a>提升开发者体验</h2><p>GraphQL 提供了更好的开发者体验（DX），开发者将花更少的时间思考如何获取数据。在使用 Apollo 时，他们只需要在 UI 中声明数据。数据和 UI 放在一起，阅读代码和编写代码都变得更方便。</p>
<p>通常，在开发 UI 时需要在 UI 模板、客户端代码和 UI 样式之间跳转。GraphQL 允许工程师在客户端开发 UI，减少摩擦，因为工程师在添加或修改代码时无需在文件之间切换。如果你熟悉 React，这里有一个很好的比喻：GraphQL 之于数据，就像 React 之于 UI。</p>
<p>下面是一个简单的示例，UI 中直接包含了属性名称<code>launch.name</code>和 <code>launch.rocket.name</code> 。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">const GET_LAUNCHES = gql`</span><br><span class="line">  query launchList($after: String) &#123;</span><br><span class="line">    launches(after: $after) &#123;</span><br><span class="line">      launches &#123;</span><br><span class="line">        id</span><br><span class="line">        name</span><br><span class="line">        isBooked</span><br><span class="line">        rocket &#123;</span><br><span class="line">          id</span><br><span class="line">          name</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">`;</span><br><span class="line"> </span><br><span class="line">export default function Launches() &#123;</span><br><span class="line">  return (</span><br><span class="line">    &lt;Query query=&#123;GET_LAUNCHES&#125;&gt;</span><br><span class="line">      &#123;(&#123; data, loading, error &#125;) =&gt; &#123;</span><br><span class="line">        if (loading) return &lt;Loading /&gt;;</span><br><span class="line">        if (error) return &lt;p&gt;ERROR&lt;/p&gt;;</span><br><span class="line"> </span><br><span class="line">        return (</span><br><span class="line">            &lt;div&gt;</span><br><span class="line">            &#123;data.launches.launches.map(launch =&gt; (</span><br><span class="line">                &lt;div</span><br><span class="line">                  key=&#123;launch.id&#125;</span><br><span class="line">                &gt;&#123;launch.name&#125;&lt;br/&gt;</span><br><span class="line">                Rocket: &#123;launch.rocket.name&#125;</span><br><span class="line">                &lt;/div&gt;</span><br><span class="line">              ))&#125;</span><br><span class="line">          &lt;/div&gt;</span><br><span class="line">        );</span><br><span class="line">      &#125;&#125;</span><br><span class="line">    &lt;/Query&gt;</span><br><span class="line">  );</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>使用这种方法，可以非常容易地修改或向 UI 或查询（gql）添加新字段。React 组件的可移植性更强了，因为它们描述了所需的所有数据。</p>
<p>如前所述， GraphQL 提供了更好的文档，而且还有一个叫作 GraphiQL 的 IDE：</p>
<p>前端工程师很喜欢 GraphiQL，下面引用 Indeed 的一位高级工程师说过的话：</p>
<blockquote>
<p>“我认为开发体验中最好的部分是能够使用 GraphiQL。对我来说，与典型的 API 文档相比，这是一种编写查询更有效的辅助方法”。</p>
</blockquote>
<p>GraphQL 的另一个很棒的功能是片段，因为它允许我们在更高的组件层面重用查询。</p>
<p>这些功能改善了开发者体验，让开发人员更快乐，更不容易出现 JavaScript 疲劳。</p>
<h2 id="提升性能"><a href="#提升性能" class="headerlink" title="提升性能"></a>提升性能</h2><p>工程师并不是唯一从 GraphQL 中受益的人。用户也会从中受益，因为应用程序的性能获得了提升（可以感知到的）：</p>
<p>\1. 减少了有效载荷（客户端只需要必要的东西）；</p>
<p>\2. 多个请求合并为一个请求可减少网络开销；</p>
<p>\3. 使用工具可以更轻松地实现客户端缓存和后端批处理和后端缓存；<br>\4. 预取；<br>\5. 更快的 UI 更新。</p>
<p>PayPal 使用 GraphQL 重新设计了他们的结账流程。下面是来自用户的反馈：</p>
<blockquote>
<p>“REST 的原则并没有为 Web 和移动应用及其用户的需求考虑，这个在结账优化交易中体现得尤为明显。用户希望能够尽快完成结账，如果应用程序使用了很多原子 REST API，就需要在客户端和服务器之间进行多次往返以获取数据。我们的结账每次往返网络时间至少需要 700 毫秒，这还不包括服务器处理请求的时间。每次往返都会导致渲染变慢，用户体验不好，结算转换率也会降低。”</p>
</blockquote>
<p>性能改进中有一项是“多个请求组合成一个请求可以减少网络开销”。对于 HTTP/1 而言，这是非常正确的，因为它没有 HTTP/2 那样的多路复用机制。但尽管 HTTP/2 提供的多路复用机制有助于优化单独的请求，但它对于图遍历（获取相关或嵌套对象）并没有实际帮助。让我们来看一看 REST 和 GraphQL 是如何处理嵌套对象和其他复杂请求的。</p>
<h2 id="标准化和简化复杂的-API"><a href="#标准化和简化复杂的-API" class="headerlink" title="标准化和简化复杂的 API"></a>标准化和简化复杂的 API</h2><p>通常，客户端会发出复杂的请求来获取有序、排好序、被过滤过的数据或子集（用于分页），或者请求嵌套对象。GraphQL 支持嵌套数据和其他难以使用标准 REST API 资源（也叫端点或路由）实现的查询。</p>
<p>例如，我们假设有三种资源：用户、订阅和简历。工程师需要按顺序进行两次单独的调用（这会降低性能）来获取一个用户简历，首先需要通过调用获取用户资源，拿到简历 ID，然后再使用简历 ID 来获取简历数据。对于订阅来说也是一样的。</p>
<p>1.GET /users/123：响应中包含了简历 ID 和工作岗位通知订阅的 ID 清单；<br>2.GET /resumes/ABC：响应中包含了简历文本——依赖第一个请求；<br>3.GET /subscriptions/XYZ：响应中包含了工作岗位通知的内容和地址——依赖第一个请求。</p>
<p>上面的示例很糟糕，原因有很多：客户端可能会获得太多数据，并且必须等待相关的请求完成了以后才能继续。此外，客户端需要实现如何获取子资源（例如建立或订阅）和过滤。</p>
<p>想象一下，一个客户端可能只需要第一个订阅的内容和地址以及简历中的当前职位，另一个客户端可能需要所有订阅和整个简历列表。所以，如果使用 REST API，对第一个客户端来说有点不划算。</p>
<p>另一个例子：用户表里可能会有用户的名字和姓氏、电子邮件、简历、地址、电话、社会保障号、密码（当然是经过混淆的）和其他私人信息。并非每个客户端都需要所有字段，有些应用程序可能只需要用户电子邮件，所以向这些应用程序发送社会保障号等信息就不太安全。</p>
<p>当然，为每个客户端创建不同的端点也是不可行的，例如 /api/v1/users 和 /api/v1/usersMobile。事实上，各种客户端通常都有不同的数据需求：/api/v1/userPublic、/api/v1/userByName、/api/v1/usersForAdmin，如果这样的话，端点会呈指数级增长。</p>
<p>GraphQL 允许客户要求 API 发送他们想要的字段，这将使后端工作变得更加容易：/api/gql——所有客户端只需要这个端点。</p>
<p>注意：对于 REST 和 GraphQL，后端都需要使用访问控制级别。</p>
<p>或者可以使用旧 REST 来实现 GraphQL 的很多功能。但是这样要付出什么代价？后端可以支持复杂的 RESTful 请求，这样客户端就可以使用字段和嵌套对象进行调用：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /users/?fields=name,address&amp;include=resumes,subscriptions</span><br></pre></td></tr></table></figure>

<p>上面的请求将比使用多个 REST 请求更好，但它不是标准化的，不受客户端库支持，而且这样的代码也更难编写和维护。对于相对复杂的 API，工程师需要在查询中使用自己的查询字符串参数约定，最终得到类似 GraphQL 的东西。既然 GraphQL 已经提供了标准和库，为什么还要基于 REST 设计自己的查询约定呢？</p>
<p>将复杂的 REST 端点与以下的 GraphQL 嵌套查询进行对比，嵌套查询使用了更多的过滤条件，例如“只要给我前 X 个对象”和“按时间按升序排列”（可以添加无限制的过滤选项）：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    user (id: 123) &#123;</span><br><span class="line">        id</span><br><span class="line">        firstName</span><br><span class="line">        lastName</span><br><span class="line">        address &#123;</span><br><span class="line">            city</span><br><span class="line">            country</span><br><span class="line">            zip</span><br><span class="line">        &#125;</span><br><span class="line">        resumes (first: 1, orderBy: time_ASC) &#123;</span><br><span class="line">            text</span><br><span class="line">            title</span><br><span class="line">            blob</span><br><span class="line">            time</span><br><span class="line">          &#125;</span><br><span class="line">          subscriptions(first: 10) &#123;</span><br><span class="line">            what</span><br><span class="line">            where</span><br><span class="line">            time</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在使用 GraphQL 时，我们可以在查询中保留嵌套对象，对于每个对象，我们将精确地获得我们需要的数据，不多也不少。</p>
<p>响应消息的数据格式反映了请求查询的结构，如下所示：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;data&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;user&quot;</span>: &#123;</span><br><span class="line">            <span class="attr">&quot;id&quot;</span>: <span class="number">123</span>,</span><br><span class="line">            <span class="attr">&quot;firstName&quot;</span>: <span class="string">&quot;Azat&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;lastName&quot;</span>: <span class="string">&quot;Mardan&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;address&quot;</span>: &#123;</span><br><span class="line">                <span class="attr">&quot;city&quot;</span>: <span class="string">&quot;San Francisco&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;country&quot;</span>: <span class="string">&quot;US&quot;</span>,</span><br><span class="line">                <span class="attr">&quot;zip&quot;</span>: <span class="string">&quot;94105&quot;</span></span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;resumes&quot; [</span><br><span class="line">                  &#123;</span><br><span class="line">                    <span class="attr">&quot;text&quot;</span>: <span class="string">&quot;some text here...&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;title&quot;</span>: <span class="string">&quot;My Resume&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;blob&quot;</span>: <span class="string">&quot;&lt;BLOB&gt;&quot;</span>,</span><br><span class="line">                    <span class="attr">&quot;time&quot;</span>: <span class="string">&quot;2018-11-13T21:23:16.000Z&quot;</span></span><br><span class="line">                  &#125;,</span><br><span class="line">            ],</span><br><span class="line">              &quot;subscriptions&quot;: [ ]</span><br><span class="line">        &#125;,</span><br><span class="line">    &quot;errors&quot;: []    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>相比复杂的 REST 端点，使用 GraphQL 的另一个好处是提高了安全性。这是因为 URL 经常会被记录下来，而 RESTful GET 端点依赖于查询字符串（是 URL 的一部分）。这可能会暴露敏感数据，所以 RESTful GET 请求的安全性低于 GraphQL 的 POST 请求。我打赌这就是为什么 Indeed 主页会使用 POST 发出“阅读”页面请求。</p>
<p>使用 GraphQL 可有更容易地实现分页等关键功能，这要归功于查询以及 BaaS 提供商提供的标准，以及后端的实现和客户端库使用的标准。</p>
<h2 id="改进的安全性、强类型和验证"><a href="#改进的安全性、强类型和验证" class="headerlink" title="改进的安全性、强类型和验证"></a>改进的安全性、强类型和验证</h2><p>GraphQL 的 schema 与语言无关。对前面的示例进行扩展，我们可以在 schema 中定义 Address 类型：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">type Address &#123;</span><br><span class="line">    city: String!</span><br><span class="line">    country: String!</span><br><span class="line">    zip: Int</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>String 和 Int 是标量类型，! 表示字段不可为空。</p>
<p>schema 验证是 GraphQL 规范的一部分，因此像这样的查询将返回错误，因为 name 和 phone 不是 Address 对象的字段：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    user (id: 123) &#123;</span><br><span class="line">        address &#123;</span><br><span class="line">            name</span><br><span class="line">            phone</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们可以使用我们的类型构建复杂的 GraphQL schema。例如，用户类型可能会使用我们的地址、简历和订阅类型，如下所示：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">type User &#123;</span><br><span class="line">    id: ID!</span><br><span class="line">    firstName: String!</span><br><span class="line">    lastName: String!</span><br><span class="line">    address: Address!</span><br><span class="line">    resumes: [Resume] </span><br><span class="line">    subscriptions: [Subscription]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Indeed 的大量对象和类型都是使用 ProtoBuf 定义的。类型化数据并不是什么新鲜事物，而且类型数据的好处也是众所周知。与发明新的 JSON 类型标准相比，GraphQL 的优点在于已经存在可以从 ProtoBuf 自动换换到 GraphQL 的库。即使其中一个库（<a target="_blank" rel="noopener" href="https://github.com/google/rejoiner"> rejoiner </a>）不能用，也可以开发自己的转换器。</p>
<p>GraphQL 提供了比 JSON RESTful API 更强的安全性，主要有两个原因：强类型 schema（例如数据验证和无 SQL 注入）以及精确定义客户端所需数据的能力（不会无意泄漏数据）。</p>
<p>静态验证是另一个优势，可以帮助工程师节省时间，并在进行重构时提升工程师的信心。诸如<a target="_blank" rel="noopener" href="https://github.com/apollographql/eslint-plugin-graphql"> eslint-plugin-graphql </a>之类的工具可以让工程师知道后端发生的变化，并让后端工程师确保不会破坏客户端代码。</p>
<p>保持前端和后端之间的契约是非常重要的。在使用 REST API 时，我们要小心不要破坏了客户端代码，因为客户端无法控制响应消息。相反，GraphQL 为客户端提供了控制，GraphQL 可以频繁更新，而不会因为引入了新类型造成重大变更。因为使用了 schema，所以 GraphQL 是一种无版本的 API。</p>
<h2 id="GraphQL-的实现"><a href="#GraphQL-的实现" class="headerlink" title="GraphQL 的实现"></a>GraphQL 的实现</h2><p>在选择实现 GraphQL API 的平台时，Node 是一个候选项，因为最初 GraphQL 用于 Web 应用程序和前端，而 Node 是开发 Web 应用程序的首选，因为它是基于 JavaScript 的。使用 Node 可以非常容易地实现 GraphQL（假设提供了 schema）。事实上，使用 Express 或 Koa 来实现只需要几行代码：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> Koa = <span class="built_in">require</span>(<span class="string">&#x27;koa&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> Router = <span class="built_in">require</span>(<span class="string">&#x27;koa-router&#x27;</span>); <span class="comment">// koa-router@7.x</span></span><br><span class="line"><span class="keyword">const</span> graphqlHTTP = <span class="built_in">require</span>(<span class="string">&#x27;koa-graphql&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> app = <span class="keyword">new</span> Koa();</span><br><span class="line"><span class="keyword">const</span> router = <span class="keyword">new</span> Router();</span><br><span class="line"></span><br><span class="line">router.all(<span class="string">&#x27;/graphql&#x27;</span>, graphqlHTTP(&#123;</span><br><span class="line">  schema: schema,</span><br><span class="line">  graphiql: <span class="literal">true</span></span><br><span class="line">&#125;));</span><br><span class="line"></span><br><span class="line">app.use(router.routes()).use(router.allowedMethods());</span><br></pre></td></tr></table></figure>

<p>schema 是使用 npm 的 graphql 中的类型来定义的。Query 和 Mutation 是特殊的 schema 类型。</p>
<p>GraphQL API 的大部分实现都在于 schema 和解析器。解析器可以包含任意代码，但最常见的是以下五个主要类别：</p>
<ul>
<li>调用 Thrift、gRPC 或其他 RPC 服务；</li>
<li>调用 HTTP REST API（当优先事项不是重写现有 REST API 时）；</li>
<li>直接调用数据存储；</li>
<li>调用其他 GraphQL schema 查询或服务；</li>
<li>调用外部 API。</li>
</ul>
<p>这里有一个<a target="_blank" rel="noopener" href="https://medium.freecodecamp.org/graphql-zero-to-production-a7c4f786a57b">示例</a>。</p>
<p>Node 很棒，但在 Indeed，我们主要使用 Java。包括 Java 在内的很多语言都支持 GraphQL，例如<a target="_blank" rel="noopener" href="https://github.com/graphql-go"> https://github.com/graphql-go </a>和<a target="_blank" rel="noopener" href="https://github.com/graphql-python"> https://github.com/graphql-python </a>。</p>
<p>由于 Indeed 主要使用了 Java，因此这里给出一个使用 graphql-java 的 Java GraphQL 示例，完整代码位于<a target="_blank" rel="noopener" href="https://github.com/howtographql/graphql-java">这里</a>。它定义了 /graphql 端点：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.coxautodev.graphql.tools.SchemaParser;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.annotation.WebServlet;</span><br><span class="line"><span class="keyword">import</span> graphql.servlet.SimpleGraphQLServlet;</span><br><span class="line"></span><br><span class="line"><span class="meta">@WebServlet(urlPatterns = &quot;/graphql&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GraphQLEndpoint</span> <span class="keyword">extends</span> <span class="title">SimpleGraphQLServlet</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">GraphQLEndpoint</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(SchemaParser.newParser()</span><br><span class="line">                .file(<span class="string">&quot;schema.graphqls&quot;</span>) <span class="comment">//parse the schema file created earlier</span></span><br><span class="line">                .build()</span><br><span class="line">                .makeExecutableSchema());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>GraphQL 的 schema 使用 POJO 来定义。GraphQL 端点类使用了 LinkRepository POJO。解析器包含了操作的（例如获取链接）实际代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@WebServlet(urlPatterns = &quot;/graphql&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GraphQLEndpoint</span> <span class="keyword">extends</span> <span class="title">SimpleGraphQLServlet</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">GraphQLEndpoint</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(buildSchema());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> GraphQLSchema <span class="title">buildSchema</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        LinkRepository linkRepository = <span class="keyword">new</span> LinkRepository();</span><br><span class="line">        <span class="keyword">return</span> SchemaParser.newParser()</span><br><span class="line">                .file(<span class="string">&quot;schema.graphqls&quot;</span>)</span><br><span class="line">                .resolvers(<span class="keyword">new</span> Query(linkRepository))</span><br><span class="line">                .build()</span><br><span class="line">                .makeExecutableSchema();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在很多情况下，GraphQL 的 schema 可以从其他类型的 schema 自动生成，例如 gRPC、Boxcar、ProtoBuf 或 ORM/ODM。</p>
<p>GraphQL 不一定需要客户端。一个简单的 GraphQL 请求就是一个常规的 POST HTTP 请求，其中包含了查询内容。我们可以使用任意的 HTTP 代理库（如 CURL、axios、fetch、superagent 等）来生成请求。例如，在终端中使用 curl 发送请求：</p>
<figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl \</span><br><span class="line">  -X POST \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  --data <span class="string">&#x27;&#123; &quot;query&quot;: &quot;&#123; posts &#123; title &#125; &#125;&quot; &#125;&#x27;</span> \</span><br><span class="line">  https:<span class="regexp">//</span><span class="number">1</span>jzxrj179.lp.gql.zone/graphql</span><br></pre></td></tr></table></figure>

<p>以下代码可以在任意一个现代浏览器（为了避免 CORS，<a target="_blank" rel="noopener" href="http://xn--launchpad-4840aurv07g.graphql.com/">请访问 launchpad.graphql.com </a>）中运行。</p>
<figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fetch(<span class="string">&#x27;https://1jzxrj179.lp.gql.zone/graphql&#x27;</span>, &#123;</span><br><span class="line">  method: <span class="string">&#x27;POST&#x27;</span>,</span><br><span class="line">  headers: &#123; <span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;application/json&#x27;</span> &#125;,</span><br><span class="line">  body: JSON.stringify(&#123; query: <span class="string">&#x27;&#123; posts &#123; title &#125; &#125;&#x27;</span> &#125;),</span><br><span class="line">&#125;)</span><br><span class="line">  .then(<span class="string">res =&gt;</span> res.json())</span><br><span class="line">  .then(<span class="string">res =&gt;</span> console.log(res.data));</span><br></pre></td></tr></table></figure>

<p>虽然构建 GraphQL 请求很容易，但是还需要实现很多其他东西，比如缓存，因为缓存可以极大地改善用户体验。构建客户端缓存不是那么容易，所幸的是，Apollo 和 Relay Modern 等提供了开箱即用的客户端缓存。</p>
<h2 id="什么时候不该使用-GraphQL？"><a href="#什么时候不该使用-GraphQL？" class="headerlink" title="什么时候不该使用 GraphQL？"></a>什么时候不该使用 GraphQL？</h2><p>当然，完美的解决方案是不存在的（尽管 GraphQL 接近完美），还有一些问题需要注意，例如：</p>
<p>\1. 它有单点故障吗？</p>
<p>\2. 它可以扩展吗？</p>
<p>\3. 谁在使用 GraphQL？</p>
<p>最后，以下列出了我们自己的有关 GraphQL 可能不是一个好选择的主要原因：</p>
<ul>
<li>当客户端的需求很简单时：如果你的 API 很简单，例如 /users/resumes/123，那么 GraphQL 就显得有点重了；</li>
<li>为了加快加载速度使用了异步资源加载；</li>
<li>在开发新产品时使用新的 API，而不是基于已有的 API；</li>
<li>不打算向公众公开 API；</li>
<li>不需要更改 UI 和其他客户端；</li>
<li>产品开发不活跃；</li>
<li>使用了其他一些 JSON schema 或序列化格式。</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>GraphQL 是一种协议和一种查询语言。GraphQL API 可以直接访问数据存储，但在大多数情况下，GraphQL API 是一个数据聚合器和一个抽象层，一个可以提升开发速度、减少维护工作并让开发人员更快乐的层。因此，GraphQL 比公共 API 更有意义。很多公司开始采用 GraphQL。IBM、PayPal 和 GitHub 声称在使用 GraphQL 方面取得了巨大的成功。如果 GraphQL 很有前途，我们现在是否可以停止构建过时且笨重的 REST API，并拥抱 GraphQL？</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Chinese/" rel="tag">Chinese</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GraphQL/" rel="tag">GraphQL</a></li></ul>

    </footer>
  </div>

   
    
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/19/">prev page</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="page-number" href="/page/19/">19</a><span class="page-number current">20</span><a class="page-number" href="/page/21/">21</a><a class="page-number" href="/page/22/">22</a><span class="space">&hellip;</span><a class="page-number" href="/page/24/">24</a><a class="extend next" rel="next" href="/page/21/">next page</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2020-2021
        <i class="ri-heart-fill heart_icon"></i> Aaron
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></s>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="Blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">🏡</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">🏛</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">📚</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">🏷</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/img/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->


<script src="/js/clickBoom2.js"></script>


<!-- CodeCopy -->


<link rel="stylesheet" href="/css/clipboard.css">

<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
  </div>
</body>

</html>